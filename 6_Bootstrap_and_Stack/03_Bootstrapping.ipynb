{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "import xlsxwriter\n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import pearsonr\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as grid_spec\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.io as pio\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_to_files(df, pathname, filename):\n",
    "    \"\"\"\n",
    "    Save a pandas DataFrame to both CSV and Excel formats in the specified location.\n",
    "    Creates directories if they don't exist.\n",
    "    \"\"\"\n",
    "    # Ensure the filename doesn't include extensions\n",
    "    base_name = os.path.splitext(filename)[0]\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(pathname, exist_ok=True)\n",
    "    \n",
    "    # Create full paths\n",
    "    csv_path = os.path.join(pathname, f\"{base_name}.csv\")\n",
    "    excel_path = os.path.join(pathname, f\"{base_name}.xlsx\")\n",
    "    \n",
    "    try:\n",
    "        # Save files\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        df.to_excel(excel_path, index=False, engine='openpyxl')\n",
    "        \n",
    "        print(f\"Files saved successfully:\\n- {csv_path}\\n- {excel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving files: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bootstrap_ci(bootstrap_distribution, confidence_level=0.95):\n",
    "    \"\"\"Compute confidence intervals with input validation\"\"\"\n",
    "    alpha = 1 - confidence_level\n",
    "    lower = np.percentile(bootstrap_distribution, (alpha / 2) * 100).round(3)\n",
    "    upper = np.percentile(bootstrap_distribution, (1 - alpha / 2) * 100).round(3)\n",
    "    return (lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_bootstrap_results_1level(\n",
    "    metrics: List[str],\n",
    "    modality_name: str,\n",
    "    base_path: str,\n",
    "    output_path: str,\n",
    "    ci_level: float = 0.95,\n",
    "    column_order: Optional[List[str]] = None,\n",
    "    print_summary: bool = True\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute bootstrap confidence intervals for multiple metrics and modalities.\n",
    "    \n",
    "    Args:\n",
    "        metrics: List of metric names (e.g., ['r2', 'r', 'mse', 'mae'])\n",
    "        modality_name: Name of the modality being analyzed\n",
    "        base_path: Base directory path containing bootstrap CSV files\n",
    "        output_path: Directory where results will be saved\n",
    "        ci_level: Confidence level (default: 0.95)\n",
    "        column_order: Optional list specifying column order in output\n",
    "        print_summary: Whether to print formatted summary (default: True)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing computed statistics and confidence intervals\n",
    "    \"\"\"\n",
    "    # Default column order\n",
    "    if column_order is None:\n",
    "        column_order = ['Modality', 'Metric', 'Mean', 'Median', 'Std', 'CI_lower', 'CI_upper']\n",
    "    \n",
    "    ci_results = []\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Load bootstrap results\n",
    "        try:\n",
    "            file_path = os.path.join(base_path, f\"{modality_name}_{metric}_bootstrapped_renamed.csv\")\n",
    "            df = pd.read_csv(file_path)\n",
    "            \n",
    "            # Clean columns\n",
    "            df = df.drop(\n",
    "                columns=df.columns[df.columns.str.contains('^Unnamed|^index$', case=False)], \n",
    "                errors='ignore'\n",
    "            )\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: File not found for {modality_name}_{metric}\")\n",
    "            continue\n",
    "        \n",
    "        # Process each modality column\n",
    "        for modality in df.columns:\n",
    "            if df[modality].isna().all():\n",
    "                print(f\"Skipping empty modality: {modality}\")\n",
    "                continue\n",
    "                \n",
    "            values = df[modality].values\n",
    "            lower, upper = get_bootstrap_ci(values, ci_level)\n",
    "            \n",
    "            ci_results.append({\n",
    "                'Modality': modality,\n",
    "                'Metric': metric.upper(),\n",
    "                'Mean': np.mean(values).round(3),\n",
    "                'Median': np.median(values).round(3),\n",
    "                'Std': np.std(values).round(3),\n",
    "                'CI_lower': lower,\n",
    "                'CI_upper': upper\n",
    "            })\n",
    "    \n",
    "    # Create and format DataFrame\n",
    "    ci_df = pd.DataFrame(ci_results)\n",
    "    \n",
    "    # Ensure all expected columns exist\n",
    "    missing_cols = [col for col in column_order if col not in ci_df.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Missing expected columns: {missing_cols}\")\n",
    "    \n",
    "    ci_df = ci_df[column_order]\n",
    "    \n",
    "    # Save results\n",
    "    output_filename = f'bootstrap_{modality_name}_pls_CI'\n",
    "    save_dataframe_to_files(ci_df, output_path, output_filename)\n",
    "    \n",
    "    # Print results\n",
    "    if print_summary:\n",
    "        print_results(ci_df, output_path)\n",
    "    \n",
    "    return ci_df\n",
    "\n",
    "\n",
    "def print_results(ci_df: pd.DataFrame, output_path: str) -> None:\n",
    "    \"\"\"Print formatted results summary.\"\"\"\n",
    "    print(\"=== Confidence Intervals ===\")\n",
    "    print(ci_df)\n",
    "    print(f\"\\nResults saved to: {output_path}\")\n",
    "    \n",
    "    for modality, group in ci_df.groupby('Modality'):\n",
    "        print(f\"\\n=== {modality} ===\")\n",
    "        for metric, metric_group in group.groupby('Metric'):\n",
    "            row = metric_group.iloc[0]\n",
    "            print(f\"{row['Metric']}:\")\n",
    "            print(f\"  Mean ± SD: {row['Mean']} ± {row['Std']}\")\n",
    "            print(f\"  Median: {row['Median']}\")\n",
    "            print(f\"  95% CI: [{row['CI_lower']}, {row['CI_upper']}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_save_bootstrap_results_2level(\n",
    "    bootstrap_dists: dict,\n",
    "    output_path: str,\n",
    "    modality_name: str = None,\n",
    "    algorithms: list = ['SVR', 'eNet', 'RF', 'XGB']\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute bootstrap statistics and save results for multiple algorithms and metrics\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    bootstrap_dists : dict\n",
    "        Dictionary containing bootstrap distributions (format: {'Metric': {'Algorithm': data}})\n",
    "    output_path : str\n",
    "        Directory where results will be saved\n",
    "    modality_name : str, optional\n",
    "        Name of the modality being analyzed (for output filename)\n",
    "    algorithms : list, optional\n",
    "        List of algorithms to analyze (default: ['SVR', 'eNet', 'RF', 'XGB'])\n",
    "    \"\"\"\n",
    "    # Initialize results storage\n",
    "    ci_results = {\n",
    "        'Modality': [],\n",
    "        'Algorithm': [],\n",
    "        'Metric': [],\n",
    "        'Mean': [],\n",
    "        'Median': [],\n",
    "        'Std': [],\n",
    "        'CI_lower': [],\n",
    "        'CI_upper': []\n",
    "    }\n",
    "\n",
    "    for algorithm in algorithms:  # <-- CHANGED: Use parameter instead of hardcoded list\n",
    "        print(f\"\\n=== {algorithm} ===\")\n",
    "        \n",
    "        for metric, dist in bootstrap_dists.items():\n",
    "            try:\n",
    "                alg_data = dist[algorithm]\n",
    "                \n",
    "                # Calculate statistics\n",
    "                mean_val = np.mean(alg_data).round(3)\n",
    "                median_val = np.median(alg_data).round(3)\n",
    "                std_val = np.std(alg_data).round(3)\n",
    "                lower, upper = get_bootstrap_ci(alg_data)\n",
    "                \n",
    "                # Store results (including modality if provided)\n",
    "                if modality_name:\n",
    "                    ci_results['Modality'].append(modality_name)\n",
    "                ci_results['Algorithm'].append(algorithm)\n",
    "                ci_results['Metric'].append(metric)\n",
    "                ci_results['Mean'].append(mean_val)\n",
    "                ci_results['Median'].append(median_val)\n",
    "                ci_results['Std'].append(std_val)\n",
    "                ci_results['CI_lower'].append(lower)\n",
    "                ci_results['CI_upper'].append(upper)\n",
    "                \n",
    "                print(f\"{metric}:\")\n",
    "                print(f\"  Mean ± SD: {mean_val} ± {std_val}\")\n",
    "                print(f\"  Median: {median_val}\")\n",
    "                print(f\"  95% CI: [{lower}, {upper}]\")\n",
    "                \n",
    "            except KeyError:\n",
    "                print(f\"Warning: {algorithm} not found in {metric} data\")\n",
    "                continue\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    try:\n",
    "        # Define expected columns (including Modality if needed)\n",
    "        expected_columns = (['Modality'] if modality_name else []) + [\n",
    "            'Algorithm', 'Metric', 'Mean', 'Median', 'Std', 'CI_lower', 'CI_upper'\n",
    "        ]\n",
    "        \n",
    "        ci_df = pd.DataFrame(ci_results)\n",
    "        \n",
    "        # Verify columns\n",
    "        missing_cols = [col for col in expected_columns if col not in ci_df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing columns: {missing_cols}\")\n",
    "            \n",
    "        ci_df = ci_df[expected_columns]\n",
    "        \n",
    "        # Create filename with modality if provided\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M\")\n",
    "        base_filename = f\"bootstrap_{modality_name}_CI\" if modality_name else f\"bootstrap_CI\"\n",
    "        \n",
    "        save_dataframe_to_files(ci_df, output_path, base_filename)\n",
    "        \n",
    "        print(\"\\n=== Final Results ===\")\n",
    "        print(ci_df)\n",
    "        print(f\"\\nResults saved to: {output_path}\")\n",
    "        \n",
    "        return ci_df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing results: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mental Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "pred_test = []\n",
    "obs_test = []\n",
    "\n",
    "for fold in folds:\n",
    "    g_pred_test = pd.read_csv(f'/mental_health/folds/fold_{fold}/g_pred/g_pred_mh_fold_{fold}.csv')\n",
    "    g_obs_test = pd.read_csv(f'/mental_health/folds/fold_{fold}/suppl/g_test_matched_fold_{fold}.csv')\n",
    "\n",
    "    pred_test.append(g_pred_test)\n",
    "    obs_test.append(g_obs_test)\n",
    "        \n",
    "g_five_folds_pred_test = pd.concat(pred_test, axis=0, ignore_index=True)\n",
    "g_five_folds_pred_test.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/mh/mental_health_target_pred_test.csv', index=False)\n",
    "\n",
    "g_five_folds_obs_test = pd.concat(obs_test, axis=0, ignore_index=True)\n",
    "g_five_folds_obs_test.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/mh/mental_health_target_obs_test.csv', index=False)\n",
    "\n",
    "print(f'Shape of the (predicted) test set in mental health is', g_five_folds_pred_test.shape)\n",
    "print(f'Shape of the (observed) test set in mental health is', g_five_folds_obs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap mental health\n",
    "# =============================================\n",
    "# PART 1: Combine 5-fold cross-validation results\n",
    "# =============================================\n",
    "\n",
    "# Concat 5 folds for mental health\n",
    "pred_test = []\n",
    "obs_test = []\n",
    "folds = range(5)\n",
    "\n",
    "for fold in folds:\n",
    "    # Load predicted values\n",
    "    g_pred_test = pd.read_csv(\n",
    "        f'/mental_health/folds/fold_{fold}/g_pred/g_pred_mh_fold_{fold}.csv'\n",
    "    )\n",
    "    \n",
    "    # Load observed values\n",
    "    g_obs_test = pd.read_csv(\n",
    "        f'/mental_health/folds/fold_{fold}/suppl/g_test_matched_fold_{fold}.csv'\n",
    "    )\n",
    "\n",
    "    pred_test.append(g_pred_test)\n",
    "    obs_test.append(g_obs_test)\n",
    "        \n",
    "# Combine all folds\n",
    "g_five_folds_pred_test = pd.concat(pred_test, axis=0, ignore_index=True)\n",
    "g_five_folds_obs_test = pd.concat(obs_test, axis=0, ignore_index=True)\n",
    "\n",
    "# Save combined results\n",
    "g_five_folds_pred_test.to_csv(\n",
    "    '/PLS/brain/stacking/BOOTSTRAP/mh/mental_health_target_pred_test.csv', \n",
    "    index=False\n",
    ")\n",
    "\n",
    "g_five_folds_obs_test.to_csv(\n",
    "    '/PLS/brain/stacking/BOOTSTRAP/mh/mental_health_target_obs_test.csv', \n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(f'Shape of the (predicted) test set for mental health: {g_five_folds_pred_test.shape}')\n",
    "print(f'Shape of the (observed) test set for mental health: {g_five_folds_obs_test.shape}')\n",
    "\n",
    "# =============================================\n",
    "# PART 2: Bootstrapping for mental health\n",
    "# =============================================\n",
    "\n",
    "# Load the combined data\n",
    "g_real = g_five_folds_obs_test\n",
    "g_pred = g_five_folds_pred_test\n",
    "\n",
    "# Merge observed and predicted values\n",
    "g = pd.concat([g_real, g_pred], axis=1)\n",
    "g = g.rename(columns={\n",
    "    'g': 'g_mh_observed',\n",
    "    'g_pred_mh': 'g_mh_predicted'\n",
    "})\n",
    "\n",
    "# Bootstrapping configuration\n",
    "boot = 5000\n",
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "bootstrap_results = {metric: [] for metric in metrics}\n",
    "\n",
    "# Run bootstrap\n",
    "for i in range(boot):\n",
    "    df_sample = g.sample(len(g), replace=True) \n",
    "    \n",
    "    # Calculate metrics\n",
    "    corr, _ = pearsonr(df_sample['g_mh_observed'], df_sample['g_mh_predicted'])\n",
    "    r2 = r2_score(df_sample['g_mh_observed'], df_sample['g_mh_predicted'])\n",
    "    mse = mean_squared_error(df_sample['g_mh_observed'], df_sample['g_mh_predicted'])\n",
    "    mae = mean_absolute_error(df_sample['g_mh_observed'], df_sample['g_mh_predicted'])\n",
    "            \n",
    "    bootstrap_results['r'].append(corr)\n",
    "    bootstrap_results['R2'].append(r2)\n",
    "    bootstrap_results['MSE'].append(mse)\n",
    "    bootstrap_results['MAE'].append(mae)\n",
    "\n",
    "# Convert results to DataFrames\n",
    "for metric in bootstrap_results:\n",
    "    bootstrap_results[metric] = pd.DataFrame(bootstrap_results[metric], columns=[f'mh_{metric}'])\n",
    "\n",
    "# Save bootstrap results\n",
    "with open(\n",
    "    '/PLS/brain/stacking/BOOTSTRAP/mh/MH_bootstrap_results.pkl', \n",
    "    'wb'\n",
    ") as f:\n",
    "    pickle.dump(bootstrap_results, f)\n",
    "       \n",
    "print(\"Bootstrap results for mental health were successfully saved as MH_bootstrap_results.pkl\")\n",
    "\n",
    "# =============================================\n",
    "# Optional: Calculate confidence intervals\n",
    "# =============================================\n",
    "\n",
    "# Calculate 95% confidence intervals for each metric\n",
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "column_order = ['Modality', 'Metric', 'Mean', 'Median', 'Std', 'CI_lower', 'CI_upper']\n",
    "ci_results = []\n",
    "\n",
    "for metric, df in bootstrap_results.items():\n",
    "    values = df[f'mh_{metric}'].values\n",
    "    \n",
    "    # Calculate confidence intervals (using percentile method)\n",
    "    lower = np.percentile(values, 2.5)\n",
    "    upper = np.percentile(values, 97.5)\n",
    "    \n",
    "    ci_results.append({\n",
    "        'Modality': 'mh',\n",
    "        'Metric': metric.upper(),\n",
    "        'Mean': np.mean(values).round(3),\n",
    "        'Median': np.median(values).round(3),\n",
    "        'Std': np.std(values).round(3),\n",
    "        'CI_lower': lower.round(3),\n",
    "        'CI_upper': upper.round(3)\n",
    "    })\n",
    "\n",
    "# Create and format DataFrame\n",
    "ci_df = pd.DataFrame(ci_results)\n",
    "missing_cols = [col for col in column_order if col not in ci_df.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing expected columns: {missing_cols}\")\n",
    "\n",
    "ci_df = ci_df[column_order]\n",
    "\n",
    "# Save results\n",
    "output_filename = 'bootstrap_mh_pls_CI'\n",
    "ci_df.to_csv(\n",
    "    f'/PLS/brain/stacking/BOOTSTRAP/mh/{output_filename}.csv',\n",
    "    index=False\n",
    ")\n",
    "ci_df.to_pickle(\n",
    "    f'/PLS/brain/stacking/BOOTSTRAP/mh/{output_filename}.pkl'\n",
    ")\n",
    "\n",
    "\n",
    "output_path = '/rev1'\n",
    "save_dataframe_to_files(ci_df, output_path, f'bootstrap_mental_health_pls_CI')\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(\"\\n=== Confidence Intervals ===\")\n",
    "print(ci_df)\n",
    "print(f\"\\nResults saved to: {output_path}\")\n",
    "\n",
    "for _, row in ci_df.iterrows():\n",
    "    print(f\"\\n=== {row['Modality']} - {row['Metric']} ===\")\n",
    "    print(f\"Mean ± SD: {row['Mean']} ± {row['Std']}\")\n",
    "    print(f\"Median: {row['Median']}\")\n",
    "    print(f\"95% CI: [{row['CI_lower']}, {row['CI_upper']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap DTI IDP + Parcellations Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "algorithms = ['svr', 'eNet', 'xgb', 'rf']\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/stacking/g/DTI_All_target_pred_2nd_level_{algorithm}_train_fold_{fold}.csv')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/stacking/g/DTI_All_target_pred_2nd_level_{algorithm}_test_fold_{fold}.csv')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[algorithm] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[algorithm] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/dti_all/DTI_All_target_pred_{algorithm}_train.csv', index=False)\n",
    "    g_five_folds_test[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/dti_all/DTI_All_target_pred_{algorithm}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {algorithm} is', g_five_folds_train[algorithm].shape)\n",
    "    print(f'Shape of the test set in {algorithm} is', g_five_folds_test[algorithm].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g\n",
    "g_five_folds_real_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/dti_all/DTI_All_target_pred_svr_test.csv')\n",
    "g_real_to_pred_match = pd.DataFrame(g_five_folds_real_test.merge(g_five_folds_pred_test['eid'], on='eid'), columns = ['g_real_test', 'eid'])\n",
    "g_real_to_pred_match.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/dti_all/g_real_to_pred_match_dti_all_test.csv')\n",
    "print('Shape of g real test matched to g pred is', g_real_to_pred_match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot = 5000\n",
    "g_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/dti_all/g_real_to_pred_match_dti_all_test.csv')\n",
    "preds=[]\n",
    "\n",
    "bootstrap_results_dfs = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    g_pred = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/dti_all/DTI_All_target_pred_{algorithm}_test.csv')\n",
    "    df = pd.concat([g_real, g_pred], axis=1).drop(columns=['eid', 'Unnamed: 0'])\n",
    "    df.columns = ['g_real_test', f'g_pred_dti_all_{algorithm}_test']\n",
    "    \n",
    "    # Initialize a discionary for each algorithmn separately\n",
    "\n",
    "    bootstrap_results = {\n",
    "    'R2': [],\n",
    "    'r': [],\n",
    "    'MSE': [],\n",
    "    'MAE': []\n",
    "    }\n",
    "\n",
    "    for i in range(boot):\n",
    "        df_sample = df.sample(len(df),replace=True) #random sample with replacement, frac=1 mean size will be the size of data set\n",
    "        corr, _ = pearsonr(df_sample['g_real_test'], df_sample[f'g_pred_dti_all_{algorithm}_test'])\n",
    "        r2 = r2_score(df_sample['g_real_test'], df_sample[f'g_pred_dti_all_{algorithm}_test'])\n",
    "        mse = mean_squared_error(df_sample['g_real_test'], df_sample[f'g_pred_dti_all_{algorithm}_test'])\n",
    "        mae = mean_absolute_error(df_sample['g_real_test'], df_sample[f'g_pred_dti_all_{algorithm}_test'])\n",
    "\n",
    "        bootstrap_results['r'].append(corr)\n",
    "        bootstrap_results['R2'].append(r2)\n",
    "        bootstrap_results['MSE'].append(mse)\n",
    "        bootstrap_results['MAE'].append(mae)\n",
    "\n",
    "    for key in bootstrap_results:\n",
    "        bootstrap_results[key] = pd.DataFrame(bootstrap_results[key], columns=[f'{algorithm}_{key}'])\n",
    "        \n",
    "    bootstrap_results_dfs[algorithm] = bootstrap_results\n",
    "\n",
    "bootstrap_svr = bootstrap_results_dfs['svr']\n",
    "bootstrap_enet = bootstrap_results_dfs['eNet']\n",
    "bootstrap_rf = bootstrap_results_dfs['rf']\n",
    "bootstrap_xgb = bootstrap_results_dfs['xgb']\n",
    "\n",
    "for metric in bootstrap_svr:\n",
    "    bootstrap_svr[metric] = pd.DataFrame(bootstrap_svr[metric])\n",
    "\n",
    "bootstrap_svr = pd.concat([bootstrap_svr['R2'].reset_index(drop=True), \n",
    "                    bootstrap_svr['r'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_enet:\n",
    "    bootstrap_enet[metric] = pd.DataFrame(bootstrap_enet[metric])\n",
    "\n",
    "bootstrap_enet = pd.concat([bootstrap_enet['R2'].reset_index(drop=True), \n",
    "                    bootstrap_enet['r'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_rf:\n",
    "    bootstrap_rf[metric] = pd.DataFrame(bootstrap_rf[metric])\n",
    "\n",
    "bootstrap_rf = pd.concat([bootstrap_rf['R2'].reset_index(drop=True), \n",
    "                    bootstrap_rf['r'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_xgb:\n",
    "    bootstrap_xgb[metric] = pd.DataFrame(bootstrap_xgb[metric])\n",
    "\n",
    "bootstrap_xgb = pd.concat([bootstrap_xgb['R2'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['r'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MAE'].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "bootstrap_fullres = pd.concat([\n",
    "    bootstrap_svr,\n",
    "    bootstrap_enet,\n",
    "    bootstrap_rf,\n",
    "    bootstrap_xgb], axis=1)\n",
    "\n",
    "bootstrap_fullres.to_csv('/PLS/brain/stacking/BOOTSTRAP/dti_all/bootstrap_dti_all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine algorithms\n",
    "bootstrap_fullres_dti_stacked_rf = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/dti_all/bootstrap_dti_all.csv')\n",
    "\n",
    "bootstrap_R2 = bootstrap_fullres_dti_stacked_rf[['svr_R2', 'eNet_R2', 'rf_R2', 'xgb_R2']]\n",
    "bootstrap_R2.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_r = bootstrap_fullres_dti_stacked_rf[['svr_r', 'eNet_r', 'rf_r', 'xgb_r']]\n",
    "bootstrap_r.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_mse = bootstrap_fullres_dti_stacked_rf[['svr_MSE', 'eNet_MSE', 'rf_MSE', 'xgb_MSE']]\n",
    "bootstrap_mse.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_mae = bootstrap_fullres_dti_stacked_rf[['svr_MAE', 'eNet_MAE', 'rf_MAE', 'xgb_MAE']]\n",
    "bootstrap_mae.columns = ['SVR', 'eNet', 'RF', 'XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "bootstrap_fullres_dti_stacked_rf = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/dti_all/bootstrap_dti_all.csv')\n",
    "\n",
    "bootstrap_dti_R2 = bootstrap_fullres_dti_stacked_rf[['svr_R2', 'eNet_R2', 'rf_R2', 'xgb_R2']]\n",
    "bootstrap_dti_R2.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_dti_r = bootstrap_fullres_dti_stacked_rf[['svr_r', 'eNet_r', 'rf_r', 'xgb_r']]\n",
    "bootstrap_dti_r.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_dti_mse = bootstrap_fullres_dti_stacked_rf[['svr_MSE', 'eNet_MSE', 'rf_MSE', 'xgb_MSE']]\n",
    "bootstrap_dti_mse.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_dti_mae = bootstrap_fullres_dti_stacked_rf[['svr_MAE', 'eNet_MAE', 'rf_MAE', 'xgb_MAE']]\n",
    "bootstrap_dti_mae.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "# Get best algorithm\n",
    "bootstrap_dti_stacked_rf_r = bootstrap_dti_r['RF']\n",
    "bootstrap_dti_stacked_rf_R2 = bootstrap_dti_R2['RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap DTI IDP PLSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap DTI IDP PLSR: Prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modalities\n",
    "dti_idp_modalities = [\"fa_tbss\",  \"fa_prob\", \"md_tbss\", \"md_prob\", \"l1_tbss\",\n",
    "\"l1_prob\", \"l2_tbss\", \"l2_prob\", \"l3_tbss\", \"l3_prob\",\n",
    "\"mo_tbss\", \"mo_prob\", \"od_tbss\", \"od_prob\", \"icvf_tbss\",\n",
    "\"icvf_prob\", \"isovf_tbss\", \"isovf_prob\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for modality in dti_idp_modalities:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/dti/dti_idp/fold_{fold}/g_pred/{modality}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/dti/dti_idp/fold_{fold}/g_pred/{modality}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[modality] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[modality] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/DTI_IDP_target_pred_{modality}_train.csv', index=False)\n",
    "    g_five_folds_test[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/DTI_IDP_target_pred_{modality}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {modality} is', g_five_folds_train[modality].shape)\n",
    "    print(f'Shape of the test set in {modality} is', g_five_folds_test[modality].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g for each modality\n",
    "g_real_to_pred_match_dict = {}\n",
    "g_five_folds_test_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "\n",
    "for modality in dti_idp_modalities:\n",
    "\n",
    "    g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/target_pred_{modality}_test.csv')\n",
    "    g_real_to_pred_match_dict[modality] = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test, on='eid'))\n",
    "    g_real_to_pred_match_dict[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/g_real_to_pred_match_{modality}_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap DTI Parcellations PLSR: Prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_parcellations = [\n",
    "'31020_connectome_fa','31020_connectome_mean_length','31020_connectome_sift2','31020_connectome_streamline_count',\n",
    "'31021_connectome_fa','31021_connectome_mean_length','31021_connectome_sift2','31021_connectome_streamline_count',\n",
    "'31022_connectome_fa','31022_connectome_mean_length','31022_connectome_sift2','31022_connectome_streamline_count',\n",
    "'31023_connectome_fa','31023_connectome_mean_length','31023_connectome_sift2','31023_connectome_streamline_count',\n",
    "'31024_connectome_fa','31024_connectome_mean_length','31024_connectome_sift2','31024_connectome_streamline_count',\n",
    "'31025_connectome_fa','31025_connectome_mean_length','31025_connectome_sift2','31025_connectome_streamline_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for atlas in dti_parcellations:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/dti/dti_struct/fold_{fold}/g_pred/{atlas}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/dti/dti_struct/fold_{fold}/g_pred/{atlas}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[atlas] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[atlas] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[atlas].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/DTI_Struct_target_pred_{atlas}_train.csv', index=False)\n",
    "    g_five_folds_test[atlas].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/DTI_Struct_target_pred_{atlas}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {atlas} is', g_five_folds_train[atlas].shape)\n",
    "    print(f'Shape of the test set in {atlas} is', g_five_folds_test[atlas].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g for each modality\n",
    "g_real_to_pred_match_dict = {}\n",
    "g_five_folds_test_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "\n",
    "for atlas in dti_parcellations:\n",
    "\n",
    "    g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/target_pred_{atlas}_test.csv')\n",
    "    g_real_to_pred_match_dict[atlas] = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test, on='eid'))\n",
    "    g_real_to_pred_match_dict[atlas].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/g_real_to_pred_match_{atlas}_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap DTI IDP and Parcellations PLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dti_modalities = [\"fa_tbss\",  \"fa_prob\", \"md_tbss\", \"md_prob\", \"l1_tbss\",\n",
    "\"l1_prob\", \"l2_tbss\", \"l2_prob\", \"l3_tbss\", \"l3_prob\",\n",
    "\"mo_tbss\", \"mo_prob\", \"od_tbss\", \"od_prob\", \"icvf_tbss\",\n",
    "\"icvf_prob\", \"isovf_tbss\", \"isovf_prob\",\n",
    "'31020_connectome_fa','31020_connectome_mean_length','31020_connectome_sift2','31020_connectome_streamline_count',\n",
    "'31021_connectome_fa','31021_connectome_mean_length','31021_connectome_sift2','31021_connectome_streamline_count',\n",
    "'31022_connectome_fa','31022_connectome_mean_length','31022_connectome_sift2','31022_connectome_streamline_count',\n",
    "'31023_connectome_fa','31023_connectome_mean_length','31023_connectome_sift2','31023_connectome_streamline_count',\n",
    "'31024_connectome_fa','31024_connectome_mean_length','31024_connectome_sift2','31024_connectome_streamline_count',\n",
    "'31025_connectome_fa','31025_connectome_mean_length','31025_connectome_sift2','31025_connectome_streamline_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot = 5000\n",
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "bootstrap_results_dfs = {mod: {metric: [] for metric in metrics} for mod in all_dti_modalities}\n",
    "    \n",
    "for modality in all_dti_modalities:\n",
    "    g_real_pls = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/g_real_to_pred_match_{modality}_test.csv')\n",
    "    g_pred_pls = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/target_pred_{modality}_test.csv')\n",
    "    g = g_real_pls.merge(g_pred_pls, on = 'eid').drop(columns=['Unnamed: 0', 'g predicted test_x'])\n",
    "    g = g.rename(columns={'g predicted test_y': f'g_predicted_pls_{modality}'})\n",
    "\n",
    "    bootstrap_results = {metric: [] for metric in metrics}\n",
    "        \n",
    "    for i in range(boot):\n",
    "        df_sample = g.sample(len(g),replace=True) \n",
    "\n",
    "        corr_pls, _ = pearsonr(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        r2_pls = r2_score(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        mse_pls = mean_squared_error(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        mae_pls = mean_absolute_error(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "            \n",
    "        bootstrap_results['r'].append(corr_pls)\n",
    "        bootstrap_results['R2'].append(r2_pls)\n",
    "        bootstrap_results['MSE'].append(mse_pls)\n",
    "        bootstrap_results['MAE'].append(mae_pls)\n",
    "            \n",
    "    for key in bootstrap_results:\n",
    "        bootstrap_results[key] = pd.DataFrame(bootstrap_results[key], columns=[f'{modality}_{key}'])\n",
    "\n",
    "    bootstrap_results_dfs[modality] = bootstrap_results\n",
    "\n",
    "with open('/PLS/brain/stacking/BOOTSTRAP/DTI_PLS_bootstrap_results_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(bootstrap_results_dfs, f)\n",
    "        \n",
    "print(\"bootstrap_results_dfs dictionary was successfully saved as bootstrap_results_dfs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to upload the saved bootstrapped object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/PLS/brain/stacking/BOOTSTRAP/DTI_PLS_bootstrap_results_dfs.pkl', 'rb') as f:\n",
    "    bootstrap_results_dfs = pickle.load(f)\n",
    "metric_dfs = {metric: pd.DataFrame() for metric in ['R2', 'r', 'MSE', 'MAE']}\n",
    "for modality, results in bootstrap_results_dfs.items():\n",
    "    for metric, df in results.items():\n",
    "        if metric in metric_dfs:\n",
    "            metric_dfs[metric] = pd.concat([metric_dfs[metric], df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataframes for each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_r2 = pd.concat([df['R2'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "dti_r = pd.concat([df['r'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "dti_mse = pd.concat([df['MSE'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "dti_mae = pd.concat([df['MAE'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "\n",
    "#dti_r2.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r2_dti_bootstrapped.csv', index=False)\n",
    "#dti_r.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r_dti_bootstrapped.csv', index=False)\n",
    "#dti_mse.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mse_dti_bootstrapped.csv', index=False)\n",
    "#dti_mae.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mae_dti_bootstrapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_r2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r2_dti_bootstrapped.csv')\n",
    "dti_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r_dti_bootstrapped.csv')\n",
    "dti_mse = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mse_dti_bootstrapped.csv')\n",
    "dti_mae = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mae_dti_bootstrapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_rename_dict = {\n",
    "'fa_tbss':'FA TBSS',\n",
    "'fa_prob':'FA Probabilistic',\n",
    "'md_tbss':'MD TBSS',\n",
    "'md_prob':'MD Probabilistic',\n",
    "'l1_tbss':'L1 TBSS',\n",
    "'l1_prob':'L1 Probabilistic',\n",
    "'l2_tbss':'L2 TBSS',\n",
    "'l2_prob':'L2 Probabilistic',\n",
    "'l3_tbss':'L3 TBSS',\n",
    "'l3_prob':'L3 Probabilistic',\n",
    "'mo_tbss':'MO TBSS',\n",
    "'mo_prob':'MO Probabilistic',\n",
    "'od_tbss':'OD TBSS',\n",
    "'od_prob':'OD Probabilistic',\n",
    "'icvf_tbss':'ICVF TBSS',\n",
    "'icvf_prob':'ICVF Probabilistic',\n",
    "'isovf_tbss':'ISOVF TBSS',\n",
    "'isovf_prob':'ISOVF Probabilistic',\n",
    "\n",
    "'31020_connectome_fa':'aparc a2009s MSA I Connectome FA',\n",
    "'31020_connectome_mean_length':'aparc a2009s MSA I Connectome Mean Length',\n",
    "'31020_connectome_sift2':'aparc a2009s MSA I Connectome SIFT2',\n",
    "'31020_connectome_streamline_count':'aparc a2009s MSA I Connectome Streamline Count',\n",
    "\n",
    "'31021_connectome_fa':'aparc MSA I Connectome FA',\n",
    "'31021_connectome_mean_length':'aparc MSA I Connectome Mean Length',\n",
    "'31021_connectome_sift2':'aparc MSA I Connectome SIFT2',\n",
    "'31021_connectome_streamline_count':'aparc MSA I Connectome Streamline Count',\n",
    "\n",
    "'31022_connectome_fa':'Glasser MSA I Connectome FA',\n",
    "'31022_connectome_mean_length':'Glasser MSA I Connectome Mean Length',\n",
    "'31022_connectome_sift2':'Glasser MSA I Connectome SIFT2',\n",
    "'31022_connectome_streamline_count':'Glasser MSA I Connectome Streamline Count',\n",
    "\n",
    "'31023_connectome_fa':'Glasser MSA IV Connectome FA',\n",
    "'31023_connectome_mean_length':'Glasser MSA IV Connectome Mean Length',\n",
    "'31023_connectome_sift2':'Glasser MSA IV Connectome SIFT2',\n",
    "'31023_connectome_streamline_count':'Glasser MSA IV Connectome Streamline Count',\n",
    "\n",
    "'31024_connectome_fa':'Schaefer7n200p MSA I Connectome FA',\n",
    "'31024_connectome_mean_length':'Schaefer7n200p MSA I Connectome Mean Length',\n",
    "'31024_connectome_sift2':'Schaefer7n200p MSA I Connectome SIFT2',\n",
    "'31024_connectome_streamline_count':'Schaefer7n200p MSA I Connectome Streamline Count',\n",
    "\n",
    "'31025_connectome_fa':'Schaefer7n500p MSA IV Connectome FA',\n",
    "'31025_connectome_mean_length':'Schaefer7n500p MSA IV Connectome Mean Length',\n",
    "'31025_connectome_sift2':'Schaefer7n500p MSA IV Connectome SIFT2',\n",
    "'31025_connectome_streamline_count':'Schaefer7n500p MSA IV Connectome Streamline Count'\n",
    "}\n",
    "\n",
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, base_rename_dict, metric):\n",
    "    rename_dict = {f'{k}_{metric}': v for k, v in base_rename_dict.items()}\n",
    "    return df.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_r2 = rename_columns(dti_r2, base_rename_dict, 'R2')\n",
    "dti_r = rename_columns(dti_r, base_rename_dict, 'r')\n",
    "dti_mse = rename_columns(dti_mse, base_rename_dict, 'MSE')\n",
    "dti_mae = rename_columns(dti_mse, base_rename_dict, 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "names_dti = ['dti_r2','dti_r','dti_mse','dti_mae']\n",
    "dataframes_dti = [dti_r2,dti_r,dti_mse,dti_mae]\n",
    "for df, name in zip(dataframes_dti, names_dti):\n",
    "    df.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/{name}_bootstrapped_renamed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dimensions\n",
    "#31024_Schaefer7n1000p_Tian_S4\n",
    "#31025_Schaefer7n200p_Tian_S1\n",
    "\n",
    "# Get dimensions without loading full files\n",
    "def count_lines(filepath):\n",
    "    with open(filepath) as f:\n",
    "        return sum(1 for _ in f) - 1  # Subtract 1 for header\n",
    "                    \n",
    "def count_columns(filepath):\n",
    "    with open(filepath) as f:\n",
    "        return len(next(f).split(','))  # Just read first line\n",
    "                \n",
    "Schaefer7n1000p_Tian_S4_dim = count_columns('/brainbody/brain/data/dwMRI/connectomes/31024_connectome_fa_test_corr_0.csv')\n",
    "print(Schaefer7n1000p_Tian_S4_dim)\n",
    "Schaefer7n200p_Tian_S1_dim = count_columns('/brainbody/brain/data/dwMRI/connectomes/31025_connectome_fa_test_corr_0.csv')\n",
    "print(Schaefer7n200p_Tian_S1_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CIs\n",
    "# ===== Configuration =====\n",
    "metrics = ['r2', 'r', 'mse', 'mae']\n",
    "ci_level = 0.95\n",
    "modality_name = 'dti'\n",
    "base_path = f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/{modality_name}/output'\n",
    "# ===== Process All Metrics =====\n",
    "ci_results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    # Load bootstrap results\n",
    "    try:\n",
    "        df = pd.read_csv(f'{base_path}/{modality_name}_{metric}_bootstrapped_renamed.csv')\n",
    "        \n",
    "        # Drop Unnamed columns and any index columns\n",
    "        df = df.drop(columns=df.columns[df.columns.str.contains('^Unnamed|^index$', case=False)], errors='ignore')\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found for {modality_name}_{metric}\")\n",
    "        continue\n",
    "    \n",
    "    # Compute CIs for each modality (column)\n",
    "    for modality in df.columns:\n",
    "        # Skip if column is empty or all NA\n",
    "        if df[modality].isna().all():\n",
    "            print(f\"Skipping empty modality: {modality}\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate statistics\n",
    "        values = df[modality].values\n",
    "        lower, upper = get_bootstrap_ci(values, ci_level)\n",
    "        \n",
    "        ci_results.append({\n",
    "            'Modality': modality,\n",
    "            'Metric': metric.upper(),  # R2, r, MSE, MAE\n",
    "            'Mean': np.mean(values).round(3),\n",
    "            'Median': np.median(values).round(3),\n",
    "            'Std': np.std(values).round(3),\n",
    "            'CI_lower': lower,\n",
    "            'CI_upper': upper\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "ci_df = pd.DataFrame(ci_results)\n",
    "output_path = '/rev1-analysis'\n",
    "save_dataframe_to_files(ci_df, output_path, f'bootstrap_{modality_name}_pls_CI')\n",
    "\n",
    "# Reorder columns for better readability\n",
    "column_order = ['Modality', 'Metric', 'Mean', 'Median', 'Std', 'CI_lower', 'CI_upper']\n",
    "ci_df = ci_df[column_order]\n",
    "\n",
    "print(\"=== Confidence Intervals ===\")\n",
    "print(ci_df)\n",
    "print(f\"\\nResults saved to: {output_path}\")\n",
    "\n",
    "# Print formatted summary\n",
    "for modality, group in ci_df.groupby('Modality'):\n",
    "    print(f\"\\n=== {modality} ===\")\n",
    "    for metric, metric_group in group.groupby('Metric'):\n",
    "        row = metric_group.iloc[0]  # Get first row for this metric\n",
    "        print(f\"{row['Metric']}:\")\n",
    "        print(f\"  Mean ± SD: {row['Mean']} ± {row['Std']}\")\n",
    "        print(f\"  Median: {row['Median']}\")\n",
    "        print(f\"  95% CI: [{row['CI_lower']}, {row['CI_upper']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap RS IDP + Parcellations Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "algorithms = ['svr', 'eNet', 'xgb', 'rf']\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/stacking/g/rs_idp_ts_new/RS_IDP_Timeseries_best_metrics_target_pred_2nd_level_{algorithm}_train_fold_{fold}.csv')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/stacking/g/rs_idp_ts_new/RS_IDP_Timeseries_best_metrics_target_pred_2nd_level_{algorithm}_test_fold_{fold}.csv')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[algorithm] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[algorithm] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/RS_IDP_Timeseries_best_metrics_target_pred_{algorithm}_train.csv', index=False)\n",
    "    g_five_folds_test[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/RS_IDP_Timeseries_best_metrics_target_pred_{algorithm}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {algorithm} is', g_five_folds_train[algorithm].shape)\n",
    "    print(f'Shape of the test set in {algorithm} is', g_five_folds_test[algorithm].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g\n",
    "g_five_folds_real_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/target_real_test.csv')\n",
    "g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/RS_IDP_Timeseries_best_metrics_target_pred_svr_test.csv')\n",
    "g_real_to_pred_match = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test['eid'], on='eid'), columns = ['g_real_test', 'eid'])\n",
    "g_real_to_pred_match.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/g_real_to_pred_match_rs_ts_idp_test.csv')\n",
    "print('Shape of g real test matched to g pred is', g_real_to_pred_match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot = 5000\n",
    "g_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/g_real_to_pred_match_rs_ts_idp_test.csv')\n",
    "preds=[]\n",
    "\n",
    "bootstrap_results_dfs = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    g_pred = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/RS_IDP_Timeseries_best_metrics_target_pred_{algorithm}_test.csv')\n",
    "    df = pd.concat([g_real, g_pred], axis=1).drop(columns=['eid', 'Unnamed: 0'])\n",
    "    df.columns = ['g_real_test', f'g_pred_rs_ts_idp_{algorithm}_test']\n",
    "    \n",
    "    # Initialize a discionary for each algorithmn separately\n",
    "\n",
    "    bootstrap_results = {\n",
    "    'R2': [],\n",
    "    'r': [],\n",
    "    'MSE': [],\n",
    "    'MAE': []\n",
    "    }\n",
    "\n",
    "    for i in range(boot):\n",
    "        df_sample = df.sample(len(df),replace=True) #random sample with replacement, frac=1 mean size will be the size of data set\n",
    "        corr, _ = pearsonr(df_sample['g_real_test'], df_sample[f'g_pred_rs_ts_idp_{algorithm}_test'])\n",
    "        r2 = r2_score(df_sample['g_real_test'], df_sample[f'g_pred_rs_ts_idp_{algorithm}_test'])\n",
    "        mse = mean_squared_error(df_sample['g_real_test'], df_sample[f'g_pred_rs_ts_idp_{algorithm}_test'])\n",
    "        mae = mean_absolute_error(df_sample['g_real_test'], df_sample[f'g_pred_rs_ts_idp_{algorithm}_test'])\n",
    "\n",
    "        bootstrap_results['r'].append(corr)\n",
    "        bootstrap_results['R2'].append(r2)\n",
    "        bootstrap_results['MSE'].append(mse)\n",
    "        bootstrap_results['MAE'].append(mae)\n",
    "\n",
    "    for key in bootstrap_results:\n",
    "        bootstrap_results[key] = pd.DataFrame(bootstrap_results[key], columns=[f'{algorithm}_{key}'])\n",
    "        \n",
    "    bootstrap_results_dfs[algorithm] = bootstrap_results\n",
    "\n",
    "bootstrap_svr = bootstrap_results_dfs['svr']\n",
    "bootstrap_enet = bootstrap_results_dfs['eNet']\n",
    "bootstrap_rf = bootstrap_results_dfs['rf']\n",
    "bootstrap_xgb = bootstrap_results_dfs['xgb']\n",
    "\n",
    "for metric in bootstrap_svr:\n",
    "    bootstrap_svr[metric] = pd.DataFrame(bootstrap_svr[metric])\n",
    "\n",
    "bootstrap_svr = pd.concat([bootstrap_svr['R2'].reset_index(drop=True), \n",
    "                    bootstrap_svr['r'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_enet:\n",
    "    bootstrap_enet[metric] = pd.DataFrame(bootstrap_enet[metric])\n",
    "\n",
    "bootstrap_enet = pd.concat([bootstrap_enet['R2'].reset_index(drop=True), \n",
    "                    bootstrap_enet['r'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_rf:\n",
    "    bootstrap_rf[metric] = pd.DataFrame(bootstrap_rf[metric])\n",
    "\n",
    "bootstrap_rf = pd.concat([bootstrap_rf['R2'].reset_index(drop=True), \n",
    "                    bootstrap_rf['r'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_xgb:\n",
    "    bootstrap_xgb[metric] = pd.DataFrame(bootstrap_xgb[metric])\n",
    "\n",
    "bootstrap_xgb = pd.concat([bootstrap_xgb['R2'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['r'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MAE'].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine algorithms \n",
    "bootstrap_fullres = pd.concat([\n",
    "    bootstrap_svr,\n",
    "    bootstrap_enet,\n",
    "    bootstrap_rf,\n",
    "    bootstrap_xgb], axis=1)\n",
    "\n",
    "bootstrap_fullres.to_csv('/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/bootstrap_rs_ts_idp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "bootstrap_fullres_rs_stacked_rf = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/rs_idp_ts/bootstrap_rs_ts_idp.csv')\n",
    "\n",
    "bootstrap_rs_R2 = bootstrap_fullres_rs_stacked_rf[['svr_R2', 'eNet_R2', 'rf_R2', 'xgb_R2']]\n",
    "bootstrap_rs_R2.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_rs_r = bootstrap_fullres_rs_stacked_rf[['svr_r', 'eNet_r', 'rf_r', 'xgb_r']]\n",
    "bootstrap_rs_r.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_rs_mse = bootstrap_fullres_rs_stacked_rf[['svr_MSE', 'eNet_MSE', 'rf_MSE', 'xgb_MSE']]\n",
    "bootstrap_rs_mse.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_rs_mae = bootstrap_fullres_rs_stacked_rf[['svr_MAE', 'eNet_MAE', 'rf_MAE', 'xgb_MAE']]\n",
    "bootstrap_rs_mae.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "# Get best algorithm\n",
    "bootstrap_rs_stacked_rf_r = bootstrap_rs_r['RF']\n",
    "bootstrap_rs_stacked_rf_R2 = bootstrap_rs_R2['RF']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap RS PLSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap RS IDP PLSR: Prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "amplitudes = ['amplitudes_21','amplitudes_55']\n",
    "\n",
    "tangent = ['tangent_matrices_21', 'tangent_matrices_55']\n",
    "\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "# Amplitudes\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for a in amplitudes:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/rs/ica_main/fold_{fold}/g_pred/{a}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/rs/ica_main/fold_{fold}/g_pred/{a}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[a] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[a] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[a].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{a}_train.csv', index=False)\n",
    "    g_five_folds_test[a].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{a}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {a} is', g_five_folds_train[a].shape)\n",
    "    print(f'Shape of the test set in {a} is', g_five_folds_test[a].shape)\n",
    "\n",
    "\n",
    "# Tangent\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "tangent = ['tangent_matrices_21', 'tangent_matrices_55']\n",
    "for tg in tangent:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/rs/ica_tangent/fold_{fold}/g_pred/{tg}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/rs/ica_tangent/fold_{fold}/g_pred/{tg}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[tg] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[tg] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[tg].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{tg}_train.csv', index=False)\n",
    "    g_five_folds_test[tg].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{tg}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {tg} is', g_five_folds_train[tg].shape)\n",
    "    print(f'Shape of the test set in {tg} is', g_five_folds_test[tg].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g for each modality\n",
    "\n",
    "# Amplitudes\n",
    "g_real_to_pred_match_dict = {}\n",
    "g_five_folds_test_real = pd.read_csv(f'/PLS/brain/stacking_all_mod/all/four_alg/BOOTSTRAP/target_real_test.csv')\n",
    "\n",
    "for a in amplitudes:\n",
    "\n",
    "    g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking_all_mod/all/four_alg/BOOTSTRAP/pls_vs_stack/rs/target_pred_{a}_test.csv')\n",
    "    g_real_to_pred_match_dict[a] = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test, on='eid'))\n",
    "    g_real_to_pred_match_dict[a].to_csv(f'/PLS/brain/stacking_all_mod/all/four_alg/BOOTSTRAP/pls_vs_stack/rs/g_real_to_pred_match_rs_{a}_test.csv')\n",
    "\n",
    "# Tangent\n",
    "g_real_to_pred_match_dict = {}\n",
    "g_five_folds_test_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "\n",
    "for tg in tangent:\n",
    "\n",
    "    g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/target_pred_{tg}_test.csv')\n",
    "    g_real_to_pred_match_dict[tg] = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test, on='eid')) #, columns = ['g_real_test', 'eid' 'g_predicted_{atlas}'])\n",
    "    g_real_to_pred_match_dict[tg].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/g_real_to_pred_match_rs_{tg}_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap RS Parcellations PLSR: Prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "folders = ['aparc', 'aparc_2009', 'glasser', 'glasser', 'shaefer_7n100_200', 'shaefer_7n500_600']\n",
    "atlases = [\n",
    "'aparc_Tian_s1_arrays_full_correlation', \n",
    "'aparc_2009_Tian_s1_arrays_full_correlation',\n",
    "'glasser_Tian_s1_arrays_full_correlation',\n",
    "'glasser_Tian_s4_arrays_full_correlation',\n",
    "'Schaefer7n200p_tian_s1_arrays_full_correlation',\n",
    "'Schaefer7n500p_s4_full_correlation']\n",
    "\n",
    "\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for folder, atlas in zip(folders, atlases):\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/rs/parcellation_main/{folder}/fold_{fold}/g_pred/{atlas}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/rs/parcellation_main/{folder}/fold_{fold}/g_pred/{atlas}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[atlas] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[atlas] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[atlas].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{atlas}_train.csv', index=False)\n",
    "    g_five_folds_test[atlas].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{atlas}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {atlas} is', g_five_folds_train[atlas].shape)\n",
    "    print(f'Shape of the test set in {atlas} is', g_five_folds_test[atlas].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g for each modality\n",
    "g_real_to_pred_match_dict = {}\n",
    "g_five_folds_test_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "\n",
    "for atlas in atlases:\n",
    "\n",
    "    g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{atlas}_test.csv')\n",
    "    g_real_to_pred_match_dict[atlas] = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test, on='eid'))\n",
    "    g_real_to_pred_match_dict[atlas].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/g_real_to_pred_match_rs_{atlas}_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap RS IDP and Parcellations PLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rs_modalities = ['aparc_Tian_s1_arrays_full_correlation', \n",
    "'aparc_2009_Tian_s1_arrays_full_correlation',\n",
    "'glasser_Tian_s1_arrays_full_correlation',\n",
    "'glasser_Tian_s4_arrays_full_correlation',\n",
    "'Schaefer7n200p_tian_s1_arrays_full_correlation',\n",
    "'Schaefer7n500p_s4_full_correlation',\n",
    "'amplitudes_21', 'amplitudes_55',\n",
    "'tangent_matrices_21', 'tangent_matrices_55']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot = 5000\n",
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "bootstrap_results_dfs = {mod: {metric: [] for metric in metrics} for mod in all_rs_modalities}\n",
    "    \n",
    "for modality in all_rs_modalities:\n",
    "    g_real_pls = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/g_real_to_pred_match_rs_{modality}_test.csv')\n",
    "    g_pred_pls = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/target_pred_{modality}_test.csv')\n",
    "    g = g_real_pls.merge(g_pred_pls, on = 'eid').drop(columns=['Unnamed: 0', 'g predicted test_x'])\n",
    "    g = g.rename(columns={'g predicted test_y': f'g_predicted_pls_{modality}'})\n",
    "\n",
    "    bootstrap_results = {metric: [] for metric in metrics}\n",
    "        \n",
    "    for i in range(boot):\n",
    "        df_sample = g.sample(len(g),replace=True) \n",
    "\n",
    "        corr_pls, _ = pearsonr(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        r2_pls = r2_score(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        mse_pls = mean_squared_error(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        mae_pls = mean_absolute_error(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "            \n",
    "        bootstrap_results['r'].append(corr_pls)\n",
    "        bootstrap_results['R2'].append(r2_pls)\n",
    "        bootstrap_results['MSE'].append(mse_pls)\n",
    "        bootstrap_results['MAE'].append(mae_pls)\n",
    "            \n",
    "    for key in bootstrap_results:\n",
    "        bootstrap_results[key] = pd.DataFrame(bootstrap_results[key], columns=[f'{modality}_{key}'])\n",
    "\n",
    "    bootstrap_results_dfs[modality] = bootstrap_results\n",
    "\n",
    "with open('/PLS/brain/stacking/BOOTSTRAP/RS_PLS_bootstrap_results_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(bootstrap_results_dfs, f)\n",
    "        \n",
    "print(\"bootstrap_results_dfs dictionary was successfully saved as bootstrap_results_dfs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to upload the saved bootstrapped object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/PLS/brain/stacking/BOOTSTRAP/RS_PLS_bootstrap_results_dfs.pkl', 'rb') as f:\n",
    "    bootstrap_results_dfs = pickle.load(f)\n",
    "metric_dfs = {metric: pd.DataFrame() for metric in ['R2', 'r', 'MSE', 'MAE']}\n",
    "for modality, results in bootstrap_results_dfs.items():\n",
    "    for metric, df in results.items():\n",
    "        if metric in metric_dfs:\n",
    "            metric_dfs[metric] = pd.concat([metric_dfs[metric], df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dataframes for each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_r2 = pd.concat([df['R2'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "rs_r = pd.concat([df['r'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "rs_mse = pd.concat([df['MSE'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "rs_mae = pd.concat([df['MAE'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "\n",
    "#rs_r2.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/r2_rs_bootstrapped.csv', index=False)\n",
    "#rs_r.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/r_rs_bootstrapped.csv', index=False)\n",
    "#rs_mse.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/mse_rs_bootstrapped.csv', index=False)\n",
    "#rs_mae.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/mae_rs_bootstrapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_r2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/r2_rs_bootstrapped.csv')\n",
    "rs_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/r_rs_bootstrapped.csv')\n",
    "rs_mse = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/mse_rs_bootstrapped.csv')\n",
    "rs_mae = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/mae_rs_bootstrapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "base_rename_dict = {\"aparc_Tian_s1_arrays_full_correlation\":'aparc MSA I Full correlation',\n",
    "\"aparc_2009_Tian_s1_arrays_full_correlation\":'aparc a2009s MSA I Full correlation',\n",
    "\"glasser_Tian_s1_arrays_full_correlation\":'Glasser MSA I Full correlation',\n",
    "\"glasser_Tian_s4_arrays_full_correlation\":'Glasser MSA IV Full correlation',\n",
    "\"Schaefer7n200p_tian_s1_arrays_full_correlation\":'Schaefer7n200p MSA I Full correlation',\n",
    "\"Schaefer7n500p_s4_full_correlation\":'Schaefer7n500p MSA IV Full correlation',\n",
    "\"amplitudes_21\":'Amplitudes 21 IC',\n",
    "\"amplitudes_55\":'Amplitudes 55 IC',\n",
    "\"tangent_matrices_21\":'Tangent matrices 21 IC',\n",
    "\"tangent_matrices_55\":'Tangent matrices 55 IC'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, base_rename_dict, metric):\n",
    "    rename_dict = {f'{k}_{metric}': v for k, v in base_rename_dict.items()}\n",
    "    return df.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_r2 = rename_columns(rs_r2, base_rename_dict, 'R2')\n",
    "rs_r = rename_columns(rs_r, base_rename_dict, 'r')\n",
    "rs_mse = rename_columns(rs_mse, base_rename_dict, 'MSE')\n",
    "rs_mae = rename_columns(rs_mae, base_rename_dict, 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "names_rs = ['rs_r2','rs_r','rs_mse','rs_mae']\n",
    "dataframes_rs = [rs_r2,rs_r,rs_mse,rs_mae]\n",
    "for df, name in zip(dataframes_rs, names_rs):\n",
    "    df.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/{name}_bootstrapped_renamed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CIs\n",
    "# ===== Configuration =====\n",
    "metrics = ['r2', 'r', 'mse', 'mae']\n",
    "ci_level = 0.95\n",
    "modality_name = 'rs'\n",
    "base_path = f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/{modality_name}/output'\n",
    "# ===== Process All Metrics =====\n",
    "ci_results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    # Load bootstrap results\n",
    "    try:\n",
    "        df = pd.read_csv(f'{base_path}/{modality_name}_{metric}_bootstrapped_renamed.csv')\n",
    "        \n",
    "        # Drop Unnamed columns and any index columns\n",
    "        df = df.drop(columns=df.columns[df.columns.str.contains('^Unnamed|^index$', case=False)], errors='ignore')\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found for {modality_name}_{metric}\")\n",
    "        continue\n",
    "    \n",
    "    # Compute CIs for each modality (column)\n",
    "    for modality in df.columns:\n",
    "        # Skip if column is empty or all NA\n",
    "        if df[modality].isna().all():\n",
    "            print(f\"Skipping empty modality: {modality}\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate statistics\n",
    "        values = df[modality].values\n",
    "        lower, upper = get_bootstrap_ci(values, ci_level)\n",
    "        \n",
    "        ci_results.append({\n",
    "            'Modality': modality,\n",
    "            'Metric': metric.upper(),  # R2, r, MSE, MAE\n",
    "            'Mean': np.mean(values).round(3),\n",
    "            'Median': np.median(values).round(3),\n",
    "            'Std': np.std(values).round(3),\n",
    "            'CI_lower': lower,\n",
    "            'CI_upper': upper\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "ci_df = pd.DataFrame(ci_results)\n",
    "output_path = '/rev1-analysis'\n",
    "save_dataframe_to_files(ci_df, output_path, f'bootstrap_{modality_name}_pls_CI')\n",
    "\n",
    "# Reorder columns for better readability\n",
    "column_order = ['Modality', 'Metric', 'Mean', 'Median', 'Std', 'CI_lower', 'CI_upper']\n",
    "ci_df = ci_df[column_order]\n",
    "\n",
    "print(\"=== Confidence Intervals ===\")\n",
    "print(ci_df)\n",
    "print(f\"\\nResults saved to: {output_path}\")\n",
    "\n",
    "# Print formatted summary\n",
    "for modality, group in ci_df.groupby('Modality'):\n",
    "    print(f\"\\n=== {modality} ===\")\n",
    "    for metric, metric_group in group.groupby('Metric'):\n",
    "        row = metric_group.iloc[0]  # Get first row for this metric\n",
    "        print(f\"{row['Metric']}:\")\n",
    "        print(f\"  Mean ± SD: {row['Mean']} ± {row['Std']}\")\n",
    "        print(f\"  Median: {row['Median']}\")\n",
    "        print(f\"  95% CI: [{row['CI_lower']}, {row['CI_upper']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1/T2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap T1w/T2w Stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['svr', 'eNet', 'xgb', 'rf']\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/stacking/g/T1_T2_whole_brain_target_pred_2nd_level_{algorithm}_train_fold_{fold}.csv')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/stacking/g/T1_T2_whole_brain_target_pred_2nd_level_{algorithm}_test_fold_{fold}.csv')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[algorithm] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[algorithm] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/t1_t2/T1_T2_whole_brain_target_pred_{algorithm}_train.csv', index=False)\n",
    "    g_five_folds_test[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/t1_t2/T1_T2_whole_brain_target_pred_{algorithm}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {algorithm} is', g_five_folds_train[algorithm].shape)\n",
    "    print(f'Shape of the test set in {algorithm} is', g_five_folds_test[algorithm].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g (SVR)\n",
    "g_five_folds_real_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/t1_t2/T1_T2_whole_brain_target_pred_svr_test.csv')\n",
    "g_real_to_pred_match = pd.DataFrame(g_five_folds_real_test.merge(g_five_folds_pred_test['eid'], on='eid'), columns = ['g_real_test', 'eid'])\n",
    "g_real_to_pred_match.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/t1_t2/g_real_to_pred_match_t1_t2_test.csv')\n",
    "print('Shape of g real test matched to g pred is', g_real_to_pred_match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot = 5000\n",
    "g_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/t1_t2/g_real_to_pred_match_t1_t2_test.csv')\n",
    "preds=[]\n",
    "\n",
    "bootstrap_results_dfs = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    g_pred = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/t1_t2/T1_T2_whole_brain_target_pred_{algorithm}_test.csv')\n",
    "    df = pd.concat([g_real, g_pred], axis=1).drop(columns=['eid', 'Unnamed: 0'])\n",
    "    df.columns = ['g_real_test', f'g_pred_t1_t2_{algorithm}_test']\n",
    "    \n",
    "    # Initialize a discionary for each algorithmn separately\n",
    "\n",
    "    bootstrap_results = {\n",
    "    'R2': [],\n",
    "    'r': [],\n",
    "    'MSE': [],\n",
    "    'MAE': []\n",
    "    }\n",
    "\n",
    "    for i in range(boot):\n",
    "        df_sample = df.sample(len(df),replace=True)\n",
    "        corr, _ = pearsonr(df_sample['g_real_test'], df_sample[f'g_pred_t1_t2_{algorithm}_test'])\n",
    "        r2 = r2_score(df_sample['g_real_test'], df_sample[f'g_pred_t1_t2_{algorithm}_test'])\n",
    "        mse = mean_squared_error(df_sample['g_real_test'], df_sample[f'g_pred_t1_t2_{algorithm}_test'])\n",
    "        mae = mean_absolute_error(df_sample['g_real_test'], df_sample[f'g_pred_t1_t2_{algorithm}_test'])\n",
    "\n",
    "        bootstrap_results['r'].append(corr)\n",
    "        bootstrap_results['R2'].append(r2)\n",
    "        bootstrap_results['MSE'].append(mse)\n",
    "        bootstrap_results['MAE'].append(mae)\n",
    "\n",
    "    for key in bootstrap_results:\n",
    "        bootstrap_results[key] = pd.DataFrame(bootstrap_results[key], columns=[f'{algorithm}_{key}'])\n",
    "        \n",
    "    bootstrap_results_dfs[algorithm] = bootstrap_results\n",
    "\n",
    "with open('/PLS/brain/stacking/BOOTSTRAP/t1_t2/t1_t2_bootstrap_results_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(bootstrap_results_dfs, f)\n",
    "        \n",
    "print(\"bootstrap_results_dfs dictionary was successfully saved as bootstrap_results_dfs.pkl\")\n",
    "\n",
    "bootstrap_svr = bootstrap_results_dfs['svr']\n",
    "bootstrap_enet = bootstrap_results_dfs['eNet']\n",
    "bootstrap_rf = bootstrap_results_dfs['rf']\n",
    "bootstrap_xgb = bootstrap_results_dfs['xgb']\n",
    "\n",
    "for metric in bootstrap_svr:\n",
    "    bootstrap_svr[metric] = pd.DataFrame(bootstrap_svr[metric])\n",
    "\n",
    "bootstrap_svr = pd.concat([bootstrap_svr['R2'].reset_index(drop=True), \n",
    "                    bootstrap_svr['r'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_enet:\n",
    "    bootstrap_enet[metric] = pd.DataFrame(bootstrap_enet[metric])\n",
    "\n",
    "bootstrap_enet = pd.concat([bootstrap_enet['R2'].reset_index(drop=True), \n",
    "                    bootstrap_enet['r'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_rf:\n",
    "    bootstrap_rf[metric] = pd.DataFrame(bootstrap_rf[metric])\n",
    "\n",
    "bootstrap_rf = pd.concat([bootstrap_rf['R2'].reset_index(drop=True), \n",
    "                    bootstrap_rf['r'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_xgb:\n",
    "    bootstrap_xgb[metric] = pd.DataFrame(bootstrap_xgb[metric])\n",
    "\n",
    "bootstrap_xgb = pd.concat([bootstrap_xgb['R2'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['r'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MAE'].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine algorithms\n",
    "bootstrap_fullres = pd.concat([\n",
    "    bootstrap_svr,\n",
    "    bootstrap_enet,\n",
    "    bootstrap_rf,\n",
    "    bootstrap_xgb], axis=1)\n",
    "\n",
    "bootstrap_fullres.to_csv('/PLS/brain/stacking/BOOTSTRAP/t1_t2/bootstrap_t1_t2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "bootstrap_fullres_t1t2_stacked_svr = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/t1_t2/bootstrap_t1_t2.csv')\n",
    "\n",
    "bootstrap_t1t2_R2 = bootstrap_fullres_t1t2_stacked_svr[['svr_R2', 'eNet_R2', 'rf_R2', 'xgb_R2']]\n",
    "bootstrap_t1t2_R2.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_t1t2_r = bootstrap_fullres_t1t2_stacked_svr[['svr_r', 'eNet_r', 'rf_r', 'xgb_r']]\n",
    "bootstrap_t1t2_r.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_t1t2_mse = bootstrap_fullres_t1t2_stacked_svr[['svr_MSE', 'eNet_MSE', 'rf_MSE', 'xgb_MSE']]\n",
    "bootstrap_t1t2_mse.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_t1t2_mae = bootstrap_fullres_t1t2_stacked_svr[['svr_MAE', 'eNet_MAE', 'rf_MAE', 'xgb_MAE']]\n",
    "bootstrap_t1t2_mae.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "# Get best algorithm\n",
    "bootstrap_t1t2_stacked_svr_r = bootstrap_t1t2_r['SVR']\n",
    "bootstrap_t1t2_stacked_svr_R2 = bootstrap_t1t2_R2['SVR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap T1w/T2w PLSR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap T1w PLSR: Prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_modalities = ['struct_fast', 'struct_sub_first',\n",
    "'struct_aseg_mean_intensity', 'struct_aseg_volume',\n",
    "'struct_ba_exvivo_area',  'struct_ba_exvivo_mean_thickness', 'struct_ba_exvivo_volume',\n",
    "'struct_a2009s_area', 'struct_a2009s_mean_thickness', 'struct_a2009s_volume',\n",
    "'struct_dkt_area', 'struct_dkt_mean_thickness', 'struct_dkt_volume',\n",
    "'struct_desikan_gw', 'struct_desikan_pial', 'struct_desikan_white_area', 'struct_desikan_white_mean_thickness', 'struct_desikan_white_volume',\n",
    "'struct_subsegmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for modality in t1_modalities:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/t1/fold_{fold}/g_pred/{modality}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/t1/fold_{fold}/g_pred/{modality}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[modality] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[modality] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/target_pred_{modality}_train.csv', index=False)\n",
    "    g_five_folds_test[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/target_pred_{modality}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {modality} is', g_five_folds_train[modality].shape)\n",
    "    print(f'Shape of the test set in {modality} is', g_five_folds_test[modality].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g for each modality\n",
    "g_real_to_pred_match_dict = {}\n",
    "g_five_folds_test_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "\n",
    "for modality in t1_modalities:\n",
    "\n",
    "    g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/target_pred_{modality}_test.csv')\n",
    "    g_real_to_pred_match_dict[modality] = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test, on='eid'))\n",
    "    g_real_to_pred_match_dict[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/g_real_to_pred_match_{modality}_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap T1w/T2w Whole-brain PLSR: Prepare files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1t2_whole_brain = ['T1_T2_whole_brain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat 5 folds\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for modality in t1t2_whole_brain:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/additional/fold_{fold}/g_pred/{modality}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/additional/fold_{fold}/g_pred/{modality}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[modality] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[modality] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/target_pred_{modality}_train.csv', index=False)\n",
    "    g_five_folds_test[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/target_pred_{modality}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {modality} is', g_five_folds_train[modality].shape)\n",
    "    print(f'Shape of the test set in {modality} is', g_five_folds_test[modality].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g for each modality\n",
    "g_real_to_pred_match_dict = {}\n",
    "g_five_folds_test_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "\n",
    "for modality in t1t2_whole_brain:\n",
    "\n",
    "    g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/target_pred_{modality}_test.csv')\n",
    "    g_real_to_pred_match_dict[modality] = pd.DataFrame(g_five_folds_test_real.merge(g_five_folds_pred_test, on='eid'))\n",
    "    g_real_to_pred_match_dict[modality].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/g_real_to_pred_match_{modality}_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap T1w/T2w PLSR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_t1t2_modalities = ['struct_fast', 'struct_sub_first',\n",
    "'struct_aseg_mean_intensity', 'struct_aseg_volume',\n",
    "'struct_ba_exvivo_area',  'struct_ba_exvivo_mean_thickness', 'struct_ba_exvivo_volume',\n",
    "'struct_a2009s_area', 'struct_a2009s_mean_thickness', 'struct_a2009s_volume',\n",
    "'struct_dkt_area', 'struct_dkt_mean_thickness', 'struct_dkt_volume',\n",
    "'struct_desikan_gw', 'struct_desikan_pial', 'struct_desikan_white_area', 'struct_desikan_white_mean_thickness', 'struct_desikan_white_volume',\n",
    "'struct_subsegmentation', 'T1_T2_whole_brain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot = 5000\n",
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "bootstrap_results_dfs = {mod: {metric: [] for metric in metrics} for mod in all_t1t2_modalities}\n",
    "    \n",
    "for modality in all_t1t2_modalities:\n",
    "    g_real_pls = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/g_real_to_pred_match_{modality}_test.csv')\n",
    "    g_pred_pls = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/target_pred_{modality}_test.csv')\n",
    "    g = g_real_pls.merge(g_pred_pls, on = 'eid').drop(columns=['Unnamed: 0', 'g predicted test_x'])\n",
    "    g = g.rename(columns={'g predicted test_y': f'g_predicted_pls_{modality}'})\n",
    "\n",
    "    bootstrap_results = {metric: [] for metric in metrics}\n",
    "        \n",
    "    for i in range(boot):\n",
    "        df_sample = g.sample(len(g),replace=True) \n",
    "\n",
    "        corr_pls, _ = pearsonr(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        r2_pls = r2_score(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        mse_pls = mean_squared_error(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "        mae_pls = mean_absolute_error(df_sample['g_real_test'], df_sample[f'g_predicted_pls_{modality}'])\n",
    "            \n",
    "        bootstrap_results['r'].append(corr_pls)\n",
    "        bootstrap_results['R2'].append(r2_pls)\n",
    "        bootstrap_results['MSE'].append(mse_pls)\n",
    "        bootstrap_results['MAE'].append(mae_pls)\n",
    "            \n",
    "    for key in bootstrap_results:\n",
    "        bootstrap_results[key] = pd.DataFrame(bootstrap_results[key], columns=[f'{modality}_{key}'])\n",
    "\n",
    "    bootstrap_results_dfs[modality] = bootstrap_results\n",
    "\n",
    "with open('/PLS/brain/stacking/BOOTSTRAP/T1T2_PLS_bootstrap_results_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(bootstrap_results_dfs, f)\n",
    "        \n",
    "print(\"bootstrap_results_dfs dictionary was successfully saved as bootstrap_results_dfs.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need to upload the saved bootstrapped object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/PLS/brain/stacking/BOOTSTRAP/T1T2_PLS_bootstrap_results_dfs.pkl', 'rb') as f:\n",
    "    bootstrap_results_dfs = pickle.load(f)\n",
    "metric_dfs = {metric: pd.DataFrame() for metric in ['R2', 'r', 'MSE', 'MAE']}\n",
    "for modality, results in bootstrap_results_dfs.items():\n",
    "    for metric, df in results.items():\n",
    "        if metric in metric_dfs:\n",
    "            metric_dfs[metric] = pd.concat([metric_dfs[metric], df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1t2_r2 = pd.concat([df['R2'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "t1t2_r = pd.concat([df['r'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "t1t2_mse = pd.concat([df['MSE'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "t1t2_mae = pd.concat([df['MAE'] for df in bootstrap_results_dfs.values()], axis=1)\n",
    "\n",
    "#t1t2_r2.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r2_t1t2_bootstrapped.csv', index=False)\n",
    "#t1t2_r.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r_t1t2_bootstrapped.csv', index=False)\n",
    "#t1t2_mse.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mse_t1t2_bootstrapped.csv', index=False)\n",
    "#t1t2_mae.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mae_t1t2_bootstrapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1t2_r2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r2_t1t2_bootstrapped.csv')\n",
    "t1t2_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/r_t1t2_bootstrapped.csv')\n",
    "t1t2_mse = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mse_t1t2_bootstrapped.csv')\n",
    "t1t2_mae = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/mae_t1t2_bootstrapped.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['R2', 'r', 'MSE', 'MAE']\n",
    "base_rename_dict = {\n",
    "\"struct_fast\":'FSL FAST',\n",
    "\"struct_sub_first\":'FSL FIRST',\n",
    "\"struct_aseg_mean_intensity\":'ASEG Mean Intensity',\n",
    "\"struct_aseg_volume\":'ASEG Volume',\n",
    "\"struct_ba_exvivo_area\":'BA ex-vivo Area',\n",
    "\"struct_ba_exvivo_mean_thickness\":'BA ex-vivo Mean Thickness',\n",
    "\"struct_ba_exvivo_volume\":'BA ex-vivo Volume',\n",
    "\"struct_a2009s_area\":'aparc a2009s Area',\n",
    "\"struct_a2009s_mean_thickness\":'aparc a2009s Mean Thickness',\n",
    "\"struct_a2009s_volume\":'aparc a2009s volume',\n",
    "\"struct_dkt_area\":'Desikan-Killiany-Tourville Area',\n",
    "\"struct_dkt_mean_thickness\":'Desikan-Killiany-Tourville Mean Thickness',\n",
    "\"struct_dkt_volume\":'Desikan-Killiany-Tourville volume',\n",
    "\"struct_desikan_gw\":'Desikan Grey/White Matter intensity',\n",
    "\"struct_desikan_pial\":'Desikan pial',\n",
    "\"struct_desikan_white_area\":'Desikan White Matter Area',\n",
    "\"struct_desikan_white_mean_thickness\":'Desikan White Matter Mean Thickness',\n",
    "\"struct_desikan_white_volume\":'Desikan White Matter volume',\n",
    "\"struct_subsegmentation\":'Subcortical Volumetric Subsegmentation',\n",
    "'T1_T2_whole_brain':'Whole-brain T1/T2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df, base_rename_dict, metric):\n",
    "    rename_dict = {f'{k}_{metric}': v for k, v in base_rename_dict.items()}\n",
    "    return df.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1t2_r2 = rename_columns(t1t2_r2, base_rename_dict, 'R2')\n",
    "t1t2_r = rename_columns(t1t2_r, base_rename_dict, 'r')\n",
    "t1t2_mse = rename_columns(t1t2_mse, base_rename_dict, 'MSE')\n",
    "t1t2_mae = rename_columns(t1t2_mae, base_rename_dict, 'MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics\n",
    "names_t1t2 = ['t1t2_r2','t1t2_r','t1t2_mse','t1t2_mae']\n",
    "dataframes_t1t2 = [t1t2_r2,t1t2_r,t1t2_mse,t1t2_mae]\n",
    "for df, name in zip(dataframes_t1t2, names_t1t2):\n",
    "    df.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/output/{name}_bootstrapped_renamed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CIs\n",
    "# ===== Configuration =====\n",
    "metrics = ['r2', 'r', 'mse', 'mae']\n",
    "ci_level = 0.95\n",
    "modality_name = 't1t2'\n",
    "base_path = f'/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/output'\n",
    "# ===== Process All Metrics =====\n",
    "ci_results = []\n",
    "\n",
    "for metric in metrics:\n",
    "    # Load bootstrap results\n",
    "    try:\n",
    "        df = pd.read_csv(f'{base_path}/{modality_name}_{metric}_bootstrapped_renamed.csv')\n",
    "        \n",
    "        # Drop Unnamed columns and any index columns\n",
    "        df = df.drop(columns=df.columns[df.columns.str.contains('^Unnamed|^index$', case=False)], errors='ignore')\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Warning: File not found for {modality_name}_{metric}\")\n",
    "        continue\n",
    "    \n",
    "    # Compute CIs for each modality (column)\n",
    "    for modality in df.columns:\n",
    "        # Skip if column is empty or all NA\n",
    "        if df[modality].isna().all():\n",
    "            print(f\"Skipping empty modality: {modality}\")\n",
    "            continue\n",
    "            \n",
    "        # Calculate statistics\n",
    "        values = df[modality].values\n",
    "        lower, upper = get_bootstrap_ci(values, ci_level)\n",
    "        \n",
    "        ci_results.append({\n",
    "            'Modality': modality,\n",
    "            'Metric': metric.upper(),  # R2, r, MSE, MAE\n",
    "            'Mean': np.mean(values).round(3),\n",
    "            'Median': np.median(values).round(3),\n",
    "            'Std': np.std(values).round(3),\n",
    "            'CI_lower': lower,\n",
    "            'CI_upper': upper\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame\n",
    "ci_df = pd.DataFrame(ci_results)\n",
    "output_path = '/rev1-analysis'\n",
    "save_dataframe_to_files(ci_df, output_path, f'bootstrap_{modality_name}_pls_CI')\n",
    "\n",
    "# Reorder columns for better readability\n",
    "column_order = ['Modality', 'Metric', 'Mean', 'Median', 'Std', 'CI_lower', 'CI_upper']\n",
    "ci_df = ci_df[column_order]\n",
    "\n",
    "print(\"=== Confidence Intervals ===\")\n",
    "print(ci_df)\n",
    "print(f\"\\nResults saved to: {output_path}\")\n",
    "\n",
    "# Print formatted summary\n",
    "for modality, group in ci_df.groupby('Modality'):\n",
    "    print(f\"\\n=== {modality} ===\")\n",
    "    for metric, metric_group in group.groupby('Metric'):\n",
    "        row = metric_group.iloc[0]  # Get first row for this metric\n",
    "        print(f\"{row['Metric']}:\")\n",
    "        print(f\"  Mean ± SD: {row['Mean']} ± {row['Std']}\")\n",
    "        print(f\"  Median: {row['Median']}\")\n",
    "        print(f\"  95% CI: [{row['CI_lower']}, {row['CI_upper']}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All modalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap all stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['svr', 'eNet', 'xgb', 'rf']\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "g_five_folds_train = {}\n",
    "g_five_folds_test = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    train = []\n",
    "    test = []\n",
    "    \n",
    "    for fold in folds:\n",
    "        g_pred_train = pd.read_csv(f'/PLS/brain/stacking/g/All_modalities_target_pred_2nd_level_{algorithm}_train_fold_{fold}.csv')\n",
    "        g_pred_test = pd.read_csv(f'/PLS/brain/stacking/g/All_modalities_target_pred_2nd_level_{algorithm}_test_fold_{fold}.csv')\n",
    "        \n",
    "        train.append(g_pred_train)\n",
    "        test.append(g_pred_test)\n",
    "        \n",
    "    g_five_folds_train[algorithm] = pd.concat(train, axis=0, ignore_index=True)\n",
    "    g_five_folds_test[algorithm] = pd.concat(test, axis=0, ignore_index=True)\n",
    "\n",
    "    g_five_folds_train[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/all_mod/All_modalities_target_pred_{algorithm}_train.csv', index=False)\n",
    "    g_five_folds_test[algorithm].to_csv(f'/PLS/brain/stacking/BOOTSTRAP/all_mod/All_modalities_target_pred_{algorithm}_test.csv', index=False)\n",
    "\n",
    "    print(f'Shape of the train set in {algorithm} is', g_five_folds_train[algorithm].shape)\n",
    "    print(f'Shape of the test set in {algorithm} is', g_five_folds_test[algorithm].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match real to predicted g\n",
    "g_five_folds_real_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/target_real_test.csv')\n",
    "g_five_folds_pred_test = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/all_mod/All_modalities_target_pred_svr_test.csv')\n",
    "g_real_to_pred_match = pd.DataFrame(g_five_folds_real_test.merge(g_five_folds_pred_test['eid'], on='eid'), columns = ['g_real_test', 'eid'])\n",
    "g_real_to_pred_match.to_csv(f'/PLS/brain/stacking/BOOTSTRAP/all_mod/g_real_to_pred_match_all_mod_test.csv')\n",
    "print('Shape of g real test matched to g pred is', g_real_to_pred_match.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrapping\n",
    "boot = 5000\n",
    "g_real = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/all_mod/g_real_to_pred_match_all_mod_test.csv')\n",
    "preds=[]\n",
    "\n",
    "bootstrap_results_dfs = {}\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    g_pred = pd.read_csv(f'/PLS/brain/stacking/BOOTSTRAP/all_mod/All_modalities_target_pred_{algorithm}_test.csv')\n",
    "    df = pd.concat([g_real, g_pred], axis=1).drop(columns=['eid', 'Unnamed: 0'])\n",
    "    df.columns = ['g_real_test', f'g_pred_all_mod_mri_{algorithm}_test']\n",
    "\n",
    "    bootstrap_results = {\n",
    "    'R2': [],\n",
    "    'r': [],\n",
    "    'MSE': [],\n",
    "    'MAE': []\n",
    "    }\n",
    "\n",
    "    for i in range(boot):\n",
    "        df_sample = df.sample(len(df),replace=True)\n",
    "        corr, _ = pearsonr(df_sample['g_real_test'], df_sample[f'g_pred_all_mod_mri_{algorithm}_test'])\n",
    "        r2 = r2_score(df_sample['g_real_test'], df_sample[f'g_pred_all_mod_mri_{algorithm}_test'])\n",
    "        mse = mean_squared_error(df_sample['g_real_test'], df_sample[f'g_pred_all_mod_mri_{algorithm}_test'])\n",
    "        mae = mean_absolute_error(df_sample['g_real_test'], df_sample[f'g_pred_all_mod_mri_{algorithm}_test'])\n",
    "\n",
    "        bootstrap_results['r'].append(corr)\n",
    "        bootstrap_results['R2'].append(r2)\n",
    "        bootstrap_results['MSE'].append(mse)\n",
    "        bootstrap_results['MAE'].append(mae)\n",
    "\n",
    "    for key in bootstrap_results:\n",
    "        bootstrap_results[key] = pd.DataFrame(bootstrap_results[key], columns=[f'{algorithm}_{key}'])\n",
    "        \n",
    "    bootstrap_results_dfs[algorithm] = bootstrap_results\n",
    "\n",
    "with open('/PLS/brain/stacking/BOOTSTRAP/all_mod/All_modalities_bootstrap_results_dfs.pkl', 'wb') as f:\n",
    "    pickle.dump(bootstrap_results_dfs, f)\n",
    "        \n",
    "print(\"bootstrap_results_dfs dictionary was successfully saved as bootstrap_results_dfs.pkl\")\n",
    "\n",
    "bootstrap_svr = bootstrap_results_dfs['svr']\n",
    "bootstrap_enet = bootstrap_results_dfs['eNet']\n",
    "bootstrap_rf = bootstrap_results_dfs['rf']\n",
    "bootstrap_xgb = bootstrap_results_dfs['xgb']\n",
    "\n",
    "for metric in bootstrap_svr:\n",
    "    bootstrap_svr[metric] = pd.DataFrame(bootstrap_svr[metric])\n",
    "\n",
    "bootstrap_svr = pd.concat([bootstrap_svr['R2'].reset_index(drop=True), \n",
    "                    bootstrap_svr['r'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_svr['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_enet:\n",
    "    bootstrap_enet[metric] = pd.DataFrame(bootstrap_enet[metric])\n",
    "\n",
    "bootstrap_enet = pd.concat([bootstrap_enet['R2'].reset_index(drop=True), \n",
    "                    bootstrap_enet['r'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_enet['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_rf:\n",
    "    bootstrap_rf[metric] = pd.DataFrame(bootstrap_rf[metric])\n",
    "\n",
    "bootstrap_rf = pd.concat([bootstrap_rf['R2'].reset_index(drop=True), \n",
    "                    bootstrap_rf['r'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_rf['MAE'].reset_index(drop=True)], axis=1)\n",
    "\n",
    "for metric in bootstrap_xgb:\n",
    "    bootstrap_xgb[metric] = pd.DataFrame(bootstrap_xgb[metric])\n",
    "\n",
    "bootstrap_xgb = pd.concat([bootstrap_xgb['R2'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['r'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MSE'].reset_index(drop=True), \n",
    "                    bootstrap_xgb['MAE'].reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine algorithms \n",
    "bootstrap_fullres = pd.concat([\n",
    "    bootstrap_svr,\n",
    "    bootstrap_enet,\n",
    "    bootstrap_rf,\n",
    "    bootstrap_xgb], axis=1)\n",
    "\n",
    "bootstrap_fullres.to_csv('/PLS/brain/stacking/BOOTSTRAP/all_mod/bootstrap_all_modalities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract metrics\n",
    "bootstrap_fullres_all_stacked_xgb = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/all_mod/bootstrap_all_modalities.csv')\n",
    "\n",
    "bootstrap_all_stack_R2 = bootstrap_fullres_all_stacked_xgb[['svr_R2', 'eNet_R2', 'rf_R2', 'xgb_R2']]\n",
    "bootstrap_all_stack_R2.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_all_stack_r = bootstrap_fullres_all_stacked_xgb[['svr_r', 'eNet_r', 'rf_r', 'xgb_r']]\n",
    "bootstrap_all_stack_r.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_all_stack_mse = bootstrap_fullres_all_stacked_xgb[['svr_MSE', 'eNet_MSE', 'rf_MSE', 'xgb_MSE']]\n",
    "bootstrap_all_stack_mse.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "bootstrap_all_stack_mae = bootstrap_fullres_all_stacked_xgb[['svr_MAE', 'eNet_MAE', 'rf_MAE', 'xgb_MAE']]\n",
    "\n",
    "bootstrap_all_stack_mae.columns = ['SVR', 'eNet', 'RF', 'XGB']\n",
    "\n",
    "# Extract best algorithm\n",
    "bootstrap_all_stacked_xgb_r = bootstrap_all_stack_r['XGB']\n",
    "bootstrap_all_stacked_xgb_R2 = bootstrap_all_stack_R2['XGB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CIs\n",
    "# Initialize results storage with additional statistics\n",
    "ci_results = {\n",
    "    'Algorithm': [],\n",
    "    'Metric': [],\n",
    "    'Mean': [],\n",
    "    'Median': [],\n",
    "    'Std': [],\n",
    "    'CI_lower': [],\n",
    "    'CI_upper': []\n",
    "}\n",
    "\n",
    "# Dictionary of bootstrap distributions\n",
    "bootstrap_dists = {\n",
    "    'R2': bootstrap_t1t2_R2,\n",
    "    'r': bootstrap_t1t2_r,\n",
    "    'MSE': bootstrap_t1t2_mse,\n",
    "    'MAE': bootstrap_t1t2_mae\n",
    "}\n",
    "\n",
    "for algorithm in ['SVR', 'eNet', 'RF', 'XGB']:\n",
    "    print(f\"\\n=== {algorithm} ===\")\n",
    "    \n",
    "    for metric, dist in bootstrap_dists.items():\n",
    "        # Get the specific algorithm's data\n",
    "        try:\n",
    "            alg_data = dist[algorithm]\n",
    "            \n",
    "            # Calculate statistics\n",
    "            mean_val = np.mean(alg_data).round(3)\n",
    "            median_val = np.median(alg_data).round(3)\n",
    "            std_val = np.std(alg_data).round(3)\n",
    "            lower, upper = get_bootstrap_ci(alg_data)\n",
    "            \n",
    "            # Store results\n",
    "            ci_results['Algorithm'].append(algorithm)\n",
    "            ci_results['Metric'].append(metric)\n",
    "            ci_results['Mean'].append(mean_val)\n",
    "            ci_results['Median'].append(median_val)\n",
    "            ci_results['Std'].append(std_val)\n",
    "            ci_results['CI_lower'].append(lower)\n",
    "            ci_results['CI_upper'].append(upper)\n",
    "            \n",
    "            # Print summary\n",
    "            print(f\"{metric}:\")\n",
    "            print(f\"  Mean ± SD: {mean_val} ± {std_val}\")\n",
    "            print(f\"  Median: {median_val}\")\n",
    "            print(f\"  95% CI: [{lower}, {upper}]\")\n",
    "            \n",
    "        except KeyError:\n",
    "            print(f\"Warning: {algorithm} not found in {metric} data\")\n",
    "            continue\n",
    "\n",
    "# Convert to DataFrame with proper column order\n",
    "ci_df = pd.DataFrame(ci_results)[['Algorithm', 'Metric', 'Mean', 'Median', 'Std', 'CI_lower', 'CI_upper']]\n",
    "\n",
    "# Save with timestamp\n",
    "output_path = '/rev1-analysis'\n",
    "ci_df.to_csv(os.path.join(output_path, 'bootstrap_t1t2_stacked_CI.csv'), index=False)\n",
    "ci_df.to_excel(\n",
    "    os.path.join(output_path, 'bootstrap_t1t2_stacked_CI.xlsx'),\n",
    "    index=False,\n",
    "    engine='openpyxl'\n",
    ")\n",
    "\n",
    "print(\"\\n=== Final Results ===\")\n",
    "print(ci_df)\n",
    "print(f\"\\nResults saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute CIs for PLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CIs for PLS\n",
    "common_metrics = ['r2', 'r', 'mse', 'mae']\n",
    "base_root = '/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack'\n",
    "modalities = ['dti', 'rs', 't1t2']\n",
    "output_path = '/rev1'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    print(f\"Creating output directory: {output_path}\")\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Then run your analysis\n",
    "for modality in modalities:\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"Processing modality: {modality.upper()}\")\n",
    "    print(f\"{'='*40}\")\n",
    "\n",
    "    if modality == 't1t2':\n",
    "        modality_path = os.path.join(base_root, 't1', 'output')\n",
    "    else:\n",
    "        modality_path = os.path.join(base_root, modality, 'output')\n",
    "    \n",
    "    # Run analysis\n",
    "    results = compute_and_save_bootstrap_results_1level(\n",
    "        metrics=common_metrics,\n",
    "        modality_name=modality,\n",
    "        base_path=modality_path,\n",
    "        output_path=output_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute CIs for stacked models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modalities\n",
    "modality_definitions = [\n",
    "    {\n",
    "        'name': 'dti',\n",
    "        'metrics': {\n",
    "            'R2': bootstrap_dti_R2,\n",
    "            'r': bootstrap_dti_r,\n",
    "            'MSE': bootstrap_dti_mse,\n",
    "            'MAE': bootstrap_dti_mae\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'rs',\n",
    "        'metrics': {\n",
    "            'R2': bootstrap_rs_R2,\n",
    "            'r': bootstrap_rs_r,\n",
    "            'MSE': bootstrap_rs_mse,\n",
    "            'MAE': bootstrap_rs_mae\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 't1t2',\n",
    "        'metrics': {\n",
    "            'R2': bootstrap_t1t2_R2,\n",
    "            'r': bootstrap_t1t2_r,\n",
    "            'MSE': bootstrap_t1t2_mse,\n",
    "            'MAE': bootstrap_t1t2_mae\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'all_stack',\n",
    "        'metrics': {\n",
    "            'R2': bootstrap_all_stack_R2,\n",
    "            'r': bootstrap_all_stack_r,\n",
    "            'MSE': bootstrap_all_stack_mse,\n",
    "            'MAE': bootstrap_all_stack_mae\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up any existing files before processing\n",
    "for modality in modality_definitions:\n",
    "    base_name = f\"bootstrap_{modality['name']}_CI\"\n",
    "    for ext in ['.csv', '.xlsx']:\n",
    "        file_path = os.path.join(output_path, base_name + ext)\n",
    "        try:\n",
    "            if os.path.exists(file_path):\n",
    "                os.remove(file_path)\n",
    "                print(f\"Removed old file: {file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not remove {file_path}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CIs for stacked models\n",
    "results = {}\n",
    "\n",
    "for modality in modality_definitions:\n",
    "    print(f\"\\nProcessing modality: {modality['name'].upper()}\")\n",
    "    \n",
    "    # Compute results for this modality\n",
    "    modality_results = compute_and_save_bootstrap_results_2level(\n",
    "        bootstrap_dists=modality['metrics'],\n",
    "        output_path=output_path,\n",
    "        modality_name=modality['name']\n",
    "    )\n",
    "    \n",
    "    # Store the DataFrame in results dictionary\n",
    "    if modality_results is not None:\n",
    "        results[modality['name']] = modality_results\n",
    "        print(f\"Successfully processed {modality['name']}\")\n",
    "    else:\n",
    "        print(f\"Failed to process {modality['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save files\n",
    "pd.DataFrame(bootstrap_all_stacked_xgb_r).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_all_stacked_xgb_r.csv', index=False)\n",
    "pd.DataFrame(bootstrap_t1t2_stacked_svr_r).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_t1t2_stacked_svr_r.csv', index=False)\n",
    "pd.DataFrame(bootstrap_rs_stacked_rf_r).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_rs_stacked_rf_r.csv', index=False)\n",
    "pd.DataFrame(bootstrap_dti_stacked_rf_r).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_dti_stacked_rf_r.csv', index=False)\n",
    "\n",
    "\n",
    "pd.DataFrame(bootstrap_all_stacked_xgb_R2).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_all_stacked_xgb_R2.csv', index=False)\n",
    "pd.DataFrame(bootstrap_t1t2_stacked_svr_R2).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_t1t2_stacked_svr_R2.csv', index=False)\n",
    "pd.DataFrame(bootstrap_rs_stacked_rf_R2).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_rs_stacked_rf_R2.csv', index=False)\n",
    "pd.DataFrame(bootstrap_dti_stacked_rf_R2).to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_dti_stacked_rf_R2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read files\n",
    "bootstrap_all_stacked_xgb_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_all_stacked_xgb_r.csv')\n",
    "bootstrap_t1t2_stacked_svr_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_t1t2_stacked_svr_r.csv')\n",
    "bootstrap_rs_stacked_rf_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_rs_stacked_rf_r.csv')\n",
    "bootstrap_dti_stacked_rf_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_dti_stacked_rf_r.csv')\n",
    "\n",
    "t1t2_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/output/t1t2_r_bootstrapped_renamed.csv')\n",
    "rs_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/rs_r_bootstrapped_renamed.csv')\n",
    "dti_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/dti_r_bootstrapped_renamed.csv')\n",
    "\n",
    "\n",
    "bootstrap_all_stacked_xgb_R2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_all_stacked_xgb_R2.csv')\n",
    "bootstrap_t1t2_stacked_svr_R2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_t1t2_stacked_svr_R2.csv')\n",
    "bootstrap_rs_stacked_rf_R2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_rs_stacked_rf_R2.csv')\n",
    "bootstrap_dti_stacked_rf_R2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/bootstrap_dti_stacked_rf_R2.csv')\n",
    "\n",
    "t1t2_r2 = pd.read_csv('//PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/output/t1t2_r2_bootstrapped_renamed.csv')\n",
    "rs_r2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/output/rs_r2_bootstrapped_renamed.csv')\n",
    "dti_r2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/output/dti_r2_bootstrapped_renamed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine and melt dataframes with r and R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson's r\n",
    "bootstrap_all_stacked_xgb_r = pd.DataFrame(bootstrap_all_stacked_xgb_r).rename(columns={'XGB': 'All MRI Modalities Stacked (XGB)'})\n",
    "bootstrap_t1t2_stacked_svr_r = pd.DataFrame(bootstrap_t1t2_stacked_svr_r).rename(columns={'SVR': 'T1w/T2w Structural Stacked (SVR)'})\n",
    "bootstrap_rs_stacked_rf_r = pd.DataFrame(bootstrap_rs_stacked_rf_r).rename(columns={'RF': 'rsMRI Stacked (RF)'})\n",
    "bootstrap_dti_stacked_rf_r = pd.DataFrame(bootstrap_dti_stacked_rf_r).rename(columns={'RF': 'dwMRI Stacked (RF)'})\n",
    "\n",
    "all_mod_plus_stacked_plot_bootstrapped_r = pd.concat([bootstrap_all_stacked_xgb_r, bootstrap_t1t2_stacked_svr_r,\n",
    "                                                             bootstrap_rs_stacked_rf_r, bootstrap_dti_stacked_rf_r,\n",
    "                                                             t1t2_r, rs_r, dti_r], axis = 1)\n",
    "#all_mod_plus_stacked_plot_bootstrapped_r.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/all_mod_plus_stacked_plot_bootstrapped_r.csv', index=False)\n",
    "\n",
    "# Melt\n",
    "all_mod_plus_stacked_plot_bootstrapped_r_melted = all_mod_plus_stacked_plot_bootstrapped_r.melt(var_name=\"modality\", value_name='r')\n",
    "#all_mod_plus_stacked_plot_bootstrapped_r_melted.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/all_mod_plus_stacked_plot_bootstrapped_r_melted.csv', index=False)\n",
    "all_mod_plus_stacked_plot_bootstrapped_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2\n",
    "bootstrap_all_stacked_xgb_R2 = pd.DataFrame(bootstrap_all_stacked_xgb_R2).rename(columns={'XGB': 'All MRI Modalities Stacked (XGB)'})\n",
    "bootstrap_t1t2_stacked_svr_R2 = pd.DataFrame(bootstrap_t1t2_stacked_svr_R2).rename(columns={'SVR': 'T1w/T2w Structural Stacked (SVR)'})\n",
    "bootstrap_rs_stacked_rf_R2 = pd.DataFrame(bootstrap_rs_stacked_rf_R2).rename(columns={'RF': 'rsMRI Stacked (RF)'})\n",
    "bootstrap_dti_stacked_rf_R2 = pd.DataFrame(bootstrap_dti_stacked_rf_R2).rename(columns={'RF': 'dwMRI Stacked (RF)'})\n",
    "\n",
    "all_mod_plus_stacked_plot_bootstrapped_R2 = pd.concat([bootstrap_all_stacked_xgb_R2, bootstrap_t1t2_stacked_svr_R2,\n",
    "                                                             bootstrap_rs_stacked_rf_R2, bootstrap_dti_stacked_rf_R2,\n",
    "                                                             t1t2_r2, rs_r2, dti_r2], axis = 1)\n",
    "#all_mod_plus_stacked_plot_bootstrapped_R2.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/all_mod_plus_stacked_plot_bootstrapped_R2.csv', index=False)\n",
    "\n",
    "# Melt\n",
    "all_mod_plus_stacked_plot_bootstrapped_R2_melted = all_mod_plus_stacked_plot_bootstrapped_R2.melt(var_name=\"modality\", value_name='R2')\n",
    "#all_mod_plus_stacked_plot_bootstrapped_R2_melted.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/all_mod_plus_stacked_plot_bootstrapped_R2_melted.csv', index=False)\n",
    "all_mod_plus_stacked_plot_bootstrapped_R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mod_plus_stacked_plot_bootstrapped_R2 = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/all_mod_plus_stacked_plot_bootstrapped_R2.csv')\n",
    "all_mod_plus_stacked_plot_bootstrapped_r_melted = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/all_mod_plus_stacked_plot_bootstrapped_r_melted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract and rename individual modalities for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual modalities: RS\n",
    "# r\n",
    "rs_bootstrapped_r = pd.concat([bootstrap_rs_stacked_rf_r,rs_r, \n",
    "                               bootstrap_all_stacked_xgb_r], axis = 1)\n",
    "dti_bootstrapped_r = pd.concat([bootstrap_dti_stacked_rf_r,dti_r, \n",
    "                                bootstrap_all_stacked_xgb_r], axis = 1)\n",
    "t1t2_bootstrapped_r = pd.concat([bootstrap_t1t2_stacked_svr_r,t1t2_r, \n",
    "                                 bootstrap_all_stacked_xgb_r], axis = 1)\n",
    "\n",
    "# R2\n",
    "rs_bootstrapped_r2 = pd.concat([bootstrap_rs_stacked_rf_R2,rs_r2, \n",
    "                                bootstrap_all_stacked_xgb_R2], axis = 1)\n",
    "dti_bootstrapped_r2 = pd.concat([bootstrap_dti_stacked_rf_R2,dti_r2, \n",
    "                                 bootstrap_all_stacked_xgb_R2], axis = 1)\n",
    "t1t2_bootstrapped_r2 = pd.concat([bootstrap_t1t2_stacked_svr_R2,t1t2_r2, \n",
    "                                bootstrap_all_stacked_xgb_R2], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename RS modalities for plotting\n",
    "rs_bootstrapped_r = pd.DataFrame(rs_bootstrapped_r).rename(columns={\n",
    "'XGB': 'All MRI Modalities Stacked (XGB)',\n",
    "'RF': 'rsMRI Stacked (RF)',\n",
    "'aparc MSA I Full correlation': 'aparc-I Functional Connectivity', \n",
    "'aparc a2009s MSA I Full correlation': 'aparc.a2009s-I Functional Connectivity',\n",
    "'Glasser MSA I Full correlation': 'Glasser-I Functional Connectivity',\n",
    "'Glasser MSA IV Full correlation': 'Glasser-IV Functional Connectivity',\n",
    "'Schaefer7n200p MSA I Full correlation': 'Schaefer200-I Functional Connectivity',\n",
    "'Schaefer7n500p MSA IV Full correlation': 'Schaefer500-IV Functional Connectivity',\n",
    "'Amplitudes 21 IC': '55 IC Amplitudes',\n",
    "'Amplitudes 55 IC': '21 IC Amplitudes',\n",
    "'Tangent matrices 21 IC': '21 IC Functional Connectivity',\n",
    "'Tangent matrices 55 IC': '55 IC Functional Connectivity'})\n",
    "\n",
    "rs_bootstrapped_r2 = pd.DataFrame(rs_bootstrapped_r2).rename(columns={\n",
    "'XGB': 'All MRI Modalities Stacked (XGB)',\n",
    "'RF': 'rsMRI Stacked (RF)',\n",
    "'aparc MSA I Full correlation': 'aparc-I Functional Connectivity', \n",
    "'aparc a2009s MSA I Full correlation': 'aparc.a2009s-I Functional Connectivity',\n",
    "'Glasser MSA I Full correlation': 'Glasser-I Functional Connectivity',\n",
    "'Glasser MSA IV Full correlation': 'Glasser-IV Functional Connectivity',\n",
    "'Schaefer7n200p MSA I Full correlation': 'Schaefer200-I Functional Connectivity',\n",
    "'Schaefer7n500p MSA IV Full correlation': 'Schaefer500-IV Functional Connectivity',\n",
    "'Amplitudes 21 IC': '55 IC Amplitudes',\n",
    "'Amplitudes 55 IC': '21 IC Amplitudes',\n",
    "'Tangent matrices 21 IC': '21 IC Functional Connectivity',\n",
    "'Tangent matrices 55 IC': '55 IC Functional Connectivity'})\n",
    "\n",
    "rs_bootstrapped_r.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/rs_bootstrapped_r_renamed.csv', index=False)\n",
    "rs_bootstrapped_r2.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/rs_bootstrapped_r2_renamed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename DTI modalities for plotting\n",
    "dti_bootstrapped_r = pd.DataFrame(dti_bootstrapped_r).rename(columns={\n",
    "'XGB': 'All MRI Modalities Stacked (XGB)',\n",
    "'RF': 'dwMRI Stacked (RF)',\n",
    "'aparc a2009s MSA I Connectome FA': 'aparc.a2009s-I FA',\n",
    "'aparc a2009s MSA I Connectome Mean Length': 'aparc.a2009s-I Mean Length',\n",
    "'aparc a2009s MSA I Connectome SIFT2': 'aparc.a2009s-I SIFT2',\n",
    "'aparc a2009s MSA I Connectome Streamline Count': 'aparc.a2009s-I Streamline Count',\n",
    "'aparc MSA I Connectome FA': 'aparc-I FA',\n",
    "'aparc MSA I Connectome Mean Length': 'aparc-I Mean Length',\n",
    "'aparc MSA I Connectome SIFT2': 'aparc-I SIFT2',\n",
    "'aparc MSA I Connectome Streamline Count': 'aparc-I Streamline Count',\n",
    "'Glasser MSA I Connectome FA': 'Glasser-I FA',\n",
    "'Glasser MSA I Connectome Mean Length': 'Glasser-I Mean Length',\n",
    "'Glasser MSA I Connectome SIFT2': 'Glasser-I SIFT2',\n",
    "'Glasser MSA I Connectome Streamline Count': 'Glasser-I Streamline Count',\n",
    "'Glasser MSA IV Connectome FA': 'Glasser-IV FA',\n",
    "'Glasser MSA IV Connectome Mean Length': 'Glasser-IV Mean Length',\n",
    "'Glasser MSA IV Connectome SIFT2': 'Glasser-IV SIFT2',\n",
    "'Glasser MSA IV Connectome Streamline Count': 'Glasser-IV Streamline Count',\n",
    "'Schaefer7n200p MSA I Connectome FA': 'Schaefer200-I FA',\n",
    "'Schaefer7n200p MSA I Connectome Mean Length': 'Schaefer200-I Mean Length',\n",
    "'Schaefer7n200p MSA I Connectome SIFT2': 'Schaefer200-I SIFT2',\n",
    "'Schaefer7n200p MSA I Connectome Streamline Count': 'Schaefer200-I Streamline Count',\n",
    "'Schaefer7n500p MSA IV Connectome FA': 'Schaefer500-IV FA',\n",
    "'Schaefer7n500p MSA IV Connectome Mean Length': 'Schaefer500-IV Mean Length',\n",
    "'Schaefer7n500p MSA IV Connectome SIFT2': 'Schaefer500-IV SIFT2',\n",
    "'Schaefer7n500p MSA IV Connectome Streamline Count': 'Schaefer500-IV Streamline Count',\n",
    "'FA Probabilistic': 'FA Prob.',\n",
    "'MD Probabilistic': 'MD Prob.',\n",
    "'L1 Probabilistic': 'L1 Prob.',\n",
    "'L2 Probabilistic': 'L2 Prob.',\n",
    "'L3 Probabilistic': 'L3 Prob.',\n",
    "'MO Probabilistic': 'MO Prob.',\n",
    "'OD Probabilistic': 'OD Prob.',\n",
    "'ICVF Probabilistic': 'ICVF Prob.',\n",
    "'ISOVF Probabilistic': 'ISOVF Prob.'\n",
    "})\n",
    "\n",
    "dti_bootstrapped_r2 = pd.DataFrame(dti_bootstrapped_r2).rename(columns={\n",
    "'XGB': 'All MRI Modalities Stacked (XGB)',\n",
    "'RF': 'dwMRI Stacked (RF)',\n",
    "'aparc a2009s MSA I Connectome FA': 'aparc.a2009s-I FA',\n",
    "'aparc a2009s MSA I Connectome Mean Length': 'aparc.a2009s-I Mean Length',\n",
    "'aparc a2009s MSA I Connectome SIFT2': 'aparc.a2009s-I SIFT2',\n",
    "'aparc a2009s MSA I Connectome Streamline Count': 'aparc.a2009s-I Streamline Count',\n",
    "'aparc MSA I Connectome FA': 'aparc-I FA',\n",
    "'aparc MSA I Connectome Mean Length': 'aparc-I Mean Length',\n",
    "'aparc MSA I Connectome SIFT2': 'aparc-I SIFT2',\n",
    "'aparc MSA I Connectome Streamline Count': 'aparc-I Streamline Count',\n",
    "'Glasser MSA I Connectome FA': 'Glasser-I FA',\n",
    "'Glasser MSA I Connectome Mean Length': 'Glasser-I Mean Length',\n",
    "'Glasser MSA I Connectome SIFT2': 'Glasser-I SIFT2',\n",
    "'Glasser MSA I Connectome Streamline Count': 'Glasser-I Streamline Count',\n",
    "'Glasser MSA IV Connectome FA': 'Glasser-IV FA',\n",
    "'Glasser MSA IV Connectome Mean Length': 'Glasser-IV Mean Length',\n",
    "'Glasser MSA IV Connectome SIFT2': 'Glasser-IV SIFT2',\n",
    "'Glasser MSA IV Connectome Streamline Count': 'Glasser-IV Streamline Count',\n",
    "'Schaefer7n200p MSA I Connectome FA': 'Schaefer200-I FA',\n",
    "'Schaefer7n200p MSA I Connectome Mean Length': 'Schaefer200-I Mean Length',\n",
    "'Schaefer7n200p MSA I Connectome SIFT2': 'Schaefer200-I SIFT2',\n",
    "'Schaefer7n200p MSA I Connectome Streamline Count': 'Schaefer200-I Streamline Count',\n",
    "'Schaefer7n500p MSA IV Connectome FA': 'Schaefer500-IV FA',\n",
    "'Schaefer7n500p MSA IV Connectome Mean Length': 'Schaefer500-IV Mean Length',\n",
    "'Schaefer7n500p MSA IV Connectome SIFT2': 'Schaefer500-IV SIFT2',\n",
    "'Schaefer7n500p MSA IV Connectome Streamline Count': 'Schaefer500-IV Streamline Count',\n",
    "'FA Probabilistic': 'FA Prob.',\n",
    "'MD Probabilistic': 'MD Prob.',\n",
    "'L1 Probabilistic': 'L1 Prob.',\n",
    "'L2 Probabilistic': 'L2 Prob.',\n",
    "'L3 Probabilistic': 'L3 Prob.',\n",
    "'MO Probabilistic': 'MO Prob.',\n",
    "'OD Probabilistic': 'OD Prob.',\n",
    "'ICVF Probabilistic': 'ICVF Prob.',\n",
    "'ISOVF Probabilistic': 'ISOVF Prob.'})\n",
    "\n",
    "dti_bootstrapped_r.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/dti_bootstrapped_r_renamed.csv', index=False)\n",
    "dti_bootstrapped_r2.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/dti_bootstrapped_r2_renamed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename T1/T2 modalities for plotting\n",
    "t1t2_bootstrapped_r = pd.DataFrame(t1t2_bootstrapped_r).rename(columns={\n",
    "'XGB': 'All MRI Modalities Stacked (XGB)',\n",
    "'SVR': 'T1w/T2w Structural Stacked (SVR)',\n",
    "'aparc a2009s Area': 'aparc.a2009s Area', \n",
    "'aparc a2009s Mean Thickness': 'aparc.a2009s Mean Thickness', \n",
    "'aparc a2009s volume': 'aparc.a2009s Volume', \n",
    "'Desikan-Killiany-Tourville Area': 'DKT Area',\n",
    "'Desikan-Killiany-Tourville Mean Thickness': 'DKT Mean Thickness',\n",
    "'Desikan-Killiany-Tourville volume': 'DKT Volume',\n",
    "'Desikan Grey/White Matter intensity': 'Desikan GM/WM Intensity',\n",
    "'Desikan pial': 'Desikan Pial',\n",
    "'Desikan White Matter Area': 'Desikan WM Area',\n",
    "'Desikan White Matter Mean Thickness': 'Desikan WM Mean Thickness',\n",
    "'Desikan White Matter volume': 'Desikan WM Volume',\n",
    "'Subcortical Volumetric Subsegmentation': 'Subcor. Volumetric Subsegment.',\n",
    "'ASEG volume':  \"ASEG Volume\"\n",
    "})\n",
    "\n",
    "t1t2_bootstrapped_r2 = pd.DataFrame(t1t2_bootstrapped_r2).rename(columns={\n",
    "'XGB': 'All MRI Modalities Stacked (XGB)',\n",
    "'SVR': 'T1w/T2w Structural Stacked (SVR)',\n",
    "'aparc a2009s Area': 'aparc.a2009s Area', \n",
    "'aparc a2009s Mean Thickness': 'aparc.a2009s Mean Thickness', \n",
    "'aparc a2009s volume': 'aparc.a2009s Volume', \n",
    "'Desikan-Killiany-Tourville Area': 'DKT Area',\n",
    "'Desikan-Killiany-Tourville Mean Thickness': 'DKT Mean Thickness',\n",
    "'Desikan-Killiany-Tourville volume': 'DKT Volume',\n",
    "'Desikan Grey/White Matter intensity': 'Desikan GM/WM Intensity',\n",
    "'Desikan pial': 'Desikan Pial',\n",
    "'Desikan White Matter Area': 'Desikan WM Area',\n",
    "'Desikan White Matter Mean Thickness': 'Desikan WM Mean Thickness',\n",
    "'Desikan White Matter volume': 'Desikan WM Volume',\n",
    "'Subcortical Volumetric Subsegmentation': 'Subcor. Volumetric Subsegment.',\n",
    "'Subcortical Volumetric Subsegmentation': 'Subcor. Volumetric Subsegment.'})\n",
    "\n",
    "t1t2_bootstrapped_r.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/t1t2_bootstrapped_r_renamed.csv', index=False)\n",
    "t1t2_bootstrapped_r2.to_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/t1t2_bootstrapped_r2_renamed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modalities: before renaming\n",
    "rs_parcellations = ['aparc MSA I Full correlation',\n",
    "       'aparc a2009s MSA I Full correlation',\n",
    "       'Glasser MSA I Full correlation',\n",
    "       'Glasser MSA IV Full correlation',\n",
    "       'Schaefer7n200p MSA I Full correlation',\n",
    "       'Schaefer7n500p MSA IV Full correlation']\n",
    "       \n",
    "rs_idp = ['Amplitudes 21 IC','Amplitudes 55 IC', 'Tangent matrices 21 IC','Tangent matrices 55 IC']    \n",
    "\n",
    "dti_parcellations = ['aparc a2009s MSA I Connectome FA',\n",
    "       'aparc a2009s MSA I Connectome Mean Length',\n",
    "       'aparc a2009s MSA I Connectome SIFT2',\n",
    "       'aparc a2009s MSA I Connectome Streamline Count',\n",
    "       'aparc MSA I Connectome FA', 'aparc MSA I Connectome Mean Length',\n",
    "       'aparc MSA I Connectome SIFT2',\n",
    "       'aparc MSA I Connectome Streamline Count',\n",
    "       'Glasser MSA I Connectome FA',\n",
    "       'Glasser MSA I Connectome Mean Length',\n",
    "       'Glasser MSA I Connectome SIFT2',\n",
    "       'Glasser MSA I Connectome Streamline Count',\n",
    "       'Glasser MSA IV Connectome FA',\n",
    "       'Glasser MSA IV Connectome Mean Length',\n",
    "       'Glasser MSA IV Connectome SIFT2',\n",
    "       'Glasser MSA IV Connectome Streamline Count',\n",
    "       'Schaefer7n200p MSA I Connectome FA',\n",
    "       'Schaefer7n200p MSA I Connectome Mean Length',\n",
    "       'Schaefer7n200p MSA I Connectome SIFT2',\n",
    "       'Schaefer7n200p MSA I Connectome Streamline Count',\n",
    "       'Schaefer7n500p MSA IV Connectome FA',\n",
    "       'Schaefer7n500p MSA IV Connectome Mean Length',\n",
    "       'Schaefer7n500p MSA IV Connectome SIFT2',\n",
    "       'Schaefer7n500p MSA IV Connectome Streamline Count']\n",
    "dti_idp = ['FA TBSS', 'FA Probabilistic', 'MD TBSS',\n",
    "       'MD Probabilistic', 'L1 TBSS', 'L1 Probabilistic', 'L2 TBSS',\n",
    "       'L2 Probabilistic', 'L3 TBSS', 'L3 Probabilistic', 'MO TBSS',\n",
    "       'MO Probabilistic', 'OD TBSS', 'OD Probabilistic', 'ICVF TBSS',\n",
    "       'ICVF Probabilistic', 'ISOVF TBSS', 'ISOVF Probabilistic']\n",
    "t1t2_modalities = ['FSL FAST', 'FSL FIRST',\n",
    "       'ASEG Mean Thickness', 'ASEG Volume', 'BA ex-vivo Area',\n",
    "       'BA ex-vivo Mean Thickness', 'BA ex-vivo Volume',\n",
    "       'aparc a2009s Area', 'aparc a2009s Mean Thickness',\n",
    "       'aparc a2009s volume', 'Desikan-Killiany-Tourville Area',\n",
    "       'Desikan-Killiany-Tourville Mean Thickness',\n",
    "       'Desikan-Killiany-Tourville volume',\n",
    "       'Desikan Grey/White Matter intensity', 'Desikan pial',\n",
    "       'Desikan White Matter Area', 'Desikan White Matter Mean Thickness',\n",
    "       'Desikan White Matter volume',\n",
    "       'Subcortical Volumetric Subsegmentation', 'Whole-brain T1/T2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL PLOT: All modalities on one plot, three subplots, only r, no stacked\n",
    "\n",
    "________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_bootstrapped_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/rs/rs_bootstrapped_r_renamed.csv')\n",
    "dti_bootstrapped_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/dti/dti_bootstrapped_r_renamed.csv')\n",
    "t1t2_bootstrapped_r = pd.read_csv('/PLS/brain/stacking/BOOTSTRAP/pls_vs_stack/t1/t1t2_bootstrapped_r_renamed.csv')\n",
    "# Rename some vars for plots\n",
    "t1t2_bootstrapped_r_short_names = t1t2_bootstrapped_r.rename(columns={'Subcor. Volumetric Subsegment.': 'Subcortical Volumetric Subseg.',\n",
    "                                                                      'ASEG Mean Thickness': 'ASEG Mean Intensity'})\n",
    "rs_bootstrapped_r_short_names = rs_bootstrapped_r.rename(columns=lambda x: x.replace('Functional Connectivity', 'Func. Connectivity') if 'Functional Connectivity' in x else x)\n",
    "#Rename modalities\n",
    "rs_bootstrapped_r_melt = rs_bootstrapped_r_short_names.melt(var_name=\"modality\", value_name='r')\n",
    "rs_bootstrapped_r_melt['mod'] = 'rs'\n",
    "dti_bootstrapped_r_melt = dti_bootstrapped_r.melt(var_name=\"modality\", value_name='r')\n",
    "dti_bootstrapped_r_melt['mod'] = 'dti'\n",
    "t1t2_bootstrapped_r_melt = t1t2_bootstrapped_r_short_names.melt(var_name=\"modality\", value_name='r')\n",
    "t1t2_bootstrapped_r_melt['mod'] = 't1t2'\n",
    "#all_bootstrapped_r = pd.concat([rs_bootstrapped_r_melt, dti_bootstrapped_r_melt, t1t2_bootstrapped_r_melt])\n",
    "#all_bootstrapped_r_melt = all_bootstrapped_r.melt(id_vars=['modality', 'mod'], var_name='variable', value_name='value').drop(columns = 'variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modalities: after renaming\n",
    "rs_parcellations = ['aparc-I Func. Connectivity',\n",
    "       'aparc.a2009s-I Func. Connectivity',\n",
    "       'Glasser-I Func. Connectivity',\n",
    "       'Glasser-IV Func. Connectivity',\n",
    "       'Schaefer200-I Func. Connectivity',\n",
    "       'Schaefer500-IV Func. Connectivity']\n",
    "       \n",
    "rs_idp = ['55 IC Amplitudes','21 IC Amplitudes', '21 IC Func. Connectivity','55 IC Func. Connectivity']    \n",
    "\n",
    "dti_parcellations = ['aparc.a2009s-I FA',\n",
    "       'aparc.a2009s-I Mean Length', 'aparc.a2009s-I SIFT2',\n",
    "       'aparc.a2009s-I Streamline Count', 'aparc-I FA', 'aparc-I Mean Length',\n",
    "       'aparc-I SIFT2', 'aparc-I Streamline Count', 'Glasser-I FA',\n",
    "       'Glasser-I Mean Length', 'Glasser-I SIFT2',\n",
    "       'Glasser-I Streamline Count', 'Glasser-IV FA', 'Glasser-IV Mean Length',\n",
    "       'Glasser-IV SIFT2', 'Glasser-IV Streamline Count', 'Schaefer200-I FA',\n",
    "       'Schaefer200-I Mean Length', 'Schaefer200-I SIFT2',\n",
    "       'Schaefer200-I Streamline Count', 'Schaefer500-IV FA',\n",
    "       'Schaefer500-IV Mean Length', 'Schaefer500-IV SIFT2',\n",
    "       'Schaefer500-IV Streamline Count']\n",
    "dti_idp = ['FA TBSS', 'FA Prob.', 'MD TBSS', 'MD Prob.',\n",
    "       'L1 TBSS', 'L1 Prob.', 'L2 TBSS', 'L2 Prob.', 'L3 TBSS', 'L3 Prob.',\n",
    "       'MO TBSS', 'MO Prob.', 'OD TBSS', 'OD Prob.', 'ICVF TBSS', 'ICVF Prob.',\n",
    "       'ISOVF TBSS', 'ISOVF Prob.']\n",
    "t1t2_modalities = ['FSL FAST', 'FSL FIRST',\n",
    "       'ASEG Mean Intensity', 'ASEG Volume', 'BA ex-vivo Area',\n",
    "       'BA ex-vivo Mean Thickness', 'BA ex-vivo Volume', 'aparc.a2009s Area',\n",
    "       'aparc.a2009s Mean Thickness', 'aparc.a2009s Volume', 'DKT Area',\n",
    "       'DKT Mean Thickness', 'DKT Volume', 'Desikan GM/WM Intensity',\n",
    "       'Desikan Pial', 'Desikan WM Area', 'Desikan WM Mean Thickness',\n",
    "       'Desikan WM Volume', 'Subcortical Volumetric Subseg.',\n",
    "       'Whole-brain T1/T2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color map\n",
    "color_mapping_violin = {}\n",
    "for modality in rs_parcellations:\n",
    "    color_mapping_violin[modality] = 'rgba(121, 175, 151, 1.0)' #mediumaquamarine\n",
    "for modality in rs_idp:\n",
    "    color_mapping_violin[modality] = 'rgba(75, 111, 90, 0.6)' #seagreen\n",
    "\n",
    "for modality in dti_parcellations:\n",
    "    color_mapping_violin[modality] = 'rgba(31, 120, 180, 1.0)' #steelblue\n",
    "for modality in dti_idp:\n",
    "    color_mapping_violin[modality] = 'rgba(0, 161, 213, 0.6)' #dodgerblue\n",
    "for modality in t1t2_modalities:\n",
    "    color_mapping_violin[modality] = 'rgba(247, 200, 158, 1.0)' #wheat\n",
    "\n",
    "color_mapping_violin['rsMRI Stacked'] = 'rgba(210, 105, 105, 0.6)' #salmon\n",
    "color_mapping_violin['dwMRI Stacked'] = 'rgba(106, 101, 153, 0.6)' #blue\n",
    "color_mapping_violin['sMRI Stacked'] = 'rgba(223, 143, 68, 1.0)'  #darkgoldenrod\n",
    "color_mapping_violin['MRI Modalities Stacked'] = 'rgba(178, 71, 69, 1.0)' #Crimson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color map using 6-digit hex codes\n",
    "color_mapping_violin = {}\n",
    "\n",
    "# rsMRI - Greens/Teals\n",
    "for modality in rs_parcellations:\n",
    "    color_mapping_violin[modality] = 'rgba(15, 77, 18, 1.0)'\n",
    "for modality in rs_idp:\n",
    "    color_mapping_violin[modality] = 'rgba(17, 173, 25, 1.0)'\n",
    "\n",
    "# dwMRI - Blues\n",
    "for modality in dti_parcellations:\n",
    "    color_mapping_violin[modality] = 'rgba(37, 95, 122, 1.0)'\n",
    "for modality in dti_idp:\n",
    "    color_mapping_violin[modality] = 'rgba(62, 161, 207, 1.0)'\n",
    "\n",
    "# sMRI - Warm tones\n",
    "for modality in t1t2_modalities:\n",
    "    color_mapping_violin[modality] = 'rgba(201, 168, 20, 1.0)'\n",
    "\n",
    "color_mapping_violin['rsMRI Stacked'] = 'rgba(210, 105, 105, 0.6)' #salmon\n",
    "color_mapping_violin['dwMRI Stacked'] = 'rgba(106, 101, 153, 0.6)' #blue\n",
    "color_mapping_violin['sMRI Stacked'] = 'rgba(223, 143, 68, 1.0)'  #darkgoldenrod\n",
    "color_mapping_violin['MRI Modalities Stacked'] = 'rgba(178, 71, 69, 1.0)' #Crimson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data frames\n",
    "rs_bootstrapped_r_melt_sort = rs_bootstrapped_r_melt.sort_values(by='r', ascending=True).reset_index(drop=True)\n",
    "rs_bootstrapped_r_melt_sort = rs_bootstrapped_r_melt_sort[rs_bootstrapped_r_melt_sort['modality'] != 'All MRI Modalities Stacked (XGB)']\n",
    "rs_bootstrapped_r_melt_sort = rs_bootstrapped_r_melt_sort[rs_bootstrapped_r_melt_sort['modality'] != 'rsMRI Stacked (RF)']\n",
    "\n",
    "dti_bootstrapped_r_melt_sort = dti_bootstrapped_r_melt.sort_values(by='r', ascending=True).reset_index(drop=True)\n",
    "dti_bootstrapped_r_melt_sort = dti_bootstrapped_r_melt_sort[dti_bootstrapped_r_melt_sort['modality'] != 'All MRI Modalities Stacked (XGB)']\n",
    "dti_bootstrapped_r_melt_sort = dti_bootstrapped_r_melt_sort[dti_bootstrapped_r_melt_sort['modality'] != 'dwMRI Stacked (RF)']\n",
    "\n",
    "t1t2_bootstrapped_r_melt_sort = t1t2_bootstrapped_r_melt.sort_values(by='r', ascending=True).reset_index(drop=True)\n",
    "t1t2_bootstrapped_r_melt_sort = t1t2_bootstrapped_r_melt_sort[t1t2_bootstrapped_r_melt_sort['modality'] != 'All MRI Modalities Stacked (XGB)']\n",
    "t1t2_bootstrapped_r_melt_sort = t1t2_bootstrapped_r_melt_sort[t1t2_bootstrapped_r_melt_sort['modality'] != 'T1w/T2w Structural Stacked (SVR)']\n",
    "\n",
    "# Calculate median values for each modality and ensure the order matches the sorted data\n",
    "rs_median = rs_bootstrapped_r_melt_sort.groupby('modality')['r'].median().reset_index()\n",
    "rs_median = rs_median.set_index('modality').loc[rs_bootstrapped_r_melt_sort['modality'].unique()].reset_index() #loc[0:2,:]\n",
    "rs_median = pd.concat([rs_median.head(1), rs_median.tail(1)]).reset_index(drop=True)\n",
    "\n",
    "dti_median = dti_bootstrapped_r_melt_sort.groupby('modality')['r'].median().reset_index()\n",
    "dti_median = dti_median.set_index('modality').loc[dti_bootstrapped_r_melt_sort['modality'].unique()].reset_index() #.loc[0:2,:]\n",
    "dti_median = pd.concat([dti_median.head(1), dti_median.tail(1)]).reset_index(drop=True)\n",
    "\n",
    "t1t2_median = t1t2_bootstrapped_r_melt_sort.groupby('modality')['r'].median().reset_index()\n",
    "t1t2_median = t1t2_median.set_index('modality').loc[t1t2_bootstrapped_r_melt_sort['modality'].unique()].reset_index() #.loc[0:2,:]\n",
    "t1t2_median = pd.concat([t1t2_median.head(1), t1t2_median.tail(1)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violins\n",
    "fig = make_subplots(rows=1, cols=3, shared_yaxes=False, subplot_titles=(\"dwMRI\", \"rsMRI\", \"sMRI\"),\n",
    "                    horizontal_spacing=0.27)\n",
    "\n",
    "# Define a function to add half-inverted violin plots\n",
    "def add_half_violin_trace(fig, data, row, col, color_mapping):\n",
    "    for modality in data['modality'].unique():\n",
    "        subset = data[data['modality'] == modality]\n",
    "        fig.add_trace(\n",
    "            go.Violin(x=subset['r'], y=subset['modality'], orientation='h', side='positive', name=modality,\n",
    "                      box_visible=False, meanline_visible=False, points=False, line_color=color_mapping.get(modality, 'black'), fillcolor=color_mapping.get(modality, 'black'), line_width=1.2, showlegend=False),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "# Add half-inverted violin plots for each modality\n",
    "add_half_violin_trace(fig, dti_bootstrapped_r_melt_sort, 1, 1, color_mapping_violin)\n",
    "add_half_violin_trace(fig, rs_bootstrapped_r_melt_sort, 1, 2, color_mapping_violin)\n",
    "add_half_violin_trace(fig, t1t2_bootstrapped_r_melt_sort, 1, 3, color_mapping_violin)\n",
    "\n",
    "\n",
    "# Add scatter plots to show the median values\n",
    "def add_median_trace(fig, medians, row, col):\n",
    "    for i, modality in enumerate(medians['modality']):\n",
    "        median_value = medians.loc[i, 'r']\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[median_value],\n",
    "                y=[modality],\n",
    "                mode='markers+text', #markers+text #lines+text\n",
    "                marker=dict(color='grey', size=3),\n",
    "                #line=dict(color='black', width=2),\n",
    "                showlegend=False,\n",
    "                text=[f\"{median_value:.2f}\"],\n",
    "                textposition=\"bottom center\", #middle left \n",
    "                textfont=dict(size=23,family=\"DejaVu Sans\", color='black')\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "\n",
    "# Add median traces for each subplot\n",
    "add_median_trace(fig, dti_median, 1, 1)\n",
    "add_median_trace(fig, rs_median, 1, 2)\n",
    "add_median_trace(fig, t1t2_median, 1, 3)\n",
    "\n",
    "# Create custom legend\n",
    "legend_elements = [\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(75, 111, 90, 0.6)', width=6), name='rsMRI IDPs', showlegend=True),\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(121, 175, 151, 1.0)', width=6), name='rsMRI Parcellations', showlegend=True),\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(0, 161, 213, 0.6)', width=6), name='dwMRI IDPs', showlegend=True),\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(31, 120, 180, 1.0)', width=6), name='dwMRI Parcellations', showlegend=True),\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(247, 200, 158, 1.0)', width=6), name='sMRI', showlegend=True),\n",
    "\n",
    "]\n",
    "\n",
    "# Add custom legend to the figure\n",
    "for trace in legend_elements:\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    fig.update_xaxes(showline=True, linewidth=0.5, linecolor='grey', mirror=True, dtick=0.1,\n",
    "                     range=[0.05, 0.35], row=1, col=i, tickangle=-50, tickfont=dict(size=33, family=\"DejaVu Sans\", color='black'),\n",
    "                    tickvals=[0.1, 0.15, 0.2, 0.25, 0.3], ticktext=['0.1', '0.15', '0.2', '0.25', '0.3'])\n",
    "    fig.update_yaxes(showline=True, linewidth=0.5, linecolor='grey', mirror=True, row=1, col=i, tickfont=dict(size=15, family=\"DejaVu Sans\", color='black'))\n",
    "\n",
    "\n",
    "# Customize y-axis labels for each subplot\n",
    "fig.update_yaxes(tickfont=dict(size=22,family=\"DejaVu Sans\", color='black'), row=1, col=1) #, family='Arial'\n",
    "fig.update_yaxes(tickfont=dict(size=26.5,family=\"DejaVu Sans\", color='black'), row=1, col=2) #, family='Courier New'\n",
    "fig.update_yaxes(tickfont=dict(size=28,family=\"DejaVu Sans\", color='black'), row=1, col=3) #, family='Times New Roman' #, side='right'\n",
    "                 \n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=6.0*300,  # 5.85 inches (half of A4 height) in pixels (300 dpi)\n",
    "    width=7.3*300,   # 8.27 inches (A4 width) in pixels (300 dpi)\n",
    "    #height=1100, width=1800,  # height=1100, width=1800,\n",
    "    plot_bgcolor='white', paper_bgcolor='white',\n",
    "    showlegend=True,\n",
    "\n",
    "    title=dict(\n",
    "        text=\"Bootstrap Distribution of Pearson <i>r</i>: PLSR\",\n",
    "        x=0.5,\n",
    "        y=0.95,\n",
    "        xanchor='center',\n",
    "        font=dict(size=55, family=\"DejaVu Sans\", color='black')\n",
    "    ),\n",
    "     margin=dict(t=250),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.15,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        font=dict(size=45, family=\"DejaVu Sans\", color='black')),\n",
    "    annotations=[\n",
    "        dict(\n",
    "            text=\"dwMRI\", x=0.08, y=1, xref=\"paper\", yref=\"paper\",\n",
    "            showarrow=False, font=dict(size=40, family=\"DejaVu Sans\", color='black')),\n",
    "        dict(\n",
    "            text=\"rsMRI\", x=0.498, y=1, xref=\"paper\", yref=\"paper\",\n",
    "            showarrow=False, font=dict(size=40, family=\"DejaVu Sans\", color='black')),\n",
    "        dict(\n",
    "            text=\"sMRI\", x=0.915, y=1, xref=\"paper\", yref=\"paper\",\n",
    "            showarrow=False, font=dict(size=40, family=\"DejaVu Sans\", color='black'))\n",
    "],\n",
    ")\n",
    "\n",
    "# Add a red marker at minimum x-value (0.05)\n",
    "for col in [1, 2, 3]:\n",
    "    fig.add_vline(\n",
    "        x=0.05, \n",
    "        line=dict(color=\"red\", width=2, dash=\"dot\"),\n",
    "        opacity=0.8,\n",
    "        row=1,\n",
    "        col=col,\n",
    "        annotation_text=\"0\",\n",
    "        annotation_position=\"bottom right\",\n",
    "        annotation_font=dict(\n",
    "            size=24,    \n",
    "            #family=\"DejaVu Sans\",\n",
    "            color=\"#660000\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "pio.write_image(fig, '/figures/Fig3b.png', scale=1, format='png') # width=8.27*400, height=6.85*400,  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CI line plots\n",
    "fig = make_subplots(rows=1, cols=3, shared_yaxes=False, subplot_titles=(\"dwMRI\", \"rsMRI\", \"sMRI\"),\n",
    "                    horizontal_spacing=0.27)\n",
    "\n",
    "# New function to add CI lines and median markers\n",
    "def add_ci_trace(fig, data, row, col, color_mapping):\n",
    "    modalities = data['modality'].unique()\n",
    "    for i, modality in enumerate(modalities):\n",
    "        subset = data[data['modality'] == modality]\n",
    "        values = subset['r']\n",
    "        \n",
    "        median = np.median(values)\n",
    "        lower, upper = get_bootstrap_ci(values)\n",
    "        \n",
    "        # Main CI line with end markers\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[lower, upper],\n",
    "                y=[modality, modality],\n",
    "                mode='lines+markers',\n",
    "                line=dict(color=color_mapping.get(modality, 'black'), dash='longdash', width=3),\n",
    "                marker=dict(\n",
    "                    color=color_mapping.get(modality, 'black'),\n",
    "                    size=8,\n",
    "                    symbol='line-ns-open',  # Vertical line markers\n",
    "                    line=dict(width=1.5),\n",
    "                    opacity=1\n",
    "                ),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        # Median marker\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[median],\n",
    "                y=[modality],\n",
    "                mode='markers+text',\n",
    "                marker=dict(\n",
    "                    symbol= 'line-ns', #'line-ns-open',\n",
    "                    color=color_mapping.get(modality, 'black'),#'#660000',\n",
    "                    size=4,\n",
    "                    line=dict(color='#660000', width=2),\n",
    "                    opacity=1\n",
    "                ),\n",
    "                #text=[f\"{median:.2f}\"] if (i == 0 or i == len(modalities)-1) else None,\n",
    "                #textposition=\"bottom center\",\n",
    "                #textfont=dict(size=12, family=\"DejaVu Sans\", color='black'),\n",
    "                showlegend=False\n",
    "            ),\n",
    "            row=row, col=col\n",
    "        )\n",
    "        \n",
    "        # Annotate first/last modalities\n",
    "        if i == 0 or i == len(modalities)-1:\n",
    "            # Left CI annotation\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[lower],\n",
    "                    y=[modality],\n",
    "                    mode='text',\n",
    "                    text=[f\"{lower:.2f}\"],\n",
    "                    textposition=\"bottom left\",\n",
    "                    textfont=dict(size=22, family=\"DejaVu Sans\", color='black'),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "            # Right CI annotation\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[upper],\n",
    "                    y=[modality],\n",
    "                    mode='text',\n",
    "                    text=[f\"{upper:.2f}\"],\n",
    "                    textposition=\"bottom right\",\n",
    "                    textfont=dict(size=22, family=\"DejaVu Sans\", color='black'),\n",
    "                    showlegend=False\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "# Replace violin plots with CI lines\n",
    "add_ci_trace(fig, dti_bootstrapped_r_melt_sort, 1, 1, color_mapping_violin)\n",
    "add_ci_trace(fig, rs_bootstrapped_r_melt_sort, 1, 2, color_mapping_violin)\n",
    "add_ci_trace(fig, t1t2_bootstrapped_r_melt_sort, 1, 3, color_mapping_violin)\n",
    "\n",
    "# Create custom legend\n",
    "legend_elements = [\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(62, 161, 207, 1.0)', width=6), name='dwMRI IDPs', showlegend=True),  #'rgba(0, 161, 213, 0.6)'\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(37, 95, 122, 1.0)', width=6), name='dwMRI Parcellations', showlegend=True), #'rgba(31, 120, 180, 1.0)'\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(17, 173, 25, 1.0)', width=6), name='rsMRI IDPs', showlegend=True), #'rgba(75, 111, 90, 0.6)'\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(15, 77, 18, 1.0)', width=6), name='rsMRI Parcellations', showlegend=True), #'rgba(121, 175, 151, 1.0)'\n",
    "    go.Scatter(x=[None], y=[None], mode='lines', line=dict(color='rgba(201, 168, 20, 1.0)', width=6), name='sMRI', showlegend=True), #'rgba(247, 200, 158, 1.0)'\n",
    "]\n",
    "\n",
    "# Add custom legend to the figure\n",
    "for trace in legend_elements:\n",
    "    fig.add_trace(trace)\n",
    "\n",
    "for i in range(1, 4):\n",
    "    fig.update_xaxes(showline=True, linewidth=0.5, linecolor='grey', mirror=True, dtick=0.1,\n",
    "                     range=[-0.01, 0.38], row=1, col=i, tickangle=-50, tickfont=dict(size=33, family=\"DejaVu Sans\", color='black'),\n",
    "                    tickvals=[-0.01, 0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.30, 0.35], ticktext=['', '0', '0.05', '0.1', '0.15', '0.2', '0.25', '0.30', '0.35'])\n",
    "    fig.update_yaxes(showline=True, linewidth=0.5, linecolor='grey', mirror=True, row=1, col=i, tickfont=dict(size=15, family=\"DejaVu Sans\", color='black'))\n",
    "\n",
    "\n",
    "# Customize y-axis labels for each subplot\n",
    "fig.update_yaxes(tickfont=dict(size=22,family=\"DejaVu Sans\", color='black'), row=1, col=1) #, family='Arial'\n",
    "fig.update_yaxes(tickfont=dict(size=26.5,family=\"DejaVu Sans\", color='black'), row=1, col=2) #, family='Courier New'\n",
    "fig.update_yaxes(tickfont=dict(size=28,family=\"DejaVu Sans\", color='black'), row=1, col=3) #, family='Times New Roman' #, side='right'\n",
    "                 \n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=6.0*300,  # 5.85 inches (half of A4 height) in pixels (300 dpi)\n",
    "    width=7.3*300,   # 8.27 inches (A4 width) in pixels (300 dpi)\n",
    "    #height=1100, width=1800,  # height=1100, width=1800,\n",
    "    plot_bgcolor='white', paper_bgcolor='white',\n",
    "    showlegend=True,\n",
    "\n",
    "    title=dict(\n",
    "        text=\"Bootstrap Distribution of Pearson <i>r</i>: PLSR\",\n",
    "        x=0.5,\n",
    "        y=0.95,\n",
    "        xanchor='center',\n",
    "        font=dict(size=55, family=\"DejaVu Sans\", color='black')\n",
    "    ),\n",
    "     margin=dict(t=250),\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=-0.15,\n",
    "        xanchor=\"center\",\n",
    "        x=0.5,\n",
    "        font=dict(size=45, family=\"DejaVu Sans\", color='black')),\n",
    "    annotations=[\n",
    "        dict(\n",
    "            text=\"dwMRI\", x=0.08, y=1, xref=\"paper\", yref=\"paper\",\n",
    "            showarrow=False, font=dict(size=40, family=\"DejaVu Sans\", color='black')),\n",
    "        dict(\n",
    "            text=\"rsMRI\", x=0.498, y=1, xref=\"paper\", yref=\"paper\",\n",
    "            showarrow=False, font=dict(size=40, family=\"DejaVu Sans\", color='black')),\n",
    "        dict(\n",
    "            text=\"sMRI\", x=0.915, y=1, xref=\"paper\", yref=\"paper\",\n",
    "            showarrow=False, font=dict(size=40, family=\"DejaVu Sans\", color='black'))\n",
    "],\n",
    ")\n",
    "\n",
    "# Add a red marker at minimum x-value (0.05)\n",
    "for col in [1, 2, 3]:\n",
    "    fig.add_vline(\n",
    "        x=0.0009, \n",
    "        line=dict(color=\"#660000\", width=2, dash=\"dash\"), #['solid', 'dot', 'dash', 'longdash', 'dashdot', 'longdashdot']\n",
    "        opacity=0.8,\n",
    "        row=1,\n",
    "        col=col,\n",
    "        #annotation_text=\"0\",\n",
    "        #annotation_position=\"bottom right\",\n",
    "        #annotation_font=dict(\n",
    "            #size=24,    \n",
    "            #family=\"DejaVu Sans\",\n",
    "            #color=\"#660000\")\n",
    "    )\n",
    "\n",
    "pio.write_image(fig, '/figures/Fig3b-ci.pdf', scale=1, format='pdf') # width=8.27*400, height=6.85*400,  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_red = \"#8B0000\"  # Standard dark red\n",
    "darker_red = \"#5C0000\"  # Even darker\n",
    "blood_red = \"#660000\"  # Rich dark red\n",
    "dark_red_rgb = \"rgb(139, 0, 0)\"  # Same as #8B0000\n",
    "dark_red_rgba = \"rgba(139, 0, 0, 0.8)\"  # With 80% opacity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KDE plots for stacked modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data frames\n",
    "rs_bootstrapped_r_melt_sort = rs_bootstrapped_r_melt.sort_values(by='r', ascending=True).reset_index(drop=True)\n",
    "rs_bootstrapped_r_melt_sort = rs_bootstrapped_r_melt_sort[rs_bootstrapped_r_melt_sort['modality'] == 'rsMRI Stacked (RF)']\n",
    "\n",
    "dti_bootstrapped_r_melt_sort = dti_bootstrapped_r_melt.sort_values(by='r', ascending=True).reset_index(drop=True)\n",
    "dti_bootstrapped_r_melt_sort = dti_bootstrapped_r_melt_sort[dti_bootstrapped_r_melt_sort['modality'] == 'dwMRI Stacked (RF)']\n",
    "\n",
    "t1t2_bootstrapped_r_melt_sort = t1t2_bootstrapped_r_melt.sort_values(by='r', ascending=True).reset_index(drop=True)\n",
    "all_stacked = t1t2_bootstrapped_r_melt_sort[t1t2_bootstrapped_r_melt_sort['modality'] == 'All MRI Modalities Stacked (XGB)']\n",
    "all_stacked['mod'] = all_stacked['mod'].replace('t1t2', 'all')\n",
    "t1t2_bootstrapped_r_melt_sort = t1t2_bootstrapped_r_melt_sort[t1t2_bootstrapped_r_melt_sort['modality'] == 'T1w/T2w Structural Stacked (SVR)']\n",
    "\n",
    "# Calculate median values for each modality and ensure the order matches the sorted data\n",
    "rs_median = rs_bootstrapped_r_melt_sort.groupby('modality')['r'].median().reset_index()\n",
    "rs_median = rs_median.set_index('modality').loc[rs_bootstrapped_r_melt_sort['modality'].unique()].reset_index() #loc[0:2,:]\n",
    "rs_median = pd.concat([rs_median.head(1), rs_median.tail(1)]).reset_index(drop=True)\n",
    "\n",
    "dti_median = dti_bootstrapped_r_melt_sort.groupby('modality')['r'].median().reset_index()\n",
    "dti_median = dti_median.set_index('modality').loc[dti_bootstrapped_r_melt_sort['modality'].unique()].reset_index() #.loc[0:2,:]\n",
    "dti_median = pd.concat([dti_median.head(1), dti_median.tail(1)]).reset_index(drop=True)\n",
    "\n",
    "t1t2_median = t1t2_bootstrapped_r_melt_sort.groupby('modality')['r'].median().reset_index()\n",
    "t1t2_median = t1t2_median.set_index('modality').loc[t1t2_bootstrapped_r_melt_sort['modality'].unique()].reset_index() #.loc[0:2,:]\n",
    "t1t2_median = pd.concat([t1t2_median.head(1), t1t2_median.tail(1)]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([dti_bootstrapped_r_melt_sort, rs_bootstrapped_r_melt_sort, t1t2_bootstrapped_r_melt_sort, all_stacked])\n",
    "combined_df['modality'] = combined_df['modality'].replace('All MRI Modalities Stacked (XGB)', 'MRI Modalities Stacked')\n",
    "combined_df['modality'] = combined_df['modality'].replace('dwMRI Stacked (RF)', 'dwMRI Stacked')\n",
    "combined_df['modality'] = combined_df['modality'].replace('rsMRI Stacked (RF)', 'rsMRI Stacked')\n",
    "combined_df['modality'] = combined_df['modality'].replace('T1w/T2w Structural Stacked (SVR)', 'sMRI Stacked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(18,4))\n",
    "\n",
    "custom_palette = {\n",
    "    'dwMRI Stacked': '#0d648f', #'#6A659999', 7AA6DCFF\n",
    "    'rsMRI Stacked': '#4B6F5A99', #'#79AF9799', #0d8f81\n",
    "    'sMRI Stacked': '#f8b976', #'#DF8F4499', \n",
    "    'MRI Modalities Stacked': '#6A659999' #'#374E5599'\n",
    "}\n",
    "\n",
    "kde = sns.kdeplot(\n",
    "   data=combined_df, x=\"r\", hue=\"modality\",\n",
    "   fill=True, common_norm=False, palette=custom_palette, #\"crest\",\n",
    "   alpha=.5, linewidth=1, legend=False\n",
    ")\n",
    "\n",
    "for mod in combined_df['modality'].unique():\n",
    "    median_r = combined_df[combined_df['modality'] == mod]['r'].median()\n",
    "    plt.axvline(median_r, color='grey', linestyle='--', linewidth=0.7)\n",
    "    plt.text(median_r + 0.003, plt.gca().get_ylim()[1] * 0.9, f'{median_r:.2f}', color='black', fontsize=25)\n",
    "\n",
    "sns.despine(left=True)\n",
    "plt.title(\"Bootstrap Distribution of Pearson $r$:\\nStacked MRI Modalities\", fontsize=40, y=1.3)\n",
    "plt.xlabel(\"Pearson $r$\", fontsize=25)\n",
    "plt.ylabel(\"Density\", fontsize=25)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(fontsize=20)\n",
    "x_ticks = np.arange(combined_df['r'].min(), combined_df['r'].max() + 0.02, 0.02)\n",
    "plt.xticks(ticks=x_ticks, labels=[f'{x:.2f}' for x in x_ticks], fontsize=17) #ticks=plt.xticks()[0] / for x in plt.xticks()[0]\n",
    "\n",
    "legend_elements = [mpatches.Patch(color=color, label=mod, alpha=.5) for mod, color in custom_palette.items()]\n",
    "fig.legend(handles=legend_elements, loc='lower center', ncol=4, fontsize=26, frameon=False, bbox_to_anchor=(0.5, -0.4))\n",
    "\n",
    "plt.savefig(\"/figures/Fig3a.jpg\",\n",
    "            bbox_inches=\"tight\", \n",
    "            pad_inches=1, \n",
    "            transparent=False, \n",
    "            facecolor=\"w\", \n",
    "            edgecolor='w', \n",
    "            orientation='landscape',\n",
    "            format='jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbiobank_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
