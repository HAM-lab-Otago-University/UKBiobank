{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import warnings\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack dwMRI: Parcellations (structural matrices) + IDPs (TBSS/Probabilistic tractography)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dti_all_modalities = [\n",
    "'fa_prob', 'fa_tbss',\n",
    "'icvf_prob', 'icvf_tbss',\n",
    "'isovf_prob','isovf_tbss',\n",
    "'l1_prob', 'l1_tbss',\n",
    "'l2_prob', 'l2_tbss',\n",
    "'l3_prob', 'l3_tbss',\n",
    "'md_prob', 'md_tbss',\n",
    "'mo_prob', 'mo_tbss',\n",
    "'od_prob', 'od_tbss',\n",
    "\n",
    "'31020_connectome_fa',\n",
    "'31020_connectome_mean_length',\n",
    "'31020_connectome_sift2',\n",
    "'31020_connectome_streamline_count',\n",
    "\n",
    "'31021_connectome_fa',\n",
    "'31021_connectome_mean_length',\n",
    "'31021_connectome_sift2',\n",
    "'31021_connectome_streamline_count',\n",
    "\n",
    "'31022_connectome_fa',\n",
    "'31022_connectome_mean_length',\n",
    "'31022_connectome_sift2',\n",
    "'31022_connectome_streamline_count',\n",
    "\n",
    "'31023_connectome_fa',\n",
    "'31023_connectome_mean_length',\n",
    "'31023_connectome_sift2',\n",
    "'31023_connectome_streamline_count',\n",
    "\n",
    "'31024_connectome_fa',\n",
    "'31024_connectome_mean_length',\n",
    "'31024_connectome_sift2',\n",
    "'31024_connectome_streamline_count',\n",
    "\n",
    "'31025_connectome_fa',\n",
    "'31025_connectome_mean_length',\n",
    "'31025_connectome_sift2',\n",
    "'31025_connectome_streamline_count_10M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dti_all_modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predicted g-factors\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "for fold in folds:\n",
    "     \n",
    "     print(f'Started {fold}', flush=True)\n",
    "     all_modalities_train = []\n",
    "     all_modalities_test = []\n",
    "     \n",
    "     for modality in dti_all_modalities:\n",
    "          \n",
    "          g_train_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted train': f'{modality}'})\n",
    "          print('g TRAIN shape BEFORE stacking:', g_train_pred_level1.shape)\n",
    "          g_test_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted test': f'{modality}'})\n",
    "          print('g TEST shape BEFORE stacking:', g_test_pred_level1.shape)\n",
    "          \n",
    "          all_modalities_train.append(g_train_pred_level1)\n",
    "          all_modalities_test.append(g_test_pred_level1)\n",
    "          \n",
    "     features_train_level1 = all_modalities_train[0]\n",
    "     features_test_level1 = all_modalities_test[0]\n",
    "     \n",
    "     for i in range(1, len(all_modalities_train)):\n",
    "          features_train_level1 = pd.merge(features_train_level1, all_modalities_train[i], on='eid', how='inner')\n",
    "     print('g TRAIN shape AFTER stacking:', features_train_level1.shape)\n",
    "\n",
    "     features_train_level1.to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/dti_all/features_train_level1_fold_{fold}.csv', index=False)\n",
    "     features_train_level1_g_matched = features_train_level1.merge(pd.read_csv(f'/PLS/g_factor/g_train_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_train_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/dti_all/features_train_level1_g_matched_fold_{fold}.csv', index=False)\n",
    "     \n",
    "     for i in range(1, len(all_modalities_test)):\n",
    "          features_test_level1 = pd.merge(features_test_level1, all_modalities_test[i], on='eid', how='inner')\n",
    "     print('g TEST shape AFTER stacking:', features_test_level1.shape)\n",
    "     features_test_level1.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/dti_all/features_test_level1_fold_{fold}.csv', index=False)\n",
    "     features_test_level1_g_matched = features_test_level1.merge(pd.read_csv(f'/PLS/g_factor/g_test_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_test_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/dti_all/features_test_level1_g_matched_fold_{fold}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for all algorithms and folds\n",
    "algorithms = ['svr', 'eNet', 'xgb', 'rf']\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "stack_folds_all_dti = []\n",
    "for algorithm in algorithms:\n",
    "    for fold in folds:\n",
    "        model = pd.read_csv(f'/PLS/brain/stacking/result/DTI_All_{algorithm}_stacked_result_fold_{fold}.csv', header=None)\n",
    "        model.columns = ['Algorithm', 'Fold', 'Best parameters', 'MSE', 'MAE', 'R2', 'Pearson r']\n",
    "        stack_folds_all_dti.append(model)\n",
    "        stack_all_dti = pd.concat(stack_folds_all_dti, ignore_index=False)\n",
    "stack_all_dti['Pearson r'] = stack_all_dti['Pearson r'].astype(str).str.replace(r'PearsonRResult\\(statistic=|pvalue=|\\)', '', regex=True)\n",
    "stack_all_dti[['Pearson r', 'p-value']] = stack_all_dti['Pearson r'].str.split(',', expand=True).astype(float).round(decimals=3)\n",
    "stack_all_dti['Best parameters'] = stack_all_dti['Best parameters'].str.replace(\"'\", \"\")\n",
    "stack_all_dti['Best parameters'] = stack_all_dti['Best parameters'].str.replace(\"{\", \"\").str.replace(\"}\", \"\")\n",
    "stack_all_dti.round(3).to_csv(f'/PLS/brain/stacking/DTI_All_stacked_five_folds.csv', index=False)\n",
    "stack_all_dti.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_all_dti_mean_dti = stack_all_dti[['Algorithm', 'MSE', 'MAE', 'R2', 'Pearson r']].groupby(['Algorithm']).mean().round(3).reset_index()\n",
    "stack_all_dti_mean_dti.sort_values(by='Pearson r', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack rsMRI: Parcellations (full correlation) + IDPs (tangent + amplitudes)\n",
    "\n",
    "## RS IDP best + FullCorr atlases matched to DTI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- aparc_Tian_s1\n",
    "- aparc_2009_Tian_s1\n",
    "- Glasser_Tian_s1\n",
    "- Glasser_Tian_s4\n",
    "- Schaeffer_7n200_Tian_s1\n",
    "- Schaeffer_7n500_Tian_s4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_idp_rs_best_metrics = [\n",
    "# RS TS\n",
    "# Full corr\n",
    "'aparc_s1_full_correlation', \n",
    "'aparc_2009_s1_full_correlation',\n",
    "'glasser_s1_full_correlation',\n",
    "'glasser_s4_full_correlation',\n",
    "'Schaefer7n200p_s1_full_correlation',\n",
    "'Schaefer7n500p_s4_full_correlation',\n",
    "\n",
    "# RS IDP\n",
    "'amplitudes_21', \n",
    "'amplitudes_55',\n",
    "'tangent_matrices_21', \n",
    "'tangent_matrices_55']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rs_idp_rs_best_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predicted g-factors\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "for fold in folds:\n",
    "     \n",
    "     print(f'Started {fold}', flush=True)\n",
    "     all_modalities_train = []\n",
    "     all_modalities_test = []\n",
    "     \n",
    "     for modality in rs_idp_rs_best_metrics:\n",
    "          \n",
    "          g_train_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted train': f'{modality}'})\n",
    "          print('g TRAIN shape BEFORE stacking:', g_train_pred_level1.shape)\n",
    "          print(g_train_pred_level1.isna().sum().sort_values(ascending=False))\n",
    "          g_test_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted test': f'{modality}'})\n",
    "          print('g TEST shape BEFORE stacking:', g_test_pred_level1.shape)\n",
    "          print(g_test_pred_level1.isna().sum().sort_values(ascending=False))\n",
    "          \n",
    "          all_modalities_train.append(g_train_pred_level1)\n",
    "          all_modalities_test.append(g_test_pred_level1)\n",
    "          \n",
    "     features_train_level1 = all_modalities_train[0]\n",
    "     features_test_level1 = all_modalities_test[0]\n",
    "     \n",
    "     for i in range(1, len(all_modalities_train)):\n",
    "          features_train_level1 = pd.merge(features_train_level1, all_modalities_train[i], on='eid', how='inner')\n",
    "     print('g TRAIN shape AFTER stacking:', features_train_level1.shape)\n",
    "\n",
    "     features_train_level1.to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/rs_idp_ts_best_metrics/features_train_level1_fold_{fold}.csv', index=False)\n",
    "     features_train_level1_g_matched = features_train_level1.merge(pd.read_csv(f'/PLS/g_factor/g_train_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_train_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/rs_idp_ts_best_metrics/features_train_level1_g_matched_fold_{fold}.csv', index=False)\n",
    "     print(features_train_level1_g_matched.isna().sum().sort_values(ascending=False))\n",
    "     \n",
    "     for i in range(1, len(all_modalities_test)):\n",
    "          features_test_level1 = pd.merge(features_test_level1, all_modalities_test[i], on='eid', how='inner')\n",
    "     print('g TEST shape AFTER stacking:', features_test_level1.shape)\n",
    "     features_test_level1.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/rs_idp_ts_best_metrics/features_test_level1_fold_{fold}.csv', index=False)\n",
    "     features_test_level1_g_matched = features_test_level1.merge(pd.read_csv(f'/PLS/g_factor/g_test_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_test_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/rs_idp_ts_best_metrics/features_test_level1_g_matched_fold_{fold}.csv', index=False)\n",
    "     print(features_test_level1_g_matched.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for all algorithms and folds\n",
    "algorithms = ['xgb', 'eNet', 'rf', 'svr']\n",
    "folds = [ \"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "stack_folds_all = []\n",
    "for algorithm in algorithms:\n",
    "    for fold in folds:\n",
    "        model = pd.read_csv(f'/PLS/brain/stacking/result/RS_IDP_Timeseries_best_metrics_{algorithm}_stacked_result_fold_{fold}.csv', header=None)\n",
    "        model.columns = ['Algorithm', 'Fold', 'Best parameters', 'MSE', 'MAE', 'R2', 'Pearson r']\n",
    "        stack_folds_all.append(model)\n",
    "        stack_all = pd.concat(stack_folds_all, ignore_index=False)\n",
    "stack_all['Pearson r'] = stack_all['Pearson r'].astype(str).str.replace(r'PearsonRResult\\(statistic=|pvalue=|\\)', '', regex=True)\n",
    "stack_all[['Pearson r', 'p-value']] = stack_all['Pearson r'].str.split(',', expand=True).astype(float).round(decimals=3)\n",
    "stack_all['Best parameters'] = stack_all['Best parameters'].str.replace(\"'\", \"\")\n",
    "stack_all['Best parameters'] = stack_all['Best parameters'].str.replace(\"{\", \"\").str.replace(\"}\", \"\")\n",
    "stack_all.round(3).to_csv(f'/PLS/brain/stacking/RS_IDP_Timeseries_best_metrics_stacked_five_folds.csv', index=False)\n",
    "stack_all.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_all_mean_rs = stack_all[['Algorithm', 'MSE', 'MAE', 'R2', 'Pearson r']].groupby(['Algorithm']).mean().round(3).reset_index()\n",
    "stack_all_mean_rs.sort_values(by='R2', ascending=False)\n",
    "#stack_all_mean.sort_values(by='R2', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack sMRI: T1w + whole-brain T1w/T2w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities_struct = ['struct_fast', 'struct_sub_first', 'struct_aseg_mean_intensity', 'struct_aseg_volume', 'struct_ba_exvivo_area', \n",
    "          'struct_ba_exvivo_mean_thickness', 'struct_ba_exvivo_volume', 'struct_a2009s_area', 'struct_a2009s_mean_thickness', 'struct_a2009s_volume',\n",
    "           'struct_dkt_area', 'struct_dkt_mean_thickness', 'struct_dkt_volume', 'struct_desikan_gw', 'struct_desikan_pial',\n",
    "           'struct_desikan_white_area', 'struct_desikan_white_mean_thickness', 'struct_desikan_white_volume', 'struct_subsegmentation', 'T1_T2_whole_brain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(modalities_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predicted g-factors\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "for fold in folds:\n",
    "     \n",
    "     print(f'Started {fold}', flush=True)\n",
    "     all_modalities_train = []\n",
    "     all_modalities_test = []\n",
    "     \n",
    "     for modality in modalities_struct:\n",
    "          \n",
    "          g_train_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted train': f'{modality}'})\n",
    "          print('g TRAIN shape BEFORE stacking:', g_train_pred_level1.shape)\n",
    "          print(g_train_pred_level1.isna().sum().sort_values(ascending=False))\n",
    "          g_test_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted test': f'{modality}'})\n",
    "          print('g TEST shape BEFORE stacking:', g_test_pred_level1.shape)\n",
    "          print(g_test_pred_level1.isna().sum().sort_values(ascending=False))\n",
    "          \n",
    "          all_modalities_train.append(g_train_pred_level1)\n",
    "          all_modalities_test.append(g_test_pred_level1)\n",
    "          \n",
    "     features_train_level1 = all_modalities_train[0]\n",
    "     features_test_level1 = all_modalities_test[0]\n",
    "     \n",
    "     for i in range(1, len(all_modalities_train)):\n",
    "          features_train_level1 = pd.merge(features_train_level1, all_modalities_train[i], on='eid', how='inner')\n",
    "     print('g TRAIN shape AFTER stacking:', features_train_level1.shape)\n",
    "\n",
    "     features_train_level1.to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/t1_t2_struct/features_train_level1_fold_{fold}.csv', index=False)\n",
    "     features_train_level1_g_matched = features_train_level1.merge(pd.read_csv(f'/PLS/g_factor/g_train_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_train_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/t1_t2_struct/features_train_level1_g_matched_fold_{fold}.csv', index=False)\n",
    "     print(features_train_level1_g_matched.isna().sum().sort_values(ascending=False))\n",
    "     \n",
    "     for i in range(1, len(all_modalities_test)):\n",
    "          features_test_level1 = pd.merge(features_test_level1, all_modalities_test[i], on='eid', how='inner')\n",
    "     print('g TEST shape AFTER stacking:', features_test_level1.shape)\n",
    "     features_test_level1.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/t1_t2_struct/features_test_level1_fold_{fold}.csv', index=False)\n",
    "     features_test_level1_g_matched = features_test_level1.merge(pd.read_csv(f'/PLS/g_factor/g_test_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_test_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/t1_t2_struct/features_test_level1_g_matched_fold_{fold}.csv', index=False)\n",
    "     print(features_test_level1_g_matched.isna().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for all algorithms and folds\n",
    "algorithms = ['xgb', 'eNet', 'rf', 'svr']\n",
    "folds = [ \"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "stack_folds_all = []\n",
    "for algorithm in algorithms:\n",
    "    for fold in folds:\n",
    "        model = pd.read_csv(f'/PLS/brain/stacking/result/T1_T2_whole_brain_{algorithm}_stacked_result_fold_{fold}.csv', header=None)\n",
    "        model.columns = ['Algorithm', 'Fold', 'Best parameters', 'MSE', 'MAE', 'R2', 'Pearson r']\n",
    "        stack_folds_all.append(model)\n",
    "        stack_all = pd.concat(stack_folds_all, ignore_index=False)\n",
    "stack_all['Pearson r'] = stack_all['Pearson r'].astype(str).str.replace(r'PearsonRResult\\(statistic=|pvalue=|\\)', '', regex=True)\n",
    "stack_all[['Pearson r', 'p-value']] = stack_all['Pearson r'].str.split(',', expand=True).astype(float).round(decimals=3)\n",
    "stack_all['Best parameters'] = stack_all['Best parameters'].str.replace(\"'\", \"\")\n",
    "stack_all['Best parameters'] = stack_all['Best parameters'].str.replace(\"{\", \"\").str.replace(\"}\", \"\")\n",
    "stack_all.round(3).to_csv(f'/PLS/brain/stacking/T1_T2_whole_brain_stacked_five_folds.csv', index=False)\n",
    "stack_all.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_all_mean_t1t2 = stack_all[['Algorithm', 'MSE', 'MAE', 'R2', 'Pearson r']].groupby(['Algorithm']).mean().round(3).reset_index()\n",
    "stack_all_mean_t1t2.sort_values(by='R2', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack all modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_best = [\n",
    "# Full corr\n",
    "'aparc_s1_full_correlation', \n",
    "'aparc_2009_s1_full_correlation',\n",
    "'glasser_s1_full_correlation',\n",
    "'glasser_s4_full_correlation',\n",
    "'Schaefer7n200p_s1_full_correlation',\n",
    "'Schaefer7n500p_s4_full_correlation',\n",
    "\n",
    "# RS IDP\n",
    "'amplitudes_21', \n",
    "'amplitudes_55',\n",
    "'tangent_matrices_21', \n",
    "'tangent_matrices_55',\n",
    "\n",
    "# DTI IDP\n",
    "'fa_prob', 'fa_tbss',\n",
    "'icvf_prob', 'icvf_tbss',\n",
    "'isovf_prob','isovf_tbss',\n",
    "'l1_prob', 'l1_tbss',\n",
    "'l2_prob', 'l2_tbss',\n",
    "'l3_prob', 'l3_tbss',\n",
    "'md_prob', 'md_tbss',\n",
    "'mo_prob', 'mo_tbss',\n",
    "'od_prob', 'od_tbss',\n",
    "\n",
    "# T1\n",
    "'struct_fast', 'struct_sub_first',\n",
    "'struct_aseg_mean_intensity', 'struct_aseg_volume',\n",
    "'struct_ba_exvivo_area',  'struct_ba_exvivo_mean_thickness', 'struct_ba_exvivo_volume',\n",
    "'struct_a2009s_area', 'struct_a2009s_mean_thickness', 'struct_a2009s_volume',\n",
    "'struct_dkt_area', 'struct_dkt_mean_thickness', 'struct_dkt_volume',\n",
    "'struct_desikan_gw', 'struct_desikan_pial', 'struct_desikan_white_area', 'struct_desikan_white_mean_thickness', 'struct_desikan_white_volume',\n",
    "'struct_subsegmentation',\n",
    "'T1_T2_whole_brain',\n",
    "\n",
    "# DTI Struct\n",
    "'31020_connectome_fa',\n",
    "'31020_connectome_mean_length',\n",
    "'31020_connectome_sift2',\n",
    "'31020_connectome_streamline_count',\n",
    "\n",
    "'31021_connectome_fa',\n",
    "'31021_connectome_mean_length',\n",
    "'31021_connectome_sift2',\n",
    "'31021_connectome_streamline_count',\n",
    "\n",
    "'31022_connectome_fa',\n",
    "'31022_connectome_mean_length',\n",
    "'31022_connectome_sift2',\n",
    "'31022_connectome_streamline_count',\n",
    "\n",
    "'31023_connectome_fa',\n",
    "'31023_connectome_mean_length',\n",
    "'31023_connectome_sift2',\n",
    "'31023_connectome_streamline_count',\n",
    "\n",
    "'31024_connectome_fa',\n",
    "'31024_connectome_mean_length',\n",
    "'31024_connectome_sift2',\n",
    "'31024_connectome_streamline_count',\n",
    "\n",
    "'31025_connectome_fa',\n",
    "'31025_connectome_mean_length',\n",
    "'31025_connectome_sift2',\n",
    "'31025_connectome_streamline_count_10M'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge predicted g-factors\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "for fold in folds:\n",
    "     \n",
    "     print(f'Started {fold}', flush=True)\n",
    "     all_modalities_train = []\n",
    "     all_modalities_test = []\n",
    "     \n",
    "     for modality in mod_best:\n",
    "          \n",
    "          g_train_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_train_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted train': f'{modality}'})\n",
    "          print('g TRAIN shape BEFORE stacking:', g_train_pred_level1.shape)\n",
    "          g_test_pred_level1 = pd.read_csv(f'/PLS/brain/stacking/g_pred_first_level/{modality}_g_pred_test_id_fold_{fold}.csv').drop(columns='Unnamed: 0').rename(columns={'g predicted test': f'{modality}'})\n",
    "          print('g TEST shape BEFORE stacking:', g_test_pred_level1.shape)\n",
    "          \n",
    "          all_modalities_train.append(g_train_pred_level1)\n",
    "          all_modalities_test.append(g_test_pred_level1)\n",
    "          \n",
    "     features_train_level1 = all_modalities_train[0]\n",
    "     features_test_level1 = all_modalities_test[0]\n",
    "     \n",
    "     for i in range(1, len(all_modalities_train)):\n",
    "          features_train_level1 = pd.merge(features_train_level1, all_modalities_train[i], on='eid', how='inner')\n",
    "\n",
    "     print('g TRAIN shape AFTER stacking:', features_train_level1.shape)\n",
    "     \n",
    "     features_train_level1.astype(float).to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/all_modalities/features_train_level1_fold_{fold}.csv', index=False)\n",
    "     features_train_level1_g_matched = features_train_level1.merge(pd.read_csv(f'/PLS/g_factor/g_train_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_train_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_train_level1_stacked/all_modalities/features_train_level1_g_matched_fold_{fold}.csv', index=False)\n",
    "     \n",
    "     for i in range(1, len(all_modalities_test)):\n",
    "          features_test_level1 = pd.merge(features_test_level1, all_modalities_test[i], on='eid', how='inner')\n",
    "          \n",
    "     print('g TEST shape AFTER stacking:', features_test_level1.shape)\n",
    "     features_test_level1.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/all_modalities/features_test_level1_fold_{fold}.csv', index=False)\n",
    "     features_test_level1_g_matched = features_test_level1.merge(pd.read_csv(f'/PLS/g_factor/g_test_with_id_fold_{fold}.csv'), on='eid').drop(columns='g')\n",
    "     features_test_level1_g_matched.to_csv(f'/PLS/brain/stacking/features_test_level1_stacked/all_modalities/features_test_level1_g_matched_fold_{fold}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results for all algorithms and folds\n",
    "algorithms = ['eNet', 'xgb', 'rf', 'svr']\n",
    "folds = [ \"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "stack_folds_all = []\n",
    "for algorithm in algorithms:\n",
    "    for fold in folds:\n",
    "        model = pd.read_csv(f'/PLS/brain/stacking/result/All_modalities_{algorithm}_stacked_result_fold_{fold}.csv', header=None)\n",
    "        model.columns = ['Algorithm', 'Fold', 'Best parameters', 'MSE', 'MAE', 'R2', 'Pearson r']\n",
    "        stack_folds_all.append(model)\n",
    "        stack_all = pd.concat(stack_folds_all, ignore_index=False)\n",
    "stack_all['Pearson r'] = stack_all['Pearson r'].astype(str).str.replace(r'PearsonRResult\\(statistic=|pvalue=|\\)', '', regex=True)\n",
    "stack_all[['Pearson r', 'p-value']] = stack_all['Pearson r'].str.split(',', expand=True).astype(float).round(decimals=3)\n",
    "stack_all['Best parameters'] = stack_all['Best parameters'].str.replace(\"'\", \"\")\n",
    "stack_all['Best parameters'] = stack_all['Best parameters'].str.replace(\"{\", \"\").str.replace(\"{\", \"\").str.replace(\"}\", \"\")\n",
    "stack_all.round(3).to_csv(f'/PLS/brain/stacking/All_modalities_stacked_five_folds.csv', index=False)\n",
    "stack_all.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_all_mean = stack_all[['Algorithm', 'MSE', 'MAE', 'R2', 'Pearson r']].groupby(['Algorithm']).mean().round(3).reset_index()\n",
    "#stack_all_mean.sort_values(by='Pearson r', ascending=False)\n",
    "stack_all_mean.sort_values(by='R2', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbiobank_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
