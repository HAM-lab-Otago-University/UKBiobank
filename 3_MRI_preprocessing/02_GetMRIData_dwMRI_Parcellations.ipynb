{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MISMATCH BETWEEN FOLDER NAME IN UKBB SHOWCASE AND FILES IN STRUCTURAL DTI MATRICES:\n",
    "\n",
    "31024_Schaefer7n1000p_Tian_S4\n",
    "- expected: 1000 + 54 = 1054 structures\n",
    "- in fact: 216 structures = 200 + 16 (T1)\n",
    "\n",
    "31025_Schaefer7n200p_Tian_S1:\n",
    "- expected: 200 + 16 = 216 structures\n",
    "- in fact: 554 structures = 500 + 54 (T4)\n",
    "\n",
    "31026_Schaefer7n500p_Tian_S4\n",
    "- expected: 500 + 54 = 516 structures\n",
    "- in fact: 1054 structures = 1000 + 54 (T4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check how many columns are in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/brain/dti/dti_struct/31025_connectome_streamline_count_10M.csv\", \"r\") as f:\n",
    "  reader = csv.reader(f, delimiter=\",\")\n",
    "  first_row = next(reader)\n",
    "  num_columns = len(first_row)\n",
    "  print(num_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31020_aparc_a2009s_Tian_S1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_FA_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = ['/Melbourne_BULK/DTI_connectome/31020_aparc_a2009s_Tian_S1/10000/unzipped/',\n",
    "'/Melbourne_BULK/DTI_connectome/31020_aparc_a2009s_Tian_S1/20000/unzipped/',\n",
    "'/Melbourne_BULK/DTI_connectome/31020_aparc_a2009s_Tian_S1/30000/unzipped/',\n",
    "'media/hcs-sci-psy-narun/Melbourne_BULK/DTI_connectome/31020_aparc_a2009s_Tian_S1/40000/unzipped/',\n",
    "'/Melbourne_BULK/DTI_connectome/31020_aparc_a2009s_Tian_S1/42840/unzipped/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_count = 0\n",
    "\n",
    "fa_connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        fa_file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(fa_file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fa_connectome = pd.read_csv(fa_file, header=None)\n",
    "            fa_connectome_triu_indices = np.triu_indices(len(np.array(fa_connectome)), k=0)\n",
    "            fa_connectome_triu_v = np.array(fa_connectome)[fa_connectome_triu_indices]\n",
    "\n",
    "            fa_connectome_mean_list.append(fa_connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {fa_file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df and indices')\n",
    "\n",
    "fa_connectome_mean_full_df = pd.DataFrame(fa_connectome_mean_list, index = index_list)\n",
    "fa_connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_FA_10M/31020_aparc_a2009s_Tian_S1_fa_connectome_mean_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_FA_10M/31020_aparc_a2009s_Tian_S1_full_id_full.csv', index=False)  \n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "fa_connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, fa in zip(index_list, fa_connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        fa_connectome_instance_2.append(fa)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31020_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_FA_10M/31020_aparc_a2009s_Tian_S1_full_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del fa_connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "fa_connectome_instance_2_df = pd.DataFrame(fa_connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "fa_connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_FA_10M/31020_aparc_a2009s_Tian_S1_fa_connectome_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del fa_connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When upload file specify which column of the CSV file should be used as the index of the dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When upload file specify which column of the CSV file should be used as the index of the dataframe\n",
    "df = pd.read_csv('my_data.csv', index_col=0)\n",
    "df = pd.read_csv('my_data.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_length_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_mean_length_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_length_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_length_10M/31020_aparc_a2009s_Tian_S1_connectome_mean_length_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_length_10M/31020_aparc_a2009s_Tian_S1_connectome_mean_length_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31020_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_length_10M/31020_aparc_a2009s_Tian_S1_connectome_mean_length_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('IBu/UK_BB/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_mean_length_10M/31020_aparc_a2009s_Tian_S1_connectome_mean_length_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_sift2_fbc_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_sift2_fbc_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_sift2_fbc_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_sift2_fbc_10M/31020_aparc_a2009s_Tian_S1_connectome_sift2_fbc_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_sift2_fbc_10M/31020_aparc_a2009s_Tian_S1_connectome_sift2_fbc_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31020_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_sift2_fbc_10M/31020_aparc_a2009s_Tian_S1_connectome_sift2_fbc_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_sift2_fbc_10M/31020_aparc_a2009s_Tian_S1_connectome_sift2_fbc_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_streamline_count_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_streamline_count_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_streamline_count_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_streamline_count_10M/31020_aparc_a2009s_Tian_S1_connectome_streamline_count_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_streamline_count_10M/31020_aparc_a2009s_Tian_S1_connectome_streamline_count_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31020_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_streamline_count_10M/31020_aparc_a2009s_Tian_S1_connectome_streamline_count_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31020_aparc_a2009s_Tian_S1/Connectome_streamline_count_10M/31020_aparc_a2009s_Tian_S1_connectome_streamline_count_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract names of the folders\n",
    "folder_names = []\n",
    "\n",
    "for path in folder_paths:\n",
    "    folders = sorted(glob.glob(path + \"*_31020_*\"))\n",
    "\n",
    "    for folder in folders:\n",
    "        folder_name = os.path.basename(folder)\n",
    "        folder_names.append(folder_name)\n",
    "\n",
    "print(len(folder_names))\n",
    "\n",
    "index_instance_2 = []\n",
    "for folder_name in folder_names:\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print(len(index_instance_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31027_Tractography_endpoints_coordinates - skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are real coordinates for streamlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31027_Tractography_endpoints_coordinates/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31027_Tractography_endpoints_coordinates/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31027_Tractography_endpoints_coordinates/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31027_Tractography_endpoints_coordinates/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31027_Tractography_endpoints_coordinates/42959/unzipped/\"]\n",
    "\n",
    "missing_file_count = 0\n",
    "\n",
    "endpoints_coordinates_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            endpoints_coordinates = pd.read_csv(file, header=None)\n",
    "            endpoints_coordinates_triu_indices = np.triu_indices(len(np.array(endpoints_coordinates)), k=0)\n",
    "            endpoints_coordinates_triu_v = np.array(endpoints_coordinates)[endpoints_coordinates_triu_indices]\n",
    "\n",
    "            endpoints_coordinates_list.append(endpoints_coordinates_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df and indices')\n",
    "\n",
    "endpoints_coordinates_full_df = pd.DataFrame(endpoints_coordinates_list, index = index_list)\n",
    "endpoints_coordinates_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31027_Tractography_endpoints_coordinates/endpoints_coordinates_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31027_Tractography_endpoints_coordinates/endpoints_coordinates_id_full.csv', index=False)  \n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "endpoints_coordinates_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, cn in zip(index_list, endpoints_coordinates_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        endpoints_coordinates_instance_2.append(cn)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31027_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31027_Tractography_endpoints_coordinates/endpoints_coordinates_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "endpoints_coordinates_instance_2_df = pd.DataFrame(endpoints_coordinates_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "endpoints_coordinates_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31027_Tractography_endpoints_coordinates/endpoints_coordinates_instance_2_df.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31028_Tractography_quality_metrics - skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31028_Tractography_quality_metrics/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31028_Tractography_quality_metrics/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31028_Tractography_quality_metrics/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31028_Tractography_quality_metrics/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31028_Tractography_quality_metrics/42959/unzipped/\"]\n",
    "\n",
    "missing_file_count = 0\n",
    "\n",
    "sift_weights_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        npy_file = \"sift_weights.npy\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, npy_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            sift_weights = np.load(file)\n",
    "\n",
    "            sift_weights_list.append(sift_weights)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full indices')\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31028_Tractography_quality_metrics/sift_weights_id_full.csv', index=False)  \n",
    "\n",
    "print('Saving full_df')\n",
    "sift_weights_list_full_df = pd.DataFrame(sift_weights_list, index = index_list).T\n",
    "sift_weights_list_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31028_Tractography_quality_metrics/sift_weights_full_df.csv')\n",
    "del sift_weights_list_full_df\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "sift_weights_instance_2_list = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, m in zip(index_list, sift_weights_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        sift_weights_instance_2_list.append(m)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31028_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31028_Tractography_quality_metrics/sift_weights_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del sift_weights_list\n",
    "gc.collect()\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "sift_weights_instance_2_df = pd.DataFrame(sift_weights_instance_2_list, index = index_instance_2_df['ID'].to_list()).T\n",
    "\n",
    "del index_instance_2\n",
    "del sift_weights_instance_2_list\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "sift_weights_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31028_Tractography_quality_metrics/sift_weights_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31021_aparc_Tian_S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31021_aparc_Tian_S1/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31021_aparc_Tian_S1/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31021_aparc_Tian_S1/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31021_aparc_Tian_S1/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31021_aparc_Tian_S1/42892/unzipped/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_FA_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_count = 0\n",
    "\n",
    "fa_connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        fa_file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(fa_file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fa_connectome = pd.read_csv(fa_file, header=None)\n",
    "            fa_connectome_triu_indices = np.triu_indices(len(np.array(fa_connectome)), k=0)\n",
    "            fa_connectome_triu_v = np.array(fa_connectome)[fa_connectome_triu_indices]\n",
    "\n",
    "            fa_connectome_mean_list.append(fa_connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {fa_file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df and indices')\n",
    "\n",
    "fa_connectome_mean_full_df = pd.DataFrame(fa_connectome_mean_list, index = index_list)\n",
    "fa_connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_FA_10M/31021_aparc_Tian_S1_fa_connectome_mean_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_FA_10M/31021_aparc_Tian_S1_full_id_full.csv', index=False)  \n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "fa_connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, fa in zip(index_list, fa_connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        fa_connectome_instance_2.append(fa)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31021_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_FA_10M/31021_aparc_Tian_S1_full_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del fa_connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "fa_connectome_instance_2_df = pd.DataFrame(fa_connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "fa_connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_FA_10M/31021_aparc_Tian_S1_fa_connectome_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del fa_connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_length_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_mean_length_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_length_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_length_10M/31021_aparc_Tian_S1_connectome_mean_length_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_length_10M/31021_aparc_Tian_S1_connectome_mean_length_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31021_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_length_10M/31021_aparc_Tian_S1_connectome_mean_length_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_mean_length_10M/31021_aparc_Tian_S1_connectome_mean_length_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_sift2_fbc_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_sift2_fbc_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_sift2_fbc_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_sift2_fbc_10M/31021_aparc_Tian_S1_connectome_sift2_fbc_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_sift2_fbc_10M/31021_aparc_Tian_S1_connectome_sift2_fbc_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31021_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_sift2_fbc_10M/31021_aparc_Tian_S1_connectome_sift2_fbc_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_sift2_fbc_10M/31021_aparc_Tian_S1_connectome_sift2_fbc_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_streamline_count_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_streamline_count_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_streamline_count_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_streamline_count_10M/31021_aparc_Tian_S1_connectome_streamline_count_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_streamline_count_10M/31021_aparc_Tian_S1_connectome_streamline_count_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31021_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_streamline_count_10M/31021_aparc_Tian_S1_connectome_streamline_count_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31021_aparc_Tian_S1/Connectome_streamline_count_10M/31021_aparc_Tian_S1_connectome_streamline_count_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31022_Glasser_Tian_S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31022_Glasser_Tian_S1/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31022_Glasser_Tian_S1/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31022_Glasser_Tian_S1/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31022_Glasser_Tian_S1/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31022_Glasser_Tian_S1/42892/unzipped/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_FA_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_count = 0\n",
    "\n",
    "fa_connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        fa_file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(fa_file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fa_connectome = pd.read_csv(fa_file, header=None)\n",
    "            fa_connectome_triu_indices = np.triu_indices(len(np.array(fa_connectome)), k=0)\n",
    "            fa_connectome_triu_v = np.array(fa_connectome)[fa_connectome_triu_indices]\n",
    "\n",
    "            fa_connectome_mean_list.append(fa_connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {fa_file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df and indices')\n",
    "\n",
    "fa_connectome_mean_full_df = pd.DataFrame(fa_connectome_mean_list, index = index_list)\n",
    "fa_connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_FA_10M/31022_Glasser_Tian_S1_fa_connectome_mean_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_FA_10M/31022_Glasser_Tian_S1_full_id_full.csv', index=False)  \n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "fa_connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, fa in zip(index_list, fa_connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        fa_connectome_instance_2.append(fa)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31022_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_FA_10M/31022_Glasser_Tian_S1_full_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del fa_connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "fa_connectome_instance_2_df = pd.DataFrame(fa_connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "fa_connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_FA_10M/31022_Glasser_Tian_S1_fa_connectome_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del fa_connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_length_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_mean_length_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_length_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_length_10M/31022_Glasser_Tian_S1_connectome_mean_length_10M_full_df.csv')\n",
    "\n",
    "del connectome_mean_full_df #!!!!!!\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_length_10M/31022_Glasser_Tian_S1_connectome_mean_length_10M_full_id.csv', index=False)  \n",
    "\n",
    "del index_list_df #!!!!!!\n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list): \n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31022_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_length_10M/31022_Glasser_Tian_S1_connectome_mean_length_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "gc.collect()\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "gc.collect()\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_mean_length_10M/31022_Glasser_Tian_S1_connectome_mean_length_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_sift2_fbc_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_sift2_fbc_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_sift2_fbc_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_sift2_fbc_10M/31022_Glasser_Tian_S1_connectome_sift2_fbc_10M_full_df.csv')\n",
    "del connectome_mean_full_df\n",
    "\n",
    "print('Saving full indices')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_sift2_fbc_10M/31022_Glasser_Tian_S1_connectome_sift2_fbc_10M_full_id.csv', index=False)  \n",
    "del index_list_df\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31022_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_sift2_fbc_10M/31022_Glasser_Tian_S1_connectome_sift2_fbc_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_sift2_fbc_10M/31022_Glasser_Tian_S1_connectome_sift2_fbc_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_streamline_count_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_streamline_count_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_streamline_count_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print(\"Length of the full set:\", len(connectome_mean_list))\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_streamline_count_10M/31022_Glasser_Tian_S1_connectome_streamline_count_10M_full_df.csv')\n",
    "del connectome_mean_full_df \n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_streamline_count_10M/31022_Glasser_Tian_S1_connectome_streamline_count_10M_full_id.csv', index=False)  \n",
    "del index_list_df\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print(\"Length of the instance 2 set:\", len(connectome_instance_2))\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31022_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_streamline_count_10M/31022_Glasser_Tian_S1_connectome_streamline_count_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "#del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31022_Glasser_Tian_S1/Connectome_streamline_count_10M/31022_Glasser_Tian_S1_connectome_streamline_count_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31023_Glasser_Tian_S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31023_Glasser_Tian_S4/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31023_Glasser_Tian_S4/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31023_Glasser_Tian_S4/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31023_Glasser_Tian_S4/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31023_Glasser_Tian_S4/42887/unzipped/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_FA_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_count = 0\n",
    "\n",
    "fa_connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        fa_file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(fa_file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fa_connectome = pd.read_csv(fa_file, header=None)\n",
    "            fa_connectome_triu_indices = np.triu_indices(len(np.array(fa_connectome)), k=0)\n",
    "            fa_connectome_triu_v = np.array(fa_connectome)[fa_connectome_triu_indices]\n",
    "\n",
    "            fa_connectome_mean_list.append(fa_connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {fa_file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print(\"Length of the full set:\", len(fa_connectome_mean_list))\n",
    "\n",
    "print('Saving full indices')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_FA_10M/31023_Glasser_Tian_S4_full_id_full.csv', index=False)  \n",
    "del index_list_df\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df')\n",
    "\n",
    "fa_connectome_mean_full_df = pd.DataFrame(fa_connectome_mean_list, index = index_list)\n",
    "fa_connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_FA_10M/31023_Glasser_Tian_S4_fa_connectome_mean_full_df.csv')\n",
    "\n",
    "del fa_connectome_mean_full_df\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "fa_connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, fa in zip(index_list, fa_connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        fa_connectome_instance_2.append(fa)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31023_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_FA_10M/31023_Glasser_Tian_S4_full_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "fa_connectome_instance_2_df = pd.DataFrame(fa_connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del fa_connectome_mean_list\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "fa_connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_FA_10M/31023_Glasser_Tian_S4_fa_connectome_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del index_instance_2\n",
    "del fa_connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_length_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_mean_length_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_length_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_length_10M/31023_Glasser_Tian_S4_connectome_mean_length_10M_full_id.csv', index=False)  \n",
    "del index_list_df\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_length_10M/31023_Glasser_Tian_S4_connectome_mean_length_10M_full_df.csv')\n",
    "\n",
    "del connectome_mean_full_df\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31023_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_length_10M/31023_Glasser_Tian_S4_connectome_mean_length_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del index_instance_2\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_mean_length_10M/31023_Glasser_Tian_S4_connectome_mean_length_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_sift2_fbc_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_sift2_fbc_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_sift2_fbc_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            codel index_list_df\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_sift2_fbc_10M/31023_Glasser_Tian_S4_connectome_sift2_fbc_10M_full_id.csv', index=False)  \n",
    "del index_list_df\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_sift2_fbc_10M/31023_Glasser_Tian_S4_connectome_sift2_fbc_10M_full_df.csv')\n",
    "del connectome_mean_full_df\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31023_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_sift2_fbc_10M/31023_Glasser_Tian_S4_connectome_sift2_fbc_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_sift2_fbc_10M/31023_Glasser_Tian_S4_connectome_sift2_fbc_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_streamline_count_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_streamline_count_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_streamline_count_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full indices')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_streamline_count_10M/31023_Glasser_Tian_S4_connectome_streamline_count_10M_full_id.csv', index=False)  \n",
    "del index_list_df\n",
    "\n",
    "print('Saving full df')\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_streamline_count_10M/31023_Glasser_Tian_S4_connectome_streamline_count_10M_full_df.csv')\n",
    "del connectome_mean_full_df\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31023_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_streamline_count_10M/31023_Glasser_Tian_S4_connectome_streamline_count_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31023_Glasser_Tian_S4/Connectome_streamline_count_10M/31023_Glasser_Tian_S4_connectome_streamline_count_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31024_Schaefer7n1000p_Tian_S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31024_Schaefer7n1000p_Tian_S4/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31024_Schaefer7n1000p_Tian_S4/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31024_Schaefer7n1000p_Tian_S4/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31024_Schaefer7n1000p_Tian_S4/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31024_Schaefer7n1000p_Tian_S4/42891/unzipped/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_FA_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_count = 0\n",
    "\n",
    "fa_connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        fa_file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(fa_file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fa_connectome = pd.read_csv(fa_file, header=None)\n",
    "            fa_connectome_triu_indices = np.triu_indices(len(np.array(fa_connectome)), k=0)\n",
    "            fa_connectome_triu_v = np.array(fa_connectome)[fa_connectome_triu_indices]\n",
    "\n",
    "            fa_connectome_mean_list.append(fa_connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {fa_file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df and indices')\n",
    "\n",
    "fa_connectome_mean_full_df = pd.DataFrame(fa_connectome_mean_list, index = index_list)\n",
    "fa_connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_FA_10M/31024_Schaefer7n1000p_Tian_S4_fa_connectome_mean_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_FA_10M/31024_Schaefer7n1000p_Tian_S4_full_id_full.csv', index=False)  \n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "fa_connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, fa in zip(index_list, fa_connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        fa_connectome_instance_2.append(fa)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31024_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_FA_10M/31024_Schaefer7n1000p_Tian_S4_full_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del fa_connectome_mean_list\n",
    "\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "fa_connectome_instance_2_df = pd.DataFrame(fa_connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "fa_connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_FA_10M/31024_Schaefer7n1000p_Tian_S4_fa_connectome_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del fa_connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_length_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_mean_length_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_length_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_length_10M/31024_Schaefer7n1000p_Tian_S4_connectome_mean_length_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_length_10M/31024_Schaefer7n1000p_Tian_S4_connectome_mean_length_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31024_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_length_10M/31024_Schaefer7n1000p_Tian_S4_connectome_mean_length_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_mean_length_10M/31024_Schaefer7n1000p_Tian_S4_connectome_mean_length_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_sift2_fbc_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_sift2_fbc_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_sift2_fbc_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_sift2_fbc_10M/31024_Schaefer7n1000p_Tian_S4_connectome_sift2_fbc_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_sift2_fbc_10M/31024_Schaefer7n1000p_Tian_S4_connectome_sift2_fbc_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31024_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_sift2_fbc_10M/31024_Schaefer7n1000p_Tian_S4_connectome_sift2_fbc_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_sift2_fbc_10M/31024_Schaefer7n1000p_Tian_S4_connectome_sift2_fbc_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_streamline_count_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_streamline_count_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_streamline_count_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_streamline_count_10M/31024_Schaefer7n1000p_Tian_S4_connectome_streamline_count_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_streamline_count_10M/31024_Schaefer7n1000p_Tian_S4_connectome_streamline_count_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31024_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_streamline_count_10M/31024_Schaefer7n1000p_Tian_S4_connectome_streamline_count_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31024_Schaefer7n1000p_Tian_S4/Connectome_streamline_count_10M/31024_Schaefer7n1000p_Tian_S4_connectome_streamline_count_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31025_Schaefer7n200p_Tian_S1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31025_Schaefer7n200p_Tian_S1/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31025_Schaefer7n200p_Tian_S1/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31025_Schaefer7n200p_Tian_S1/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31025_Schaefer7n200p_Tian_S1/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31025_Schaefer7n200p_Tian_S1/42886/unzipped/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_FA_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_count = 0\n",
    "\n",
    "fa_connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        fa_file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(fa_file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fa_connectome = pd.read_csv(fa_file, header=None)\n",
    "            fa_connectome_triu_indices = np.triu_indices(len(np.array(fa_connectome)), k=0)\n",
    "            fa_connectome_triu_v = np.array(fa_connectome)[fa_connectome_triu_indices]\n",
    "\n",
    "            fa_connectome_mean_list.append(fa_connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {fa_file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full indices')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_FA_10M/31025_Schaefer7n200p_Tian_S1_full_id_full.csv', index=False)  \n",
    "del index_list_df\n",
    "gc.collect()\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df')\n",
    "\n",
    "fa_connectome_mean_full_df = pd.DataFrame(fa_connectome_mean_list, index = index_list)\n",
    "fa_connectome_mean_full_dict = fa_connectome_mean_full_df.to_dict (orient='list')\n",
    "#fa_connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_FA_10M/31025_Schaefer7n200p_Tian_S1_fa_connectome_mean_full_df.csv.gz', compression='gzip')\n",
    "\n",
    "with open(f'/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_FA_10M/31025_Schaefer7n200p_Tian_S1_fa_connectome_mean_full_df.csv', 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=fa_connectome_mean_full_df.columns)\n",
    "    if f.tell() == 0:\n",
    "        writer.writeheader()\n",
    "    writer.writerow(fa_connectome_mean_full_dict)\n",
    "\n",
    "\n",
    "del fa_connectome_mean_full_df\n",
    "gc.collect()\n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "fa_connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, fa in zip(index_list, fa_connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        fa_connectome_instance_2.append(fa)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31025_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_FA_10M/31025_Schaefer7n200p_Tian_S1_full_id_instance_2.csv', index=False)\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "fa_connectome_instance_2_df = pd.DataFrame(fa_connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "del index_list\n",
    "del fa_connectome_mean_list\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "fa_connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_FA_10M/31025_Schaefer7n200p_Tian_S1_fa_connectome_instance_2_df.csv.gz', compression='gzip', index_label='ID')\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_length_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_mean_length_10M\n",
    "\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_length_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving indices')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_length_10M/31025_Schaefer7n200p_Tian_S1_connectome_mean_length_10M_full_id.csv', index=False)  \n",
    "del index_list_df\n",
    "gc.collect() \n",
    "\n",
    "print('Saving full_df')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_length_10M/31025_Schaefer7n200p_Tian_S1_connectome_mean_length_10M_full_df.csv.gz', compression='gzip')\n",
    "del connectome_mean_full_df\n",
    "gc.collect() \n",
    "\n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31025_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_length_10M/31025_Schaefer7n200p_Tian_S1_connectome_mean_length_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_mean_length_10M/31025_Schaefer7n200p_Tian_S1_connectome_mean_length_10M_instance_2_df.csv.gz', compression='gzip', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_sift2_fbc_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_sift2_fbc_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_sift2_fbc_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_sift2_fbc_10M/31025_Schaefer7n200p_Tian_S1_connectome_sift2_fbc_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_sift2_fbc_10M/31025_Schaefer7n200p_Tian_S1_connectome_sift2_fbc_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31025_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_sift2_fbc_10M/31025_Schaefer7n200p_Tian_S1_connectome_sift2_fbc_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_sift2_fbc_10M/31025_Schaefer7n200p_Tian_S1_connectome_sift2_fbc_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_streamline_count_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_streamline_count_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_streamline_count_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_streamline_count_10M/31025_Schaefer7n200p_Tian_S1_connectome_streamline_count_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_streamline_count_10M/31025_Schaefer7n200p_Tian_S1_connectome_streamline_count_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31025_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_streamline_count_10M/31025_Schaefer7n200p_Tian_S1_connectome_streamline_count_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31025_Schaefer7n200p_Tian_S1/Connectome_streamline_count_10M/31025_Schaefer7n200p_Tian_S1_connectome_streamline_count_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 31026_Schaefer7n500p_Tian_S4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\"/Melbourne_BULK/DTI_connectome/31026_Schaefer7n500p_Tian_S4/10000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31026_Schaefer7n500p_Tian_S4/20000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31026_Schaefer7n500p_Tian_S4/30000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31026_Schaefer7n500p_Tian_S4/40000/unzipped/\",\n",
    "\"/Melbourne_BULK/DTI_connectome/31026_Schaefer7n500p_Tian_S4/42886/unzipped/\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_FA_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_file_count = 0\n",
    "\n",
    "fa_connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_FA_10M.csv\"\n",
    "\n",
    "        fa_file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(fa_file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            fa_connectome = pd.read_csv(fa_file, header=None)\n",
    "            fa_connectome_triu_indices = np.triu_indices(len(np.array(fa_connectome)), k=0)\n",
    "            fa_connectome_triu_v = np.array(fa_connectome)[fa_connectome_triu_indices]\n",
    "\n",
    "            fa_connectome_mean_list.append(fa_connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {fa_file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving fa_connectome_mean_full_df and indices')\n",
    "\n",
    "fa_connectome_mean_full_df = pd.DataFrame(fa_connectome_mean_list, index = index_list)\n",
    "fa_connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_FA_10M/31026_Schaefer7n500p_Tian_S4_fa_connectome_mean_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_FA_10M/31026_Schaefer7n500p_Tian_S4_full_id_full.csv', index=False)  \n",
    "\n",
    "print('Getting IDs and matrices for instance 2')\n",
    "\n",
    "fa_connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, fa in zip(index_list, fa_connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        fa_connectome_instance_2.append(fa)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31026_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_FA_10M/31026_Schaefer7n500p_Tian_S4_full_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del fa_connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "fa_connectome_instance_2_df = pd.DataFrame(fa_connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving connectome data frame instance 2')\n",
    "fa_connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_FA_10M/31026_Schaefer7n500p_Tian_S4_fa_connectome_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del fa_connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_mean_length_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_mean_length_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_mean_length_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_length_10M/31026_Schaefer7n500p_Tian_S4_connectome_mean_length_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_length_10M/31026_Schaefer7n500p_Tian_S4_connectome_mean_length_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31026_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_length_10M/31026_Schaefer7n500p_Tian_S4_connectome_mean_length_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_mean_length_10M/31026_Schaefer7n500p_Tian_S4_connectome_mean_length_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_sift2_fbc_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_sift2_fbc_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_sift2_fbc_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_sift2_fbc_10M/31026_Schaefer7n500p_Tian_S4_connectome_sift2_fbc_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_sift2_fbc_10M/31026_Schaefer7n500p_Tian_S4_connectome_sift2_fbc_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31026_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_sift2_fbc_10M/31026_Schaefer7n500p_Tian_S4_connectome_sift2_fbc_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_sift2_fbc_10M/31026_Schaefer7n500p_Tian_S4_connectome_sift2_fbc_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connectome_streamline_count_10M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connectome_streamline_count_10M\n",
    "missing_file_count = 0\n",
    "\n",
    "connectome_mean_list = []\n",
    "index_list = []\n",
    "skipped_folders = []\n",
    "\n",
    "for folder_path in folder_paths:\n",
    "\n",
    "    print(f'Started {folder_path}')\n",
    "\n",
    "    for subject_folder in sorted(os.listdir(folder_path)):\n",
    "        subfolder_path = os.path.join(folder_path, subject_folder)\n",
    "        subject_folder_name = os.path.basename(subfolder_path)\n",
    "        \n",
    "        csv_file = \"connectome_streamline_count_10M.csv\"\n",
    "\n",
    "        file = os.path.join(subfolder_path, csv_file)\n",
    "\n",
    "        if not os.path.exists(file):\n",
    "            missing_file_count += 1\n",
    "            skipped_folders.append(subfolder_path)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            connectome = pd.read_csv(file, header=None)\n",
    "            connectome_triu_indices = np.triu_indices(len(np.array(connectome)), k=0)\n",
    "            connectome_triu_v = np.array(connectome)[connectome_triu_indices]\n",
    "\n",
    "            connectome_mean_list.append(connectome_triu_v)\n",
    "            index_list.append(subject_folder_name)\n",
    "            \n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(f\"Skipping empty file: {file}\")\n",
    "            continue\n",
    "\n",
    "print('Number of folders without the file:', missing_file_count)\n",
    "print('Skipped folders:', *skipped_folders, sep='\\n')\n",
    "\n",
    "print('Saving full_df and indices')\n",
    "\n",
    "connectome_mean_full_df = pd.DataFrame(connectome_mean_list, index = index_list)\n",
    "connectome_mean_full_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_streamline_count_10M/31026_Schaefer7n500p_Tian_S4_connectome_streamline_count_10M_full_df.csv')\n",
    "\n",
    "index_list_df = pd.DataFrame(index_list, columns = ['ID'])\n",
    "index_list_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_streamline_count_10M/31026_Schaefer7n500p_Tian_S4_connectome_streamline_count_10M_full_id.csv', index=False)  \n",
    "\n",
    "print('Getting IDs for instance 2')\n",
    "\n",
    "connectome_instance_2 = []\n",
    "index_instance_2 = []\n",
    "\n",
    "for folder_name, c in zip(index_list, connectome_mean_list):\n",
    "    mid_part = folder_name.split(\"_\")[-2]\n",
    "    if mid_part == '2':\n",
    "        connectome_instance_2.append(c)\n",
    "        index_instance_2.append(folder_name)\n",
    "\n",
    "print('Converting instance 2 indices to the data frame') \n",
    "index_instance_2_df = pd.DataFrame(index_instance_2, columns = ['ID'])\n",
    "index_instance_2_df['ID'] = index_instance_2_df['ID'].str.replace('_31026_2_0', '')\n",
    "index_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_streamline_count_10M/31026_Schaefer7n500p_Tian_S4_connectome_streamline_count_10M_id_instance_2.csv', index=False)\n",
    "\n",
    "del index_list\n",
    "del connectome_mean_list\n",
    "\n",
    "print('Getting connectome data frame for instance 2')\n",
    "connectome_instance_2_df = pd.DataFrame(connectome_instance_2, index = index_instance_2_df['ID'].to_list())\n",
    "\n",
    "del index_instance_2\n",
    "\n",
    "print('Saving instance 2')\n",
    "connectome_instance_2_df.to_csv('/ML_DATASETS/Brain/DTI/Structural_matrices/31026_Schaefer7n500p_Tian_S4/Connectome_streamline_count_10M/31026_Schaefer7n500p_Tian_S4_connectome_streamline_count_10M_instance_2_df.csv', index_label='ID')\n",
    "\n",
    "del connectome_instance_2_df\n",
    "del index_instance_2_df\n",
    "\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
