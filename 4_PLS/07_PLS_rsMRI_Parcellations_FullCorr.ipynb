{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import sys\n",
    "import warnings\n",
    "import skbold\n",
    "from skbold.preproc import ConfoundRegressor\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "## Define ConfoundRegressor\n",
    "def confound_regressor(features_train, features_test, confounds_train, confounds_test):\n",
    "    # Scale features (train and test sets)\n",
    "    scaler_features = StandardScaler()\n",
    "    features_train_scaled = scaler_features.fit_transform(features_train)\n",
    "    features_test_scaled = scaler_features.transform(features_test)\n",
    "    \n",
    "    # Scale confounds (train and test sets)\n",
    "    scaler_confounds = StandardScaler()\n",
    "    confounds_train_scaled = scaler_confounds.fit_transform(confounds_train)\n",
    "    confounds_test_scaled = scaler_confounds.transform(confounds_test)\n",
    "    \n",
    "    # Convert full sets into np.array\n",
    "    features_full_scaled_np = np.array(pd.concat([pd.DataFrame(features_train_scaled, columns = features_train.columns), pd.DataFrame(features_test_scaled, columns = features_test.columns)], axis=0))\n",
    "    confounds_full_scaled_np = np.array(pd.concat([pd.DataFrame(confounds_train_scaled, columns = confounds_train.columns), pd.DataFrame(confounds_test_scaled, columns = confounds_test.columns)], axis=0))\n",
    "    \n",
    "    # Define ConfoundRegressor on a FULL set (train and test)\n",
    "    cfr = ConfoundRegressor(confound=confounds_full_scaled_np, X=features_full_scaled_np)\n",
    "    features_train_corrected = cfr.fit_transform(features_train_scaled)\n",
    "    features_test_corrected = cfr.transform(features_test_scaled)\n",
    "    return features_train_corrected, features_test_corrected, features_train_scaled, features_test_scaled, scaler_features, scaler_confounds\n",
    "\n",
    "## Define modalities\n",
    "modalities = [\n",
    "'aparc_2009_Tian_s1_arrays_full_correlation',\n",
    "'aparc_2009_Tian_s2_arrays_full_correlation',\n",
    "'aparc_2009_Tian_s3_arrays_full_correlation',\n",
    "'aparc_2009_Tian_s4_arrays_full_correlation']\n",
    "\n",
    "modalities = [\n",
    "'glasser_Tian_s1_arrays_full_correlation',\n",
    "'glasser_Tian_s2_arrays_full_correlation',\n",
    "'glasser_Tian_s3_arrays_full_correlation',\n",
    "'glasser_Tian_s4_arrays_full_correlation']\n",
    "\n",
    "modalities = [\n",
    "'aparc_Tian_s1_arrays_full_correlation',\n",
    "'aparc_Tian_s2_arrays_full_correlation',\n",
    "'aparc_Tian_s3_arrays_full_correlation',\n",
    "'aparc_Tian_s4_arrays_full_correlation']\n",
    "\n",
    "modalities = [\n",
    "'Schaefer7n200p_tian_s1_arrays_full_correlation_with_id',\n",
    "'Schaefer7n200p_tian_s2_arrays_full_correlation_with_id',\n",
    "'Schaefer7n200p_tian_s3_arrays_full_correlation_with_id',\n",
    "'Schaefer7n200p_tian_s4_arrays_full_correlation_with_id']\n",
    "\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "###################################################### Preparatory steps\n",
    "#for i in range(0,80):\n",
    "    #fold = i % 5\n",
    "    #model = i // 5\n",
    "    #print(fold, model, folds[fold], modalities[modal])\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "seed = 42\n",
    "pls_result = {}\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    fold = int(sys.argv[1]) % 5\n",
    "    modal = int(sys.argv[1]) // 5\n",
    "\n",
    "print(f'Started {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "#####################################################\n",
    "\n",
    "print('Reading confounds', flush=True)\n",
    "confounds = pd.read_csv('/PLS/pls_rs/pls_idp/main/resting_files/rs_confounds.csv')\n",
    "\n",
    "############## 1\n",
    "print(f'Reading {modalities[modal]}', flush=True)\n",
    "\n",
    "file = pd.read_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/resting_files/{modalities[modal]}.csv').rename(columns={'Unnamed: 0':'eid'})\n",
    "\n",
    "# Match confounds to MRI\n",
    "print(f'Matching full brain data to confounds in {modalities[modal]}', flush=True)\n",
    "\n",
    "conf_to_brain_match = pd.merge(confounds, file['eid'], on='eid')\n",
    "brain_to_conf_match = pd.merge(conf_to_brain_match['eid'], file, on='eid')\n",
    "\n",
    "print('Reading train/test sets and g-factor', flush=True)\n",
    "test_id = pd.read_csv(f'/PLS/pls_dti/fold_id/test_id_fold_{folds[fold]}.csv')\n",
    "train_id = pd.read_csv(f'/PLS/pls_dti/fold_id/train_id_fold_{folds[fold]}.csv') \n",
    "\n",
    "# Upload g-factor with ID\n",
    "g_train_full = pd.read_csv(f'/PLS/pls_dti/g_factor/g_train_with_id_fold_{folds[fold]}.csv')\n",
    "g_test_full = pd.read_csv(f'/PLS/pls_dti/g_factor/g_test_with_id_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "# Match brain data to cognitive data\n",
    "print(f'Matching brain data to train/test confounds in {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "brain_train, brain_test, brain_train_id, brain_test_id = pd.merge(brain_to_conf_match, train_id, on='eid').drop(columns=['eid']), pd.merge(brain_to_conf_match, test_id, on='eid').drop(columns=['eid']), pd.merge(brain_to_conf_match, train_id, on='eid')['eid'], pd.merge(brain_to_conf_match, test_id, on='eid')['eid']\n",
    "\n",
    "brain_train.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/{modalities[modal]}_train_fold_{folds[fold]}.csv', index=False)\n",
    "brain_test.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/{modalities[modal]}_test_fold_{folds[fold]}.csv', index=False)\n",
    "brain_train_id.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/{modalities[modal]}_train_id_fold_{folds[fold]}.csv', index=False)\n",
    "brain_test_id.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/{modalities[modal]}_test_id_fold_{folds[fold]}.csv', index=False)\n",
    "\n",
    "############## 2\n",
    "# Match confounds to MRI\n",
    "brain_conf_train, brain_conf_test = pd.merge(conf_to_brain_match, brain_train_id, on='eid').drop(columns=['eid']), pd.merge(conf_to_brain_match, brain_test_id, on='eid').drop(columns=['eid'])\n",
    "brain_conf_train.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/{modalities[modal]}_conf_train_fold_{folds[fold]}.csv', index=False)\n",
    "brain_conf_test.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/{modalities[modal]}_conf_test_fold_{folds[fold]}.csv', index=False)\n",
    "\n",
    "############## 3\n",
    "print(f'Matching g-factor to {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "\n",
    "# Match g-factor back to DTI\n",
    "g_train, g_test, g_train_id, g_test_id = pd.merge(g_train_full, brain_train_id, on='eid').drop(columns=['eid']), pd.merge(g_test_full, brain_test_id, on='eid').drop(columns=['eid']), pd.merge(g_train_full, brain_train_id, on='eid')['eid'], pd.merge(g_test_full, brain_test_id, on='eid')['eid']\n",
    "g_train.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/g_train_{modalities[modal]}_matched_fold_{folds[fold]}.csv', index=False)\n",
    "g_test.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/suppl/g_test_{modalities[modal]}_matched_fold_{folds[fold]}.csv', index=False)\n",
    "\n",
    "############## 4\n",
    "print(f'Applying ConfoundRegressor to {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "\n",
    "# Apply ConfoundRegressor\n",
    "features_train_corr, features_test_corr, features_train_scaled, features_test_scaled, scaler_features, scaler_confounds = confound_regressor(brain_train, brain_test, brain_conf_train, brain_conf_test)\n",
    "pd.DataFrame(features_train_corr, columns = brain_train.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/scaling/{modalities[modal]}_train_corr_{folds[fold]}.csv', index=False)\n",
    "pd.DataFrame(features_test_corr, columns = brain_test.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/scaling/{modalities[modal]}_test_corr_{folds[fold]}.csv', index=False)\n",
    "\n",
    "pd.DataFrame(features_train_scaled, columns = brain_train.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/scaling/{modalities[modal]}_train_scaled_{folds[fold]}.csv', index=False)\n",
    "pd.DataFrame(features_test_scaled, columns = brain_test.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/scaling/{modalities[modal]}_test_scaled_{folds[fold]}.csv', index=False)\n",
    "\n",
    "\n",
    "with open(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/scaling/scaler_features_{modalities[modal]}_fold_{folds[fold]}.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_features, f)\n",
    "\n",
    "with open(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/scaling/scaler_confounds_{modalities[modal]}_fold_{folds[fold]}.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_confounds, f)\n",
    "\n",
    "# Initiate and run PLS\n",
    "parameters = {'n_components': range(1, 36, 1)}\n",
    "pls = PLSRegression()\n",
    "model = GridSearchCV(pls, parameters, scoring = 'neg_mean_absolute_error', cv=KFold(10, shuffle = True, random_state=seed), verbose=4, n_jobs = 25)\n",
    "\n",
    "\n",
    "print(f'Fitting PLS to {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "\n",
    "model.fit(features_train_corr, np.array(g_train))\n",
    "\n",
    "print(f'Model parameters for fold {folds[fold]}:', model.cv_results_['params'])\n",
    "print(f'Mean test score for fold {folds[fold]}:', model.cv_results_['mean_test_score'])\n",
    "print(f'Rank test score for fold {folds[fold]}:', model.cv_results_['rank_test_score'])\n",
    "print(model)\n",
    "\n",
    "print(f'Saving PLS model for {modalities[modal]} fold {folds[fold]}')\n",
    "with open(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/models/pkl/{modalities[modal]}_model_fold_{folds[fold]}.pkl', \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f'Best params in fold {folds[fold]} = ', model.best_params_)\n",
    "print(f'Best score (neg_mean_absolute_error) in fold {folds[fold]} = ', model.best_score_)\n",
    "\n",
    "# Predict the values\n",
    "print(f'Predicting & saving g_test for {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "g_pred_test = model.predict(np.array(features_test_corr))\n",
    "pd.DataFrame(g_pred_test, columns=['g predicted test']).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/g_pred/{modalities[modal]}_test_fold_{folds[fold]}.csv')\n",
    "\n",
    "g_pred_test_with_id = pd.concat([g_test_id.astype(int), pd.DataFrame(g_pred_test, columns=['g predicted test'])], axis=1).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/g_pred/{modalities[modal]}_g_pred_test_id_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "print(f'Predicting & saving g_train for {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "g_pred_train = model.predict(np.array(features_train_corr))\n",
    "pd.DataFrame(g_pred_train, columns=['g predicted train']).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/g_pred/{modalities[modal]}_g_pred_train_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "g_pred_train_with_id = pd.concat([g_train_id.astype(int), pd.DataFrame(g_pred_train, columns=['g predicted train'])], axis=1).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/g_pred/{modalities[modal]}_g_pred_train_id_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "print(f\"Fold = {folds[fold]}\")\n",
    "print(\"----------\")\n",
    "print(\"MSE = \", mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"MAE = \", mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"R2 = \", r2_score(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"Pearson's r = \", pearsonr(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"----------\")\n",
    "\n",
    "pls_result['fold'] = folds[fold]\n",
    "pls_result['modalities'] = modalities[modal]\n",
    "pls_result['n_components'] = model.best_params_\n",
    "pls_result['MSE'] = mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['MAE'] = mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['R2'] = r2_score(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['Pearson r'] = pearsonr(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "\n",
    "print(f'Saving PLS result for {modalities[modal]} fold {folds[fold]}', flush=True)\n",
    "with open(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/models/csv/{modalities[modal]}_fold_{folds[fold]}_PLS_result.csv', 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=pls_result.keys())\n",
    "    writer.writerow(pls_result)\n",
    "\n",
    "pls_result.clear()\n",
    "\n",
    "corr, pval = stats.pearsonr(np.squeeze(np.array(g_test)), np.squeeze(g_pred_test))\n",
    "r2 = r2_score(np.squeeze(np.array(g_test)), np.squeeze(g_pred_test))\n",
    "mse = mean_squared_error(np.squeeze(np.array(g_test)), np.squeeze(g_pred_test))\n",
    "result = pd.DataFrame([modalities[modal], fold, corr, pval, r2, mse, model.best_params_], index=['modalities[modal]', 'Fold', 'Correlation', 'P-value', 'R2', 'MSE', 'n components'], columns=['Values']).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/aparc_2009/fold_{folds[fold]}/models/csv/{modalities[modal]}_fold_{folds[fold]}_full_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schaefer 7n500p + MSA-IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because files are very big, deconfounding and PLS are done separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deconfound\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "subcortical = ['s1', 's2', 's3', 's4']\n",
    "\n",
    "###################################################### Preparatory steps\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "seed = 42\n",
    "pls_result = {}\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    fold = int(sys.argv[1]) % 5\n",
    "    subcort = int(sys.argv[1]) // 5\n",
    "\n",
    "print(f'Started {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "#####################################################\n",
    "\n",
    "print('Reading confounds', flush=True)\n",
    "confounds = pd.read_csv('/PLS/pls_rs/pls_idp/main/resting_files/rs_confounds.csv')\n",
    "\n",
    "############## 1\n",
    "print(f'Reading {subcortical[subcort]}', flush=True)\n",
    "\n",
    "file = pd.read_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/resting_files/Schaefer7n500p_tian_{subcortical[subcort]}_arrays_full_correlation.csv').rename(columns={'Unnamed: 0':'eid'})\n",
    "\n",
    "# Match confounds to MRI\n",
    "print(f'Matching full brain data to confounds in {subcortical[subcort]}', flush=True)\n",
    "\n",
    "conf_to_brain_match = pd.merge(confounds, file['eid'], on='eid')\n",
    "brain_to_conf_match = pd.merge(conf_to_brain_match['eid'], file, on='eid')\n",
    "\n",
    "print('Reading train/test sets and g-factor', flush=True)\n",
    "# Upload g-factor with ID\n",
    "g_train_full = pd.read_csv(f'/PLS/pls_dti/g_factor/g_train_with_id_fold_{folds[fold]}.csv')\n",
    "g_test_full = pd.read_csv(f'/PLS/pls_dti/g_factor/g_test_with_id_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "# Match brain data to cognitive data\n",
    "print(f'Matching brain data to train/test confounds in {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "brain_train, brain_test, brain_train_id, brain_test_id = pd.merge(brain_to_conf_match, g_train_full['eid'], on='eid').drop(columns=['eid']), pd.merge(brain_to_conf_match, g_test_full['eid'], on='eid').drop(columns=['eid']), pd.merge(brain_to_conf_match, g_train_full['eid'], on='eid')['eid'], pd.merge(brain_to_conf_match, g_test_full['eid'], on='eid')['eid']\n",
    "\n",
    "brain_train.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_train_fold_{folds[fold]}.csv', index=False)\n",
    "brain_test.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_test_fold_{folds[fold]}.csv', index=False)\n",
    "brain_train_id.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_train_id_fold_{folds[fold]}.csv', index=False)\n",
    "brain_test_id.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_test_id_fold_{folds[fold]}.csv', index=False)\n",
    "\n",
    "############## 2\n",
    "# Match confounds to MRI\n",
    "brain_conf_train, brain_conf_test = pd.merge(conf_to_brain_match, brain_train_id, on='eid').drop(columns=['eid']), pd.merge(conf_to_brain_match, brain_test_id, on='eid').drop(columns=['eid'])\n",
    "brain_conf_train.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_conf_train_fold_{folds[fold]}.csv', index=False)\n",
    "brain_conf_test.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_conf_test_fold_{folds[fold]}.csv', index=False)\n",
    "\n",
    "############## 3\n",
    "print(f'Matching g-factor to {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "\n",
    "# Match g-factor back to MRI\n",
    "g_train, g_test, g_train_id, g_test_id = pd.merge(g_train_full, brain_train_id, on='eid').drop(columns=['eid']), pd.merge(g_test_full, brain_test_id, on='eid').drop(columns=['eid']), pd.merge(g_train_full, brain_train_id, on='eid')['eid'], pd.merge(g_test_full, brain_test_id, on='eid')['eid']\n",
    "g_train.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_train_Schaefer7n500p_{subcortical[subcort]}_full_correlation_matched_fold_{folds[fold]}.csv', index=False)\n",
    "g_test.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_test_Schaefer7n500p_{subcortical[subcort]}_full_correlation_matched_fold_{folds[fold]}.csv', index=False)\n",
    "g_train_id.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_train_id_Schaefer7n500p_{subcortical[subcort]}_full_correlation_matched_fold_{folds[fold]}.csv', index=False)\n",
    "g_test_id.to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_test_id_Schaefer7n500p_{subcortical[subcort]}_full_correlation_matched_fold_{folds[fold]}.csv', index=False)\n",
    "\n",
    "############## 4\n",
    "print(f'Applying ConfoundRegressor to {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "\n",
    "# Apply ConfoundRegressor\n",
    "features_train_corr, features_test_corr, features_train_scaled, features_test_scaled, scaler_features = confound_regressor(brain_train, brain_test, brain_conf_train, brain_conf_test)\n",
    "pd.DataFrame(features_train_corr, columns = brain_train.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/scaling/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_train_corr_{folds[fold]}.csv', index=False)\n",
    "pd.DataFrame(features_test_corr, columns = brain_test.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/scaling/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_test_corr_{folds[fold]}.csv', index=False)\n",
    "\n",
    "pd.DataFrame(features_train_scaled, columns = brain_train.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/scaling/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_train_scaled_{folds[fold]}.csv', index=False)\n",
    "pd.DataFrame(features_test_scaled, columns = brain_test.columns).to_csv(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/scaling/fc/Schaefer7n500p_{subcortical[subcort]}_full_correlation_test_scaled_{folds[fold]}.csv', index=False)\n",
    "\n",
    "\n",
    "with open(f'/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/scaling/fc/scaler_features_Schaefer7n500p_{subcortical[subcort]}_full_correlation_fold_{folds[fold]}.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_features, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define modalities\n",
    "subcortical = ['s1', 's2', 's3', 's4']\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "seed = 42\n",
    "pls_result = {}\n",
    "\n",
    "if len(sys.argv) > 1:\n",
    "    fold = int(sys.argv[1]) % 5\n",
    "    subcort = int(sys.argv[1]) // 5\n",
    "\n",
    "###################################################### Preparatory steps\n",
    "features_train_corr = pd.read_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/scaling/fc/Schaefer7n500p_{subcortical[subcort]}_train_corr_{folds[fold]}.csv',)\n",
    "features_test_corr = pd.read_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/scaling/fc/Schaefer7n500p_{subcortical[subcort]}_test_corr_{folds[fold]}.csv')\n",
    "\n",
    "g_test_id = pd.read_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_test_id_Schaefer7n500p_{subcortical[subcort]}_matched_fold_{folds[fold]}.csv')\n",
    "g_train_id = pd.read_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_train_id_Schaefer7n500p_{subcortical[subcort]}_matched_fold_{folds[fold]}.csv')\n",
    "\n",
    "g_test = pd.read_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_test_Schaefer7n500p_{subcortical[subcort]}_matched_fold_{folds[fold]}.csv')\n",
    "g_train = pd.read_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/suppl/fc/g_train_Schaefer7n500p_{subcortical[subcort]}_matched_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "# Initiate and run PLS\n",
    "parameters = {'n_components': range(1, 26, 1)}\n",
    "pls = PLSRegression()\n",
    "model = GridSearchCV(pls, parameters, scoring = 'neg_mean_absolute_error', cv=KFold(10, shuffle = True, random_state=seed), verbose=4)\n",
    "\n",
    "#############\n",
    "print(f'Fitting PLS to {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "\n",
    "model.fit(features_train_corr, np.array(g_train))\n",
    "\n",
    "print(f'Model parameters for fold {folds[fold]}:', model.cv_results_['params'])\n",
    "print(f'Mean test score for fold {folds[fold]}:', model.cv_results_['mean_test_score'])\n",
    "print(f'Rank test score for fold {folds[fold]}:', model.cv_results_['rank_test_score'])\n",
    "print(model)\n",
    "\n",
    "print(f'Saving PLS model for {subcortical[subcort]} fold {folds[fold]}')\n",
    "with open(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/models/pkl/Schaefer7n500p_{subcortical[subcort]}_full_correlation_model_fold_{folds[fold]}.pkl', \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f'Best params in fold {folds[fold]} = ', model.best_params_)\n",
    "print(f'Best score (neg_mean_absolute_error) in fold {folds[fold]} = ', model.best_score_)\n",
    "\n",
    "# Predict the values\n",
    "print(f'Predicting & saving g_test for {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "g_pred_test = model.predict(np.array(features_test_corr))\n",
    "pd.DataFrame(g_pred_test, columns=['g predicted test']).to_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/g_pred/Schaefer7n500p_{subcortical[subcort]}_full_correlation_test_fold_{folds[fold]}.csv')\n",
    "\n",
    "g_pred_test_with_id = pd.concat([g_test_id.astype(int), pd.DataFrame(g_pred_test, columns=['g predicted test'])], axis=1).to_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/g_pred/Schaefer7n500p_{subcortical[subcort]}_full_correlation_g_pred_test_id_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "print(f'Predicting & saving g_train for {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "g_pred_train = model.predict(np.array(features_train_corr))\n",
    "pd.DataFrame(g_pred_train, columns=['g predicted train']).to_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/g_pred/Schaefer7n500p_{subcortical[subcort]}_full_correlation_g_pred_train_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "g_pred_train_with_id = pd.concat([g_train_id.astype(int), pd.DataFrame(g_pred_train, columns=['g predicted train'])], axis=1).to_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/g_pred/Schaefer7n500p_{subcortical[subcort]}_full_correlation_g_pred_train_id_fold_{folds[fold]}.csv')\n",
    "\n",
    "\n",
    "print(f\"Fold = {folds[fold]}\")\n",
    "print(\"----------\")\n",
    "print(\"MSE = \", mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"MAE = \", mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"R2 = \", r2_score(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"Pearson's r = \", pearsonr(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"----------\")\n",
    "\n",
    "pls_result['fold'] = folds[fold]\n",
    "pls_result['modalities'] = subcortical[subcort]\n",
    "pls_result['n_components'] = model.best_params_\n",
    "pls_result['MSE'] = mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['MAE'] = mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['R2'] = r2_score(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['Pearson r'] = pearsonr(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "\n",
    "print(f'Saving PLS result for {subcortical[subcort]} fold {folds[fold]}', flush=True)\n",
    "with open(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/models/csv/Schaefer7n500p_{subcortical[subcort]}_full_correlation_fold_{folds[fold]}_PLS_result.csv', 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=pls_result.keys())\n",
    "    writer.writerow(pls_result)\n",
    "\n",
    "pls_result.clear()\n",
    "\n",
    "corr, pval = stats.pearsonr(np.squeeze(np.array(g_test)), np.squeeze(g_pred_test))\n",
    "r2 = r2_score(np.squeeze(np.array(g_test)), np.squeeze(g_pred_test))\n",
    "mse = mean_squared_error(np.squeeze(np.array(g_test)), np.squeeze(g_pred_test))\n",
    "result = pd.DataFrame([subcortical[subcort], fold, corr, pval, r2, mse, model.best_params_], index=['Modality', 'Fold', 'Correlation', 'P-value', 'R2', 'MSE', 'n components'], columns=['Values']).to_csv(f'/projects/PLS/pls_rs/pls_rs_timeseries/shaefer_7n500_600/fold_{folds[fold]}/models/csv/Schaefer7n500p_{subcortical[subcort]}_full_correlation_fold_{folds[fold]}_full_result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbiobank_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
