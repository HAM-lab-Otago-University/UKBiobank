{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import warnings\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator, MaxNLocator\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib import colors\n",
    "import matplotlib.ticker as plticker\n",
    "import sklearn\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as grid_spec\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "from textwrap import wrap\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of the Mental Health variables: correlations, distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match mental health features to targets\n",
    "mh = pd.read_csv('/mental_health/mental_health_full_renamed.csv')\n",
    "targets = pd.read_csv('/Cog-Ment/R/g_factor_5_folds/target.csv')\n",
    "mh_matched_to_targets = pd.merge(mh, targets['eid'], on = 'eid')\n",
    "mh_matched_to_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age and sex distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_confounds_min = pd.read_csv('/ML_DATASETS/basic_confounds_min.csv')[['Sex', 'Age when attended assessment centre', 'eid']]\n",
    "age_sex = pd.DataFrame(basic_confounds_min)\n",
    "age_sex.columns = ['Sex', 'Age', 'eid']\n",
    "mh_age_sex = mh_matched_to_targets.merge(age_sex, on = 'eid')\n",
    "mh_age_sex.to_csv('/mental_health/mh_age_sex.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean age', mh_age_sex['Age'].mean().round(2))\n",
    "print(f\"SD age {mh_age_sex['Age'].std():.3f}\")\n",
    "\n",
    "\n",
    "print('Age when attended assessment centre, mean:', mh_age_sex['Age'].mean().round(2), 'SD:', f\"{mh_age_sex['Age'].std():.3f}\")\n",
    "print('Age max range:', mh_age_sex['Age'].max())\n",
    "print('Age min range:', mh_age_sex['Age'].min())\n",
    "print('Proportion of males:', (mh_age_sex['Sex'].value_counts()[1] / len(mh_age_sex['Sex']) * 100).round(2))\n",
    "print('Proportion of females:', (mh_age_sex['Sex'].value_counts()[0] / len(mh_age_sex['Sex']) * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of mehtal health scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of mehtal health scores\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Calculate the number of rows needed for 134 columns with 5 per row\n",
    "columns = mh_matched_to_targets.drop(columns='eid').columns # Ceiling division to get the number of rows\n",
    "num_rows = -(-len(columns) // 5)\n",
    "#loc = plticker.MultipleLocator(base=1.0)\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=9, figsize=(50, num_rows * 5))\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(columns):\n",
    "    column_data = mh_matched_to_targets.drop(columns='eid')[col]\n",
    "\n",
    "    max_val = column_data.max()\n",
    "    min_val = column_data.min()  # Assuming the minimum value is 0\n",
    "    range_val = max_val - min_val\n",
    "    if range_val > 0:\n",
    "        interval = range_val / 10\n",
    "        locator = ticker.MaxNLocator(nbins=10, steps=[1, 2, 5, 10])\n",
    "    else:\n",
    "        locator = ticker.FixedLocator([0])\n",
    "\n",
    "    sns.histplot(column_data, ax=axes[i], color='wheat', binwidth=0.3, linewidth=0.5)\n",
    "    axes[i].tick_params(axis='x', labelsize=10)\n",
    "    \n",
    "    wrapped_col = '\\n'.join(wrap(col, width=25))\n",
    "\n",
    "    axes[i].set_xlabel(wrapped_col, fontsize=20) # Name of the x axis\n",
    "    axes[i].set_ylabel(None)  # Name of the y axis\n",
    "    axes[i].tick_params(axis='y', labelsize=12) # Size of the y ticks\n",
    "\n",
    "    axes[i].xaxis.set_major_locator(ticker.MultipleLocator(1)) # x axis tick interval\n",
    "    axes[i].yaxis.set_major_locator(locator) # y axis tick interval\n",
    "\n",
    "    axes[i].set_xlim(left=mh_matched_to_targets.drop(columns='eid')[col].min())\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.5, wspace=0.7)\n",
    "plt.suptitle('Distribution of Mental Health Scores', fontsize=40, y=1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation plot for mental health scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot for mental health scores: only significant correlations\n",
    "correlation_features = mh_matched_to_targets.drop(columns='eid').corr(method='pearson')\n",
    "\n",
    "p_values = pd.DataFrame(index=mh_matched_to_targets.drop(columns='eid').columns, columns=mh_matched_to_targets.drop(columns='eid').columns)\n",
    "\n",
    "for row in mh_matched_to_targets.drop(columns='eid').columns:\n",
    "    for col in mh_matched_to_targets.drop(columns='eid').columns:\n",
    "        if row != col:\n",
    "            _, p_value = pearsonr(mh_matched_to_targets.drop(columns='eid')[row], mh_matched_to_targets.drop(columns='eid')[col])\n",
    "            p_values[row][col] = p_value\n",
    "p_values = p_values.astype(float)\n",
    "significance_level = 0.05\n",
    "significant_correlations = p_values[p_values < significance_level]\n",
    "mask = p_values >= significance_level\n",
    "significant_corr_matrix = correlation_features.mask(mask)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.heatmap(significant_corr_matrix, cmap='coolwarm', xticklabels=correlation_features.columns, yticklabels=correlation_features.columns)\n",
    "plt.tick_params(labelsize=8)\n",
    "plt.title('Heatmap of Significant Correlations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot for mental health scores: discard diagonal\n",
    "correlation_features = mh_matched_to_targets.drop(columns='eid').corr(method='pearson')\n",
    "plt.figure(figsize=(70, 70))\n",
    "mask = np.triu(np.ones_like(correlation_features, dtype=bool), k=1)\n",
    "plot = sns.heatmap(correlation_features, cmap='coolwarm', fmt=\".2f\",\n",
    "                   xticklabels=correlation_features.columns,\n",
    "                   yticklabels=correlation_features.columns,\n",
    "                   mask=mask)\n",
    "plot.set_xticklabels(plot.get_yticklabels(), rotation = 70, ha='right', fontsize = 30)\n",
    "plot.set_yticklabels(plot.get_yticklabels(), fontsize = 30)\n",
    "cbar = plot.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify correlations: Wellbeing vs other features (expected positive correlations only with happiness/wellbeing-related variables)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(correlation_features['Wellbeing'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single split to explain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('/Cog-Ment/R/g_factor_5_folds/target.csv')\n",
    "ds = pd.merge(mh, targets, on = 'eid')\n",
    "X = ds.drop(columns=['log_RT', 'FIS',\n",
    "       'Numeric memory:Max digits remembered correctly',\n",
    "       'log_TMT:Duration to complete numeric path',\n",
    "       'log_TMT:Duration to complete alphabetic path',\n",
    "       'SDS:Numb of symbol digit matches made correctly',\n",
    "       'PAL:Numb of word pairs correctly associated',\n",
    "       'Tower rearranging:Numb of puzzles correct',\n",
    "       'Matrix PC: Numb of puzzles correctly solved',\n",
    "       'log1p_Pairs match:Incorrect matches (round 2)',\n",
    "       'Picture vocab:Specific cognitive ability',\n",
    "       'Prosp memory:Initial answer'])\n",
    "y = ds[['eid', 'log_RT', 'FIS',\n",
    "       'Numeric memory:Max digits remembered correctly',\n",
    "       'log_TMT:Duration to complete numeric path',\n",
    "       'log_TMT:Duration to complete alphabetic path',\n",
    "       'SDS:Numb of symbol digit matches made correctly',\n",
    "       'PAL:Numb of word pairs correctly associated',\n",
    "       'Tower rearranging:Numb of puzzles correct',\n",
    "       'Matrix PC: Numb of puzzles correctly solved',\n",
    "       'log1p_Pairs match:Incorrect matches (round 2)',\n",
    "       'Picture vocab:Specific cognitive ability',\n",
    "       'Prosp memory:Initial answer']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "pd.DataFrame(X_train['eid'], columns = ['eid']).to_csv('/mental_health/single_split/train_id.csv', index=False)\n",
    "pd.DataFrame(X_test['eid'], columns = ['eid']).to_csv('/mental_health/single_split/test_id.csv', index=False)\n",
    "\n",
    "X_train = X_train.drop(columns = 'eid').reset_index(drop=True)\n",
    "X_test = X_test.drop(columns = 'eid').reset_index(drop=True)\n",
    "y_train = y_train.drop(columns = 'eid').reset_index(drop=True)\n",
    "y_test = y_test.drop(columns = 'eid').reset_index(drop=True)\n",
    "\n",
    "pd.DataFrame(X_train, columns = X_train.columns).to_csv('/mental_health/single_split/X_train_original.csv', index=False)\n",
    "pd.DataFrame(X_test, columns = X_test.columns).to_csv('/mental_health/single_split/X_test_original.csv', index=False)\n",
    "\n",
    "pd.DataFrame(y_train, columns = y_train.columns).to_csv('/mental_health/single_split/y_train_original.csv', index=False)\n",
    "pd.DataFrame(y_test, columns = y_test.columns).to_csv('/mental_health/single_split/y_test_original.csv', index=False)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled, X_test_scaled = scaler_X.fit_transform(X_train), scaler_X.transform(X_test)\n",
    "with open(f'/mental_health/Single_split/scaler_X.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "\n",
    "y_train_scaled, y_test_scaled = scaler_y.fit_transform(y_train), scaler_y.transform(y_test)\n",
    "with open(f'/mental_health/Single_split/scaler_y.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "\n",
    "pd.DataFrame(X_train_scaled, columns = X_train.columns).to_csv('/mental_health/single_split/X_train_scaled.csv', index=False)\n",
    "pd.DataFrame(X_test_scaled, columns = X_train.columns).to_csv('/mental_health/single_split/X_test_scaled.csv', index=False)\n",
    "\n",
    "pd.DataFrame(y_train_scaled, columns = y_train.columns).to_csv('/mental_health/single_split/y_train_scaled.csv', index=False)\n",
    "pd.DataFrame(y_test_scaled, columns = y_train.columns).to_csv('/mental_health/single_split/y_test_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove composite scores and test model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(ds.max().round(2).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('/Cog-Ment/R/g_factor_5_folds/target.csv')\n",
    "ds = pd.merge(mh, targets, on = 'eid')\n",
    "\n",
    "print('Mental health shape before removing scores:', ds.shape)\n",
    "\n",
    "scores_to_remove = ['NS-12',\n",
    "'RDS-4',\n",
    "'Wellbeing',\n",
    "'GAD-7',\n",
    "'PHQ-9',\n",
    "'PCL-6',\n",
    "'PDS',\n",
    "'Ever self-harmed (non-suicidal)',\n",
    "'Ever self-harmed',               \n",
    "'Ever attempted suicide',         \n",
    "'Substance addiction',            \n",
    "'Current addiction',              \n",
    "'Alcohol dependence (AUDIT≥15)',  \n",
    "'GAD ever',                       \n",
    "'Current GAD',                    \n",
    "'Current GAD mild',               \n",
    "'Current GAD moderate',           \n",
    "'PTSD',                           \n",
    "'Current GAD severe',             \n",
    "'Hazardous alcohol use (AUDIT≥8)',\n",
    "'Current severe depression',      \n",
    "'Current depression',             \n",
    "'Depression triggered by loss',   \n",
    "'Recurrent depression',           \n",
    "'Depression single episode',      \n",
    "'Bipolar II',                     \n",
    "'Bipolar I',                      \n",
    "'Subthreshold depression',        \n",
    "'Depression ever',                \n",
    "'Lifetime frequency of contemplating self-harm',                                                              \n",
    "\"Frequency of 'life not worth living' thoughts\", \n",
    "'(log)AUDIT-C', \n",
    "'Ever depressed for a whole week', \n",
    "'(log)AUDIT-P', \n",
    "'(log)AUDIT', \n",
    "'Childhood adverse events', \n",
    "'Adult adverse events', \n",
    "'Catastrophic trauma', \n",
    "'Any distress', \n",
    "'Unusual experience']\n",
    "\n",
    "target_cols = ['log_RT', 'FIS',\n",
    "       'Numeric memory:Max digits remembered correctly',\n",
    "       'log_TMT:Duration to complete numeric path',\n",
    "       'log_TMT:Duration to complete alphabetic path',\n",
    "       'SDS:Numb of symbol digit matches made correctly',\n",
    "       'PAL:Numb of word pairs correctly associated',\n",
    "       'Tower rearranging:Numb of puzzles correct',\n",
    "       'Matrix PC: Numb of puzzles correctly solved',\n",
    "       'log1p_Pairs match:Incorrect matches (round 2)',\n",
    "       'Picture vocab:Specific cognitive ability',\n",
    "       'Prosp memory:Initial answer']\n",
    "\n",
    "ds = ds.drop(columns = scores_to_remove)\n",
    "X = ds.drop(columns=target_cols)\n",
    "\n",
    "y = ds[['eid'] + [col for col in target_cols]]\n",
    "\n",
    "print('Mental health shape after removing scores and target:', X.shape)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "pd.DataFrame(X_train['eid'], columns = ['eid']).to_csv('/mh/train_id.csv', index=False)\n",
    "pd.DataFrame(X_test['eid'], columns = ['eid']).to_csv('/mh/test_id.csv', index=False)\n",
    "\n",
    "X_train = X_train.drop(columns = 'eid').reset_index(drop=True)\n",
    "X_test = X_test.drop(columns = 'eid').reset_index(drop=True)\n",
    "y_train = y_train.drop(columns = 'eid').reset_index(drop=True)\n",
    "y_test = y_test.drop(columns = 'eid').reset_index(drop=True)\n",
    "\n",
    "pd.DataFrame(X_train, columns = X_train.columns).to_csv('/mh/X_train_original.csv', index=False)\n",
    "pd.DataFrame(X_test, columns = X_test.columns).to_csv('/mh/X_test_original.csv', index=False)\n",
    "\n",
    "pd.DataFrame(y_train, columns = y_train.columns).to_csv('/mh/y_train_original.csv', index=False)\n",
    "pd.DataFrame(y_test, columns = y_test.columns).to_csv('/mh/y_test_original.csv', index=False)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled, X_test_scaled = scaler_X.fit_transform(X_train), scaler_X.transform(X_test)\n",
    "with open(f'/mh/scaler_X.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "\n",
    "y_train_scaled, y_test_scaled = scaler_y.fit_transform(y_train), scaler_y.transform(y_test)\n",
    "with open(f'/mh/scaler_y.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "\n",
    "pd.DataFrame(X_train_scaled, columns = X_train.columns).to_csv('/mh/X_train_scaled.csv', index=False)\n",
    "pd.DataFrame(X_test_scaled, columns = X_train.columns).to_csv('/mh/X_test_scaled.csv', index=False)\n",
    "\n",
    "pd.DataFrame(y_train_scaled, columns = y_train.columns).to_csv('/mh/y_train_scaled.csv', index=False)\n",
    "pd.DataFrame(y_test_scaled, columns = y_train.columns).to_csv('/mh/y_test_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep scores, but remove questionnaire items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('/Cog-Ment/R/g_factor_5_folds/target.csv')\n",
    "ds = pd.merge(mh, targets, on = 'eid')\n",
    "\n",
    "print('Mental health shape before removing questionnaire items:', ds.shape)\n",
    "\n",
    "scores_to_keep = [\n",
    "'NS-12',\n",
    "'RDS-4',\n",
    "'Wellbeing',\n",
    "'GAD-7',\n",
    "'PHQ-9',\n",
    "'PCL-6',\n",
    "'PDS',\n",
    "'Ever self-harmed (non-suicidal)',\n",
    "'Ever self-harmed',               \n",
    "'Ever attempted suicide',         \n",
    "'Substance addiction',            \n",
    "'Current addiction',              \n",
    "'Alcohol dependence (AUDIT≥15)',  \n",
    "'GAD ever',                       \n",
    "'Current GAD',                    \n",
    "'Current GAD mild',               \n",
    "'Current GAD moderate',           \n",
    "'PTSD',                           \n",
    "'Current GAD severe',             \n",
    "'Hazardous alcohol use (AUDIT≥8)',\n",
    "'Current severe depression',      \n",
    "'Current depression',             \n",
    "'Depression triggered by loss',   \n",
    "'Recurrent depression',           \n",
    "'Depression single episode',      \n",
    "'Bipolar II',                     \n",
    "'Bipolar I',                      \n",
    "'Subthreshold depression',        \n",
    "'Depression ever',                \n",
    "'Lifetime frequency of contemplating self-harm',                                                              \n",
    "\"Frequency of 'life not worth living' thoughts\", \n",
    "'(log)AUDIT-C', \n",
    "'Ever depressed for a whole week', \n",
    "'(log)AUDIT-P', \n",
    "'(log)AUDIT', \n",
    "'Childhood adverse events', \n",
    "'Adult adverse events', \n",
    "'Catastrophic trauma', \n",
    "'Any distress', \n",
    "'Unusual experience']\n",
    "\n",
    "target_cols = ['log_RT', 'FIS',\n",
    "       'Numeric memory:Max digits remembered correctly',\n",
    "       'log_TMT:Duration to complete numeric path',\n",
    "       'log_TMT:Duration to complete alphabetic path',\n",
    "       'SDS:Numb of symbol digit matches made correctly',\n",
    "       'PAL:Numb of word pairs correctly associated',\n",
    "       'Tower rearranging:Numb of puzzles correct',\n",
    "       'Matrix PC: Numb of puzzles correctly solved',\n",
    "       'log1p_Pairs match:Incorrect matches (round 2)',\n",
    "       'Picture vocab:Specific cognitive ability',\n",
    "       'Prosp memory:Initial answer']\n",
    "\n",
    "X = ds[['eid'] + [col for col in scores_to_keep]]\n",
    "y = ds[['eid'] + [col for col in target_cols]]\n",
    "\n",
    "print('Mental health shape after removing questionnaire items and target:', X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "pd.DataFrame(X_train['eid'], columns = ['eid']).to_csv('/mh/scores_only/train_id.csv', index=False)\n",
    "pd.DataFrame(X_test['eid'], columns = ['eid']).to_csv('/mh/scores_only/test_id.csv', index=False)\n",
    "\n",
    "X_train = X_train.drop(columns = 'eid').reset_index(drop=True)\n",
    "X_test = X_test.drop(columns = 'eid').reset_index(drop=True)\n",
    "y_train = y_train.drop(columns = 'eid').reset_index(drop=True)\n",
    "y_test = y_test.drop(columns = 'eid').reset_index(drop=True)\n",
    "\n",
    "pd.DataFrame(X_train, columns = X_train.columns).to_csv('/mh/scores_only/X_train_original.csv', index=False)\n",
    "pd.DataFrame(X_test, columns = X_test.columns).to_csv('/mh/scores_only/X_test_original.csv', index=False)\n",
    "\n",
    "pd.DataFrame(y_train, columns = y_train.columns).to_csv('/mh/scores_only/y_train_original.csv', index=False)\n",
    "pd.DataFrame(y_test, columns = y_test.columns).to_csv('/mh/scores_only/y_test_original.csv', index=False)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_scaled, X_test_scaled = scaler_X.fit_transform(X_train), scaler_X.transform(X_test)\n",
    "with open(f'/mh/scores_only/scaler_X.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_X, f)\n",
    "\n",
    "y_train_scaled, y_test_scaled = scaler_y.fit_transform(y_train), scaler_y.transform(y_test)\n",
    "with open(f'/mh/scores_only/scaler_y.pkl', \"wb\") as f:\n",
    "    pickle.dump(scaler_y, f)\n",
    "\n",
    "pd.DataFrame(X_train_scaled, columns = X_train.columns).to_csv('/mh/scores_only/X_train_scaled.csv', index=False)\n",
    "pd.DataFrame(X_test_scaled, columns = X_train.columns).to_csv('/mh/scores_only/X_test_scaled.csv', index=False)\n",
    "\n",
    "pd.DataFrame(y_train_scaled, columns = y_train.columns).to_csv('/mh/scores_only/y_train_scaled.csv', index=False)\n",
    "pd.DataFrame(y_test_scaled, columns = y_train.columns).to_csv('/mh/scores_only/y_test_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlations between the target and mental health features: whole set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between g-factor and mental health features for the whole set: a random cognitive score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations between g-factor and mental health features for the whole set: Individual correlations\n",
    "X_train_original = pd.read_csv('/mental_health/single_split/X_train_original.csv')\n",
    "y_train = pd.read_csv('/mental_health/single_split/y_train_scaled.csv')\n",
    "feature_names = X_train_original.columns\n",
    "correlations_train_full = {}\n",
    "p_values_train_full = {}\n",
    "for column in X_train_original.columns:\n",
    "    r, p_value = pearsonr(X_train_original[column], y_train['FIS'])\n",
    "    correlations_train_full[column] = r\n",
    "    p_values_train_full[column] = p_value\n",
    "result = {'correlations': correlations_train_full, 'p_values': p_values_train_full}\n",
    "\n",
    "corr_p_full = pd.DataFrame(result)\n",
    "corr_full = pd.DataFrame(corr_p_full['correlations'])\n",
    "corr_full.index = feature_names\n",
    "significant_corr = corr_p_full[corr_p_full['p_values'] < 0.05].sort_values(by='correlations', ascending=False)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(significant_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlations between g-factor and mental health features for the whole set: g-factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations between g-factor and mental health features for the whole set: g-factor\n",
    "X_train_original = pd.read_csv('/mental_health/single_split/X_train_original.csv')\n",
    "g_train = pd.read_csv('/g_factor/g_train.csv')\n",
    "feature_names = X_train_original.columns\n",
    "correlations_train_full = {}\n",
    "p_values_train_full = {}\n",
    "for column in X_train_original.columns:\n",
    "    r, p_value = pearsonr(X_train_original[column], g_train['g'])\n",
    "    correlations_train_full[column] = r\n",
    "    p_values_train_full[column] = p_value\n",
    "result = {'correlations': correlations_train_full, 'p_values': p_values_train_full}\n",
    "\n",
    "corr_p_full = pd.DataFrame(result)\n",
    "corr_full = pd.DataFrame(corr_p_full['correlations'])\n",
    "corr_full.index = feature_names\n",
    "significant_corr = corr_p_full[corr_p_full['p_values'] <= 0.05].sort_values(by='correlations', ascending=False)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(significant_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PLS on the whole sample to infer overall structure of relationships between mental health and g (20:80 split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PLS on single split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLS on the whole set\n",
    "g_train = pd.read_csv('/g_factor/g_train.csv')\n",
    "g_test = pd.read_csv('/g_factor/g_test.csv')\n",
    "X_train_scaled = pd.read_csv('/mental_health/single_split/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('/mental_health/single_split/X_test_scaled.csv')\n",
    "pls_result = {}\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Initiate and run PLS\n",
    "parameters = {'n_components': range(1, np.array(X_train_scaled).shape[1]+1)}\n",
    "pls = PLSRegression()\n",
    "model = GridSearchCV(pls, parameters, scoring = 'neg_mean_absolute_error', cv=KFold(10, shuffle = True), verbose=4, n_jobs=17)\n",
    "\n",
    "print(\"Fitting PLS\")\n",
    "model.fit(X_train_scaled, g_train.values)\n",
    "\n",
    "print(f'Model parameters:', model.cv_results_['params'])\n",
    "print(f'Mean test score:', model.cv_results_['mean_test_score'])\n",
    "print(f'Rank test score:', model.cv_results_['rank_test_score'])\n",
    "print(model)\n",
    "\n",
    "print(f'Saving PLS model')\n",
    "with open(f'/mental_health/single_split/mh_pls_model.pkl', \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f'Best params = ', model.best_params_)\n",
    "print(f'Best score (neg_mean_absolute_error) = ', model.best_score_)\n",
    "\n",
    "# Predict the values\n",
    "print(f'Predicting g_test')\n",
    "g_pred_test = model.predict(X_test_scaled)\n",
    "print(f'Saving g pred')\n",
    "pd.DataFrame(g_pred_test, columns = ['g_pred_mh']).to_csv(f'/mental_health/single_split/g_pred_mh.csv')\n",
    "\n",
    "print(\"----------\")\n",
    "print(\"MSE = \", mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"MAE = \", mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"R2 = \", r2_score(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"Pearson's r = \", pearsonr(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"----------\")\n",
    "\n",
    "pls_result['n_components'] = model.best_params_\n",
    "pls_result['MSE'] = mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['MAE'] = mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['R2'] = r2_score(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['r'] = pearsonr(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "    \n",
    "with open(f'/mental_health/single_split/MH_Result_PLS.csv', 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=pls_result.keys())\n",
    "    writer.writerow(pls_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLS on the whole set without composite scores\n",
    "g_train = pd.read_csv('/g_factor/g_train.csv')\n",
    "g_test = pd.read_csv('/g_factor/g_test.csv')\n",
    "X_train_scaled = pd.read_csv('/mh/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('/mh/X_test_scaled.csv')\n",
    "pls_result = {}\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Initiate and run PLS\n",
    "parameters = {'n_components': range(1, np.array(X_train_scaled).shape[1]+1)}\n",
    "pls = PLSRegression()\n",
    "model = GridSearchCV(pls, parameters, scoring = 'neg_mean_absolute_error', cv=KFold(10, shuffle = True), verbose=4, n_jobs=17)\n",
    "\n",
    "print(\"Fitting PLS\")\n",
    "model.fit(X_train_scaled, g_train.values)\n",
    "\n",
    "print(f'Model parameters:', model.cv_results_['params'])\n",
    "print(f'Mean test score:', model.cv_results_['mean_test_score'])\n",
    "print(f'Rank test score:', model.cv_results_['rank_test_score'])\n",
    "print(model)\n",
    "\n",
    "print(f'Saving PLS model')\n",
    "with open(f'/mh/mh_pls_model.pkl', \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f'Best params = ', model.best_params_)\n",
    "print(f'Best score (neg_mean_absolute_error) = ', model.best_score_)\n",
    "\n",
    "# Predict the values\n",
    "print(f'Predicting g_test')\n",
    "g_pred_test = model.predict(X_test_scaled)\n",
    "print(f'Saving g pred')\n",
    "pd.DataFrame(g_pred_test, columns = ['g_pred_mh']).to_csv(f'/mh/g_pred_mh.csv')\n",
    "\n",
    "print(\"----------\")\n",
    "print(\"MSE = \", mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"MAE = \", mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"R2 = \", r2_score(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"Pearson's r = \", pearsonr(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"----------\")\n",
    "\n",
    "pls_result['n_components'] = model.best_params_\n",
    "pls_result['MSE'] = mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['MAE'] = mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['R2'] = r2_score(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['r'] = pearsonr(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "    \n",
    "with open(f'/mh/MH_Result_PLS.csv', 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=pls_result.keys())\n",
    "    writer.writerow(pls_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLS on the whole set without questionnaire items\n",
    "g_train = pd.read_csv('/g_factor/g_train.csv')\n",
    "g_test = pd.read_csv('/g_factor/g_test.csv')\n",
    "X_train_scaled = pd.read_csv('/mh/scores_only/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('/mh/scores_only/X_test_scaled.csv')\n",
    "pls_result = {}\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Initiate and run PLS\n",
    "parameters = {'n_components': range(1, np.array(X_train_scaled).shape[1]+1)}\n",
    "pls = PLSRegression()\n",
    "model = GridSearchCV(pls, parameters, scoring = 'neg_mean_absolute_error', cv=KFold(10, shuffle = True), verbose=4, n_jobs=17)\n",
    "\n",
    "print(\"Fitting PLS\")\n",
    "model.fit(X_train_scaled, g_train.values)\n",
    "\n",
    "print(f'Model parameters:', model.cv_results_['params'])\n",
    "print(f'Mean test score:', model.cv_results_['mean_test_score'])\n",
    "print(f'Rank test score:', model.cv_results_['rank_test_score'])\n",
    "print(model)\n",
    "\n",
    "print(f'Saving PLS model')\n",
    "with open(f'/mh/scores_only/mh_pls_model.pkl', \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "print(f'Best params = ', model.best_params_)\n",
    "print(f'Best score (neg_mean_absolute_error) = ', model.best_score_)\n",
    "\n",
    "# Predict the values\n",
    "print(f'Predicting g_test')\n",
    "g_pred_test = model.predict(X_test_scaled)\n",
    "print(f'Saving g pred')\n",
    "pd.DataFrame(g_pred_test, columns = ['g_pred_mh']).to_csv(f'/mh/scores_only/g_pred_mh.csv')\n",
    "\n",
    "print(\"----------\")\n",
    "print(\"MSE = \", mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"MAE = \", mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"R2 = \", r2_score(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"Pearson's r = \", pearsonr(np.array(g_test)[:,0], g_pred_test[:,0]))\n",
    "print(\"----------\")\n",
    "\n",
    "pls_result['n_components'] = model.best_params_\n",
    "pls_result['MSE'] = mean_squared_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['MAE'] = mean_absolute_error(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['R2'] = r2_score(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "pls_result['r'] = pearsonr(np.array(g_test)[:,0], g_pred_test[:,0])\n",
    "    \n",
    "with open(f'/mh/scores_only/MH_Result_PLS.csv', 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=pls_result.keys())\n",
    "    writer.writerow(pls_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without composite scores\n",
    "pls_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without questionnaire items\n",
    "pls_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New\n",
    "pls_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate R2 for each component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/mental_health/single_split/mh_pls_model.pkl', \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "r2_sum = 0\n",
    "r2_vector = np.empty(model.best_estimator_.n_components)\n",
    "for i in range(0,model.best_estimator_.n_components):\n",
    "        Y_pred = np.dot(model.best_estimator_.x_scores_[:,i].reshape(-1,1), model.best_estimator_.y_loadings_[:,i].reshape(-1,1).T) * g_train.values.std(axis=0, ddof=1) + g_train['g'].mean(axis=0)\n",
    "        r2_sum += r2_score(g_train.values,Y_pred)\n",
    "        print('R2 for %d component: %g' %(i+1,r2_score(g_train.values, Y_pred)))\n",
    "        r2_vector[i] = r2_score(g_train.values,Y_pred)\n",
    "print('R2 for all components: %g' %r2_sum.round(2))\n",
    "#print('R2 for all components: %g' %(r2_score(g_train.values, model.best_estimator_.predict(X_train_scaled))))\n",
    "x_loading_by_r2 = model.best_estimator_.x_loadings_ *  r2_vector\n",
    "x_loading_by_r2_scaled = stats.zscore(model.best_estimator_.x_loadings_) *  r2_vector\n",
    "weighted_x_loading = np.sum(x_loading_by_r2, axis=1)\n",
    "weighted_x_loading_scaled = np.sum(x_loading_by_r2_scaled, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build MSE plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE plot\n",
    "mse = model.cv_results_['mean_test_score']\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(range(1, 134), mse) #, \"-o\")\n",
    "plt.xticks(range(1, 134, 1), fontsize = 5)\n",
    "optimal_n_components = model.best_params_['n_components']\n",
    "plt.xlabel(f\"Number of PLS components, optimal: {optimal_n_components}\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim(-0.530, -0.5275)\n",
    "plt.title(f\"PLSRegression MSE plot\")\n",
    "plt.axvline(x=optimal_n_components, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although GridSearchCV suggets 117 components, they seem to be noize. This may happen dues to a large proportion of 0/1 features. According to the MSE plot, 16 components may be enough to capture maximum variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rerun PLS on 16 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLS on the whole set: select the number of components suggested by MSE plot\n",
    "pls_result_16 = {}\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Initiate and run PLS\n",
    "parameters = {'n_components': range(1, 17)}\n",
    "pls = PLSRegression()\n",
    "model_16 = GridSearchCV(pls, parameters, scoring = 'neg_mean_absolute_error', cv=KFold(10, shuffle = True), verbose=4, n_jobs=17)\n",
    "\n",
    "print(\"Fitting PLS\")\n",
    "model_16.fit(X_train_scaled, g_train.values)\n",
    "\n",
    "print(f'Model parameters:', model_16.cv_results_['params'])\n",
    "print(f'Mean test score:', model_16.cv_results_['mean_test_score'])\n",
    "print(f'Rank test score:', model_16.cv_results_['rank_test_score'])\n",
    "print(model_16)\n",
    "\n",
    "print(f'Saving PLS model')\n",
    "with open(f'/mental_health/single_split/mh_pls_model_16comp.pkl', \"wb\") as f:\n",
    "    pickle.dump(model_16, f)\n",
    "\n",
    "print(f'Best params = ', model_16.best_params_)\n",
    "print(f'Best score (neg_mean_absolute_error) = ', model_16.best_score_)\n",
    "\n",
    "# Predict the values\n",
    "print(f'Predicting g_test')\n",
    "g_pred_test_16 = model_16.predict(X_test_scaled)\n",
    "print(f'Saving g pred')\n",
    "pd.DataFrame(g_pred_test_16, columns = ['g_pred_mh']).to_csv('/mental_health/single_split/g_pred_mh_16comp.csv')\n",
    "\n",
    "print(\"----------\")\n",
    "print(\"MSE = \", mean_squared_error(np.array(g_test)[:,0], g_pred_test_16[:,0]))\n",
    "print(\"MAE = \", mean_absolute_error(np.array(g_test)[:,0], g_pred_test_16[:,0]))\n",
    "print(\"R2 = \", r2_score(np.array(g_test)[:,0], g_pred_test_16[:,0]))\n",
    "print(\"Pearson's r = \", pearsonr(np.array(g_test)[:,0], g_pred_test_16[:,0]))\n",
    "print(\"----------\")\n",
    "\n",
    "pls_result_16['n_components'] = model_16.best_params_\n",
    "pls_result_16['MSE'] = mean_squared_error(np.array(g_test)[:,0], g_pred_test_16[:,0])\n",
    "pls_result_16['MAE'] = mean_absolute_error(np.array(g_test)[:,0], g_pred_test_16[:,0])\n",
    "pls_result_16['R2'] = r2_score(np.array(g_test)[:,0], g_pred_test_16[:,0])\n",
    "pls_result_16['r'] = pearsonr(np.array(g_test)[:,0], g_pred_test_16[:,0])\n",
    "    \n",
    "with open(f'/mental_health/single_split/MH_Result_PLS_16Comp.csv', 'a', newline='') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=pls_result.keys())\n",
    "    writer.writerow(pls_result_16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_pred_test_16 = pd.read_csv('/mental_health/single_split/g_pred_mh_16comp.csv')\n",
    "result_16 = pd.read_csv('/mental_health/single_split/MH_Result_PLS_16Comp.csv', header=None)\n",
    "result_16.columns=['n_components', 'MSE', 'MAE', 'R2', 'r']\n",
    "result_16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate R2 for each component and sum up all components into one: 16 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/mental_health/single_split/mh_pls_model_16comp.pkl', \"rb\") as f:\n",
    "    model_16 = pickle.load(f)\n",
    "r2_sum = 0\n",
    "r2_vector = np.empty(model_16.best_estimator_.n_components)\n",
    "for i in range(0,model_16.best_estimator_.n_components):\n",
    "        Y_pred = np.dot(model_16.best_estimator_.x_scores_[:,i].reshape(-1,1), model_16.best_estimator_.y_loadings_[:,i].reshape(-1,1).T) * g_train.values.std(axis=0, ddof=1) + g_train['g'].mean(axis=0)\n",
    "        r2_sum += r2_score(g_train.values,Y_pred)\n",
    "        print('R2 for %d component: %g' %(i+1,r2_score(g_train.values, Y_pred)))\n",
    "        r2_vector[i] = r2_score(g_train.values,Y_pred)\n",
    "print('R2 for all components: %g' %r2_sum.round(2))\n",
    "#print('R2 for all components: %g' %(r2_score(g_train.values, model_16.best_estimator_.predict(X_train_scaled))))\n",
    "x_loading_by_r2 = model_16.best_estimator_.x_loadings_ *  r2_vector\n",
    "x_loading_by_r2_scaled = stats.zscore(model_16.best_estimator_.x_loadings_) *  r2_vector\n",
    "weighted_x_loading = np.sum(x_loading_by_r2, axis=1)\n",
    "weighted_x_loading_scaled = np.sum(x_loading_by_r2_scaled, axis=1)\n",
    "#pd.DataFrame(weighted_x_loading_scaled, columns = ['Loadings weighted']).to_csv('/mental_health/single_split/mh_pls_model_16comp_weighted_x_loading_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MSE plot\n",
    "mse = model_16.cv_results_['mean_test_score']\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt.plot(range(1, 17), mse) #, \"-o\")\n",
    "plt.xticks(range(1, 17, 1), fontsize = 10)\n",
    "optimal_n_components = model_16.best_params_['n_components']\n",
    "plt.xlabel(f\"Number of PLS components, optimal: {optimal_n_components}\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.ylim(-0.530, -0.528)\n",
    "plt.title(f\"PLSRegression MSE plot\")\n",
    "plt.axvline(x=optimal_n_components, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get factor loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'/mental_health/single_split/mh_pls_model_16comp.pkl', \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "X_train_scaled = pd.read_csv('/mental_health/single_split/X_train_scaled.csv')\n",
    "loading = pd.DataFrame(model.best_estimator_.x_loadings_, columns = [f'Component {i+1}' for i in range(0, model.best_estimator_.x_loadings_.shape[1])])\n",
    "loading.index = X_train_scaled.columns\n",
    "loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort correlations in an ascending order and match to PLS loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_full_sorted = corr_full.sort_values(by='correlations', ascending=False)\n",
    "weighted_x_loading_scaled_df = pd.concat([pd.DataFrame(feature_names, columns = ['Features']), pd.DataFrame(weighted_x_loading_scaled, columns = ['Loadings'])], axis=1)\n",
    "weighted_loadings_full_matched = weighted_x_loading_scaled_df.set_index('Features').loc[corr_full_sorted.index] #.reset_index()\n",
    "\n",
    "# Save\n",
    "corr_full_sorted.to_csv('/mental_health/single_split/mh_pls_model_16comp_corr_full_sorted.csv')\n",
    "weighted_x_loading_scaled_df.to_csv('/mental_health/single_split/mh_pls_model_16comp_weighted_x_loading_scaled_df.csv')\n",
    "weighted_loadings_full_matched.to_csv('/mental_health/single_split/mh_pls_model_16comp_weighted_loadings_full_matched.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_full_sorted = pd.read_csv('/mental_health/single_split/mh_pls_model_16comp_corr_full_sorted.csv', index_col=0)\n",
    "weighted_loadings_full_matched = pd.read_csv('/mental_health/single_split/mh_pls_model_16comp_weighted_loadings_full_matched.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename some columns for clarity\n",
    "corr_full_sorted_renamed = corr_full_sorted.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\"})\n",
    "weighted_loadings_full_matched_renamed = weighted_loadings_full_matched.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean', corr_full_sorted_renamed['correlations'].mean().round(2))\n",
    "print('SD', corr_full_sorted_renamed['correlations'].std().round(2))\n",
    "print('MIN', corr_full_sorted_renamed['correlations'].min().round(2))\n",
    "print('MAX', corr_full_sorted_renamed['correlations'].max().round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match loadings to correlations and filter, do not reindex\n",
    "loadings_match_to_corr = pd.merge(\n",
    "    corr_full_sorted,\n",
    "    weighted_loadings_full_matched,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "negative_corr = loadings_match_to_corr[loadings_match_to_corr['correlations'] < 0]\n",
    "positive_corr = loadings_match_to_corr[loadings_match_to_corr['correlations'] >= 0]\n",
    "negative_load = loadings_match_to_corr[loadings_match_to_corr['correlations'] < 0]\n",
    "positive_load = loadings_match_to_corr[loadings_match_to_corr['correlations'] >= 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select only significant p-values and match to loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_p_full.index = feature_names\n",
    "significant_corr = corr_p_full[corr_p_full['p_values'] <= 0.05].sort_values(by='correlations', ascending=False)\n",
    "significant_corr_sorted = significant_corr.sort_values(by='correlations', ascending=False)\n",
    "weighted_loadings_full_matched_significant = weighted_x_loading_scaled_df.set_index('Features').loc[significant_corr_sorted.index]\n",
    "weighted_loadings_full_matched_significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading + corr plot sorted larger to smaller, mirror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full loading plot\n",
    "fig, ax = plt.subplots(1, 2, figsize=(60, 220),  sharey='col') #figsize=(35, 70) #figsize=(35, 130),\n",
    "\n",
    "def get_edge_color(value):\n",
    "    return 'black' if value < 0 else 'black' #return 'blue' if value < 0 else 'green'\n",
    "\n",
    "negative_edge_colors = negative_load['Loadings'].apply(get_edge_color).tolist()\n",
    "positive_edge_colors = positive_load['Loadings'].apply(get_edge_color).tolist()\n",
    "\n",
    "\n",
    "negative_corr_sorted = negative_corr.sort_values(by='correlations', ascending=True)\n",
    "negative_load_sorted = negative_load.reindex(negative_corr_sorted.index)\n",
    "#Corr\n",
    "ax[0].barh(negative_corr_sorted.index,\n",
    "           negative_corr_sorted['correlations'],\n",
    "           color='#79AF9799', alpha=0.4, height=0.9)\n",
    "\n",
    "# Loadings\n",
    "negative_edge_colors_sorted = negative_load_sorted['Loadings'].apply(get_edge_color).tolist() # Apply the edge color function to the sorted loadings\n",
    "ax[0].barh(negative_load_sorted.index,\n",
    "            negative_load_sorted['Loadings'],\n",
    "            color='none', edgecolor=negative_edge_colors_sorted, linewidth=2, height=0.9)\n",
    "#Corr\n",
    "ax[1].barh(positive_corr.index,\n",
    "            positive_corr['correlations'],\n",
    "            color='#79AF9799', alpha=0.4, height=0.9) # #DF8F4499\n",
    "\n",
    "# Loadings\n",
    "ax[1].barh(positive_load.index,\n",
    "            positive_load['Loadings'],\n",
    "            color='none', edgecolor=positive_edge_colors, linewidth = 2, height=0.9) #, hatch='//'\n",
    "\n",
    "ax[0].tick_params(axis='y', labelsize=90)\n",
    "ax[0].tick_params(axis='x', labelsize=80, rotation=50)\n",
    "ax[0].spines['left'].set_visible(False)\n",
    "ax[0].invert_yaxis()\n",
    "\n",
    "\n",
    "ax[1].tick_params(axis='y', labelsize=90, labelright=True, labelleft=False)\n",
    "ax[1].tick_params(axis='x', labelsize=80, rotation=50)\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "# Remove the y-axis ticks on the right side while keeping the y-axis line\n",
    "ax[1].yaxis.set_ticks_position('none')\n",
    "\n",
    "# Hide the spines for a cleaner look\n",
    "for axs in ax:\n",
    "    for side in [\"top\", \"bottom\", \"right\"]:\n",
    "        axs.spines[side].set_visible(False)\n",
    "\n",
    "# Set a common x-axis label for both correlations and loadings\n",
    "fig.text(0.55, 0.08, \"Pearson's $r$ and Loadings\", ha='center', fontsize=120)\n",
    "\n",
    "min_negative = min(negative_corr['correlations'].min(), negative_load['Loadings'].min())\n",
    "max_positive = max(positive_corr['correlations'].max(), positive_load['Loadings'].max())\n",
    "ax[0].set_xlim(min_negative * 1.5,  max_positive * 0.2) #ax[0].set_xlim(min_negative * 1.1, 0) in_negative * 1.1,  max_positive * 0.1\n",
    "ax[1].set_xlim(min_negative * 1.5, max_positive * 1.1) #ax[1].set_xlim(0, max_positive * 1.1) #min_negative * 1.1, max_positive * 1.1\n",
    "\n",
    "# Format the x-axis labels to two decimal places\n",
    "#formatter = FormatStrFormatter('%.2f')\n",
    "ax[0].xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "ax[1].xaxis.set_major_formatter(FormatStrFormatter('%.2f'))\n",
    "\n",
    "# Add legends to both subplots\n",
    "ax[0].legend(loc='lower left')\n",
    "ax[1].legend(loc='lower right')\n",
    "\n",
    "ax[0].axvline(x=0, color='black', linewidth=1)\n",
    "ax[1].axvline(x=0, color='black', linewidth=1)\n",
    "\n",
    "ax[0].spines['right'].set_visible(False)\n",
    "ax[1].spines['left'].set_visible(False)\n",
    "\n",
    "# Set x-tick intervals\n",
    "ax[0].xaxis.set_major_locator(MultipleLocator(0.05))\n",
    "ax[1].xaxis.set_major_locator(MultipleLocator(0.05))\n",
    "\n",
    "#plt.tight_layout()\n",
    "\n",
    "# Adjust the spacing between the subplots\n",
    "fig.subplots_adjust(wspace=0.1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename features for clarity \n",
    "negative_corr_renamed = negative_corr.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Diagnoses: Depression': 'Depression'})\n",
    "negative_load_renamed = negative_load.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Diagnoses: Depression': 'Depression'})\n",
    "positive_corr_renamed = positive_corr.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Diagnoses: Depression': 'Depression'})\n",
    "positive_load_renamed = positive_load.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Diagnoses: Depression': 'Depression'})\n",
    "\n",
    "corr_full_sorted_renamed = corr_full_sorted.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Ever had period extreme irritability': 'Ever had period of extreme irritability',\n",
    "                                                          'Frequency of \"life not worth living\" thoughts': \"Frequency of 'life not worth living' thoughts\",\n",
    "                                                          'Diagnoses: Anxiety/panic attacks': 'Anxiety/panic attacks',\n",
    "                                                          'NS-12': 'N-12',\n",
    "                                                          'Diagnoses: Depression': 'Depression'\n",
    "                                                          })\n",
    "weighted_loadings_full_matched_renamed = weighted_loadings_full_matched.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Ever had period extreme irritability': 'Ever had period of extreme irritability',\n",
    "                                                          'Frequency of \"life not worth living\" thoughts': \"Frequency of 'life not worth living' thoughts\",\n",
    "                                                          'Diagnoses: Anxiety/panic attacks': 'Anxiety/panic attacks',\n",
    "                                                          'NS-12': 'N-12',\n",
    "                                                          'Diagnoses: Depression': 'Depression'\n",
    "                                                          })\n",
    "significant_corr_renamed = significant_corr.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Ever had period extreme irritability': 'Ever had period of extreme irritability',\n",
    "                                                          'Frequency of \"life not worth living\" thoughts': \"Frequency of 'life not worth living' thoughts\",\n",
    "                                                          'Diagnoses: Anxiety/panic attacks': 'Anxiety/panic attacks',\n",
    "                                                          'NS-12': 'N-12',\n",
    "                                                          'Diagnoses: Depression': 'Depression'\n",
    "                                                          })\n",
    "significant_corr_renamed = significant_corr.rename(index={\"Diagnoses 'G'\": \"Diseases of the nervous system\",\n",
    "                                                          \"Diagnoses: Neurological problem, NS injury, epilepsy\": \"Neurological problems, nervous system injury, epilepsy\",\n",
    "                                                          \"Diagnoses 'F'\": \"Mental and behavioural disorders\",\n",
    "                                                          \"Diagnoses: Stress, insomnia, migraine, nervous/mental problems\": \"Stress, insomnia, migraine, nervous/mental problems\",\n",
    "                                                          'Ever had period extreme irritability': 'Ever had period of extreme irritability',\n",
    "                                                          'Frequency of \"life not worth living\" thoughts': \"Frequency of 'life not worth living' thoughts\",\n",
    "                                                          'Diagnoses: Anxiety/panic attacks': 'Anxiety/panic attacks',\n",
    "                                                          'NS-12': 'N-12',\n",
    "                                                          'Diagnoses: Depression': 'Depression'\n",
    "                                                          })\n",
    "corr_full_sorted_renamed_df = pd.DataFrame(corr_full_sorted_renamed).reset_index().rename(columns={'index': 'features'})\n",
    "loadings_renamed_df = weighted_loadings_full_matched_renamed.reset_index().rename(columns={'index': 'features'})\n",
    "# Save\n",
    "significant_corr_renamed_df = significant_corr_renamed.reset_index().rename(columns={'index': 'features'})\n",
    "corr_full_sorted_renamed_df.to_csv('/mental_health/single_split/corr_full_sorted_renamed_df.csv', index=False)\n",
    "significant_corr_renamed_df.to_csv('/mental_health/single_split/significant_corr_renamed_df.csv', index=False)\n",
    "loadings_renamed_df.to_csv('/mental_health/single_split/loadings_renamed_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
