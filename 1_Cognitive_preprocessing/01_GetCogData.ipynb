{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy import stats\n",
    "from scipy.stats import spearmanr\n",
    "import ukbiobank.utils.utils\n",
    "from ukbiobank.utils import fieldNamesToIds\n",
    "from ukbiobank.utils import loadCsv\n",
    "from ukbiobank.utils import addFields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload cognitive performance data (Instance 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '/ukbbdata/FULL/ukb.csv'\n",
    "ukb = ukbiobank.ukbio(ukb_csv=csv_path)\n",
    "# Cognitive Performance Instance 2\n",
    "df = ukbiobank.utils.utils.loadCsv(ukbio=ukb, fields=['eid', \n",
    "20023,\n",
    "4282,\n",
    "4285,\n",
    "20016,\n",
    "20128,\n",
    "6348,\n",
    "6350,\n",
    "6349,\n",
    "6351,\n",
    "6373,\n",
    "6374,\n",
    "23323,\n",
    "23324,\n",
    "21004,\n",
    "6383,\n",
    "20197,\n",
    "20018,\n",
    "4291,\n",
    "4294,\n",
    "4292,\n",
    "399,\n",
    "400], instance=2)\n",
    "# Add fields: Cognitive Performance Instance 2\n",
    "cog_ac_i2 = addFields(ukbio=ukb, df=df, fields=['eid',\n",
    "20023,\n",
    "4282,\n",
    "4285,\n",
    "20016,\n",
    "20128,\n",
    "6348,\n",
    "6350,\n",
    "6349,\n",
    "6351,\n",
    "6373,\n",
    "6374,\n",
    "23323,\n",
    "23324,\n",
    "21004,\n",
    "6383,\n",
    "6348,\n",
    "20197,\n",
    "20018,\n",
    "4291,\n",
    "4294,\n",
    "4292,\n",
    "399,\n",
    "400], instances=2)\n",
    "# Convert Field IDs to Field Names\n",
    "cog_ac_i2_names = ukbiobank.utils.utils.fieldIdsToNames(ukbio=ukb, df=cog_ac_i2)\n",
    "# Picture Vocabulary was not uploaded via UK BB utils, upload them separately\n",
    "pv = pd.read_csv('/ukbbdata/FULL/ukb.csv', usecols = ['eid', '26302-2.0', '26306-2.0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Field IDs to Field Names\n",
    "cog_ac_i2_names = ukbiobank.utils.utils.fieldIdsToNames(ukbio=ukb, df=cog_ac_i2)\n",
    "cog_i2_full = pd.merge(cog_ac_i2_names, pv, on=\"eid\")\n",
    "cog_2 = cog_i2_full.rename(columns={\"26302-2.0\": \"Specific cognitive ability-2.0\", \"26306-2.0\": \"Response delay interval-2.0\"})\n",
    "\n",
    "# Save cognitive data\n",
    "cog_2.to_csv('/Cog-Ment/CSVs/cog_2_FULL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect data\n",
    "print((cog_2 < 0).sum().sort_values())\n",
    "print((cog_2 == 0).sum().sort_values())\n",
    "\n",
    "#Replace negatives with NAs\n",
    "cog_2[cog_2 < 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count NAs\n",
    "print((cog_2.isna()).sum().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change response encoding for Prospective memory Initial answer: 1 if the participant correctly touched the orange circle on the first attempt, and 0 if they touched any other shape\n",
    "\n",
    "Now: 0=blue square, 1=pink star, 2=grey cross, 3=orange circle\n",
    "\n",
    "Categorical variables in the target set\n",
    "1. Prospective memory: initial answer: 1 = correct, 0 - incorrect\n",
    "2. Prospective memory: Final attempt correct: 1 - yes, 0 - no\n",
    "3. Prospective memory result: 0 = Instruction not recalled, either skipped or incorrect, 1 = Correct recall on first attempt, 2 = Correct recall on second attempt => 0 = Instruction not recalled, either skipped or incorrect, 1 = Correct recall on second attempt, 2 = Correct recall on first attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change response encoding for Prospective memory Initial answer\n",
    "cog_2[\"PM: initial answer-2.0\"] = cog_2[\"PM: initial answer-2.0\"].replace(1, 0)\n",
    "cog_2[\"PM: initial answer-2.0\"] = cog_2[\"PM: initial answer-2.0\"].replace(2, 0)\n",
    "cog_2[\"PM: initial answer-2.0\"] = cog_2[\"PM: initial answer-2.0\"].replace(3, 1)\n",
    "cog_2[\"Prospective memory result-2.0\"] = cog_2[\"Prospective memory result-2.0\"].replace(1, 3)\n",
    "cog_2[\"Prospective memory result-2.0\"] = cog_2[\"Prospective memory result-2.0\"].replace(2, 1)\n",
    "cog_2[\"Prospective memory result-2.0\"] = cog_2[\"Prospective memory result-2.0\"].replace(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the % of NAs and sort in an ascending order\n",
    "percent_missing_cog_2 = cog_2.isnull().sum() * 100 / len(cog_2)\n",
    "missing_value_cog_2 = pd.DataFrame({'percent_missing': percent_missing_cog_2}).sort_values(by=\"percent_missing\", ascending=True)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(missing_value_cog_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between the whole set and instance 2\n",
    "dif_missing_cog_2 = -1*(cog_2.isnull().sum() - len(cog_2))\n",
    "dif_missing_cog_2 = pd.DataFrame({'diff': dif_missing_cog_2}).sort_values(by=\"diff\", ascending=True)\n",
    "with pd.option_context('display.max_rows', None):\n",
    "    display(dif_missing_cog_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "cog_2_drop = cog_2.drop(['Time to complete round (Field ID: 400)-2.3', 'Number of incorrect matches in round (Field ID: 399)-2.3'], axis=1)\n",
    "print('Zero values\\n',(cog_2_drop == 0).sum().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 with NAs columns\n",
    "cog_2_drop[\"Fluid intelligence score (Field ID: 20016)-2.0\"] = cog_2_drop[\"Fluid intelligence score (Field ID: 20016)-2.0\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Specific cognitive ability-2.0\"] = cog_2_drop[\"Specific cognitive ability-2.0\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Time to complete test-2.0\"] = cog_2_drop[\"Time to complete test-2.0\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Duration to complete numeric path (trail #1) (Field ID: 6348)-2.0\"] = cog_2_drop[\"Duration to complete numeric path (trail #1) (Field ID: 6348)-2.0\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Number of puzzles attempted-2.0\"] = cog_2_drop[\"Number of puzzles attempted-2.0\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Time to complete round (Field ID: 400)-2.1\"] = cog_2_drop[\"Time to complete round (Field ID: 400)-2.1\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Time to complete round (Field ID: 400)-2.2\"] = cog_2_drop[\"Time to complete round (Field ID: 400)-2.2\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Duration to complete alphanumeric path (trail #2) (Field ID: 6350)-2.0\"] = cog_2_drop[\"Duration to complete alphanumeric path (trail #2) (Field ID: 6350)-2.0\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Number of attempts-2.0\"] = cog_2_drop[\"Number of attempts-2.0\"].replace(0, np.nan)\n",
    "cog_2_drop[\"Final attempt correct-2.0\"] = cog_2_drop[\"Final attempt correct-2.0\"].replace(9, np.nan) #9  means \"abandoned\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n",
    "cog_2_drop_na = cog_2_drop.dropna(axis=0)\n",
    "print((cog_2_drop_na.isna()).sum().sort_values())\n",
    "print((cog_2_drop_na < 0).sum())\n",
    "cog_2_drop_na.to_csv('/Cog-Ment/CSVs/cog_2_no_na_instance_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns\n",
    "cog2_rename = cog_2_drop_na.rename(columns={'Number of symbol digit matches attempted (Field ID: 23323)-2.0': \"SDS:Numb of symbol digit matches attempted\",\n",
    " 'Number of word pairs correctly associated-2.0': \"PAL:Numb of word pairs correctly associated\",\n",
    " 'Number of fluid intelligence questions attempted within time limit-2.0': \"FI:Numb of FI questions attempted within time limit\",\n",
    " 'Total errors traversing numeric path (trail #1) (Field ID: 6349)-2.0': \"TMT:Total errors traversing numeric path #1\",\n",
    " 'Total errors traversing alphanumeric path (trail #2) (Field ID: 6351)-2.0': \"TMT:Total errors traversing alphanumeric path #2\",\n",
    " 'Number of puzzles attempted-2.0': \"Tower rearranging:Numb of puzzles attempted\",\n",
    " 'Time to complete round (Field ID: 400)-2.2': \"Pairs match:Time to complete round 2\",\n",
    " 'Final attempt correct-2.0': \"Prosp memory:Final attempt correct\",\n",
    " 'Number of puzzles viewed-2.0': \"Matrix PC:Numb of puzzles viewed\",\n",
    " 'Number of attempts-2.0': \"Prosp memory:Numb of attempts\",\n",
    " 'PM: initial answer-2.0': \"Prosp memory:Initial answer\",\n",
    " 'Number of incorrect matches in round (Field ID: 399)-2.2': \"Pairs match:Numb of incorrect matches in round 2\",\n",
    " 'Time to complete round (Field ID: 400)-2.1': \"Pairs match:Time to complete round 1\",\n",
    " 'Time to complete test-2.0': \"Numeric memory:Time to complete test\",\n",
    " 'Number of puzzles correct-2.0': \"Tower rearranging:Numb of puzzles correct\",\n",
    " 'Prospective memory result-2.0': \"Prospective memory result\",\n",
    " 'Number of puzzles correctly solved-2.0': \"Matrix PC: Numb of puzzles correctly solved\",\n",
    " 'Duration to complete numeric path (trail #1) (Field ID: 6348)-2.0': \"TMT:Duration to complete numeric path #1\",\n",
    " 'Number of incorrect matches in round (Field ID: 399)-2.1': \"Pairs match:Numb of incorrect matches in round 1\",\n",
    " 'Number of symbol digit matches made correctly (Field ID: 23324)-2.0': \"SDS:Numb of symbol digit matches made correctly\",\n",
    " 'Duration to complete alphanumeric path (trail #2) (Field ID: 6350)-2.0': \"TMT:Duration to complete alphanumeric path #2\",\n",
    " 'Mean time to correctly identify matches-2.0': \"RT:Mean time to correctly identify matches\",\n",
    " 'Maximum digits remembered correctly (Field ID: 4282)-2.0': \"Numeric memory:Max digits remembered correctly\",\n",
    " 'Fluid intelligence score (Field ID: 20016)-2.0': \"FIS\",\n",
    " 'Specific cognitive ability-2.0': \"Picture vocab:Specific cognitive ability\",\n",
    " 'Response delay interval-2.0': \"Picture vocab:Response delay interval\"})\n",
    "\n",
    "# Select columns of interest\n",
    "cog2_twelve = cog2_rename[['eid',\n",
    "'RT:Mean time to correctly identify matches',\n",
    "'FIS',\n",
    "'Numeric memory:Max digits remembered correctly',\n",
    "'TMT:Duration to complete numeric path #1', \n",
    "'TMT:Duration to complete alphanumeric path #2',\n",
    "'SDS:Numb of symbol digit matches made correctly',\n",
    "'PAL:Numb of word pairs correctly associated',\n",
    "'Tower rearranging:Numb of puzzles correct',\n",
    "'Prosp memory:Initial answer',\n",
    "'Matrix PC: Numb of puzzles correctly solved',\n",
    "'Pairs match:Numb of incorrect matches in round 2',\n",
    "'Picture vocab:Specific cognitive ability']]\n",
    "\n",
    "print((cog2_twelve == 0).sum())\n",
    "cog2_twelve.to_csv('/Cog-Ment/CSVs/cog2_twelve.csv', index=False)\n",
    "cog2_twelve.to_csv('/Cog-Ment/R/g_factor_5_folds/target.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
