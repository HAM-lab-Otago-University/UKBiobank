{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "import matplotlib.ticker as ticker\n",
    "from textwrap import wrap\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pd.read_csv('/Cog-Ment/R/g_factor_5_folds/target.csv')\n",
    "targets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.columns = ['eid', '(log)Reaction time', 'Fluid intelligence score',\n",
    "       'Numeric memory: Maximum digits remembered correctly',\n",
    "       '(log)Trail making test: Duration to complete numeric path',\n",
    "       '(log)Trail making test: Duration to complete alphabetic path',\n",
    "       'Symbol digit substitution: Number of correct matches',\n",
    "       'Paired associate learning: Number of correct pairs',\n",
    "       'Tower rearranging: Number of puzzles correct',\n",
    "       'Matrix pattern completion: Number of puzzles correct',\n",
    "       '(logx+1)Pairs matching: Incorrect matches',\n",
    "       'Picture vocabulary: Specific cognitive ability',\n",
    "       'Prospective memory: Initial answer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the distribution of cognitive test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cognitive test score distribution\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(35, 20))\n",
    "columns = targets.drop(columns='eid').columns\n",
    "axes = axes.flatten()\n",
    "for i, col in enumerate(columns):\n",
    "    column_data = targets.drop(columns='eid')[col]\n",
    "\n",
    "    binwidth = 0.03 if col != 'Matrix pattern completion: Number of puzzles correct' and col != 'Fluid intelligence score' and col != 'Numeric memory: Maximum digits remembered correctly' and col != 'Paired associate learning: Number of correct pairs' and col != 'Tower rearranging: Number of puzzles correct' and col != 'Symbol digit substitution: Number of correct matches' else 0.5\n",
    "    sns.histplot(column_data, ax=axes[i], color='wheat', binwidth=binwidth, linewidth=0.5)\n",
    "    axes[i].tick_params(axis='x', labelsize=12)\n",
    "\n",
    "    \n",
    "    wrapped_col = '\\n'.join(wrap(col, width=27)) # Wrap the column label at spaces to keep words uninterrupted\n",
    "\n",
    "    axes[i].set_xlabel(wrapped_col, fontsize=20)\n",
    "    axes[i].set_ylabel(None)\n",
    "    axes[i].tick_params(axis='y', labelsize=12)\n",
    "    axes[i].tick_params(axis='x', labelsize=12)\n",
    "\n",
    "    axes[i].xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    if col == 'Picture vocabulary: Specific cognitive ability':\n",
    "        axes[i].xaxis.set_major_locator(ticker.MultipleLocator(0.1))\n",
    "    elif col in ['(log)Trail making test: Duration to complete alphanumeric path', '(log)Trail making test: Duration to complete numeric path', '(log)Reaction time', '(log1p)Pairs matching: Incorrect matches']:\n",
    "        axes[i].xaxis.set_major_locator(ticker.MultipleLocator(0.5))\n",
    "    else:\n",
    "        axes[i].xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    #axes[i].yaxis.set_major_locator(locator) # y axis tick interval\n",
    "\n",
    "    axes[i].set_xlim(left=0) if col != '(log)Reaction time' and col != '(log)Trail making test: Duration to complete numeric path' and col !='(log)Trail making test: Duration to complete alphanumeric path' else axes[i].set_xlim(left=column_data.min()) \n",
    "\n",
    "plt.suptitle('Distribution of Cognitive Test Scores', fontsize=40, y=1.0)\n",
    "plt.subplots_adjust(hspace=0.6, wspace=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the correlation between cognitive test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot: Full\n",
    "plt.figure(figsize=(10, 10))\n",
    "correlation_target = targets.drop(columns='eid').corr(method='pearson')\n",
    "plot = sns.heatmap(correlation_target, cmap='coolwarm', fmt=\".2f\",\n",
    "                   xticklabels=correlation_target.columns,\n",
    "                   yticklabels=correlation_target.columns) #annot=True\n",
    "plot.set_xticklabels(plot.get_yticklabels(), rotation = 70, ha='right', fontsize = 20)\n",
    "plt.tick_params(labelsize=20)\n",
    "#plt.title('Correlations between Cognitive Test Scores', fontsize=25, y=1.05)\n",
    "\n",
    "# Set the font size for the colorbar\n",
    "cbar = plot.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation plot: Lower triangular part\n",
    "correlation_matrix = targets.drop(columns='eid').corr(method='pearson')\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot = sns.heatmap(correlation_matrix, cmap='coolwarm', fmt=\".2f\",\n",
    "                   xticklabels=correlation_matrix.columns,\n",
    "                   yticklabels=correlation_matrix.columns,\n",
    "                   mask=mask) # Apply mask\n",
    "plot.set_xticklabels(plot.get_xticklabels(), rotation=70, ha='right', fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "cbar = plot.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute correlations between cognitive test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlations between test scores\n",
    "correlation_matrix = targets.drop(columns='eid').corr(method='pearson')\n",
    "# Create a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool), k=1)\n",
    "# Apply the mask to get the lower triangle of the correlation matrix\n",
    "lower_triangle = pd.DataFrame(correlation_matrix.mask(mask)) #or lower_triangle = correlation_matrix.where(~mask)\n",
    "column_names = ['(log)RT', 'FIS', 'NM', '(log)TMT-numeric', '(log)TMT-alphabetic', 'SDS', 'PAL', 'Tower Rear.', 'Matrix PC', '(log1p)Pairs Match.', 'Picture Vocab.', 'Prospective Mem.']\n",
    "lower_triangle.columns = column_names\n",
    "lower_triangle.index = column_names\n",
    "lower_triangle.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract p-values\n",
    "p_values = pd.DataFrame(index=column_names, columns=column_names)\n",
    "for i in range(targets.drop(columns='eid').shape[1]):\n",
    "    for j in range(i+1, targets.drop(columns='eid').shape[1]):\n",
    "        _, p_value = pearsonr(targets.drop(columns='eid').iloc[:, i], targets.drop(columns='eid').iloc[:, j])\n",
    "        p_values.iloc[i, j] = p_value\n",
    "        p_values.iloc[j, i] = p_value \n",
    "\n",
    "mask = np.triu(np.ones_like(p_values, dtype=bool), k=1)\n",
    "lower_triangle_p_values = p_values.mask(mask)\n",
    "\n",
    "for col in lower_triangle_p_values.columns:\n",
    "    lower_triangle_p_values[col] = lower_triangle_p_values[col].apply(lambda x: '{:.3f}'.format(x) if pd.notnull(x) else x)\n",
    "lower_triangle_p_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the whole dataset into 5 folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "# Split the data set into train and test, using random folds, and save datasets and IDs for each split\n",
    "directory = \"/UK_BB/txt_no_colnames/\"\n",
    "# Use a for loop to save each train and test set for each fold\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(np.array(targets))):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    y_train, y_test = np.array(targets)[train_index], np.array(targets)[test_index]\n",
    "    # Convert to a data frame\n",
    "    y_train_df, y_test_df = pd.DataFrame(y_train, columns = targets.columns).drop(columns=['eid']), pd.DataFrame(y_test, columns = targets.columns).drop(columns=['eid'])\n",
    "    # Save\n",
    "    y_train_df.to_csv(f'/UK_BB/fold_{fold}/train_fold_{fold}.csv', index=False)\n",
    "    y_test_df.to_csv(f'/UK_BB/fold_{fold}/test_fold_{fold}.csv', index=False)\n",
    "\n",
    "\n",
    "    # Scale\n",
    "    scaler = StandardScaler()\n",
    "    y_train_scaled = scaler.fit_transform(y_train)\n",
    "    y_test_scaled = scaler.transform(y_test)\n",
    "    # Convert to a data frame\n",
    "    y_train_scaled_df, y_test_scaled_df = pd.DataFrame(y_train_scaled, columns = targets.columns).drop(columns=['eid']), pd.DataFrame(y_test_scaled, columns = targets.columns).drop(columns=['eid'])\n",
    "    # Save\n",
    "    y_train_scaled_df.to_csv(f'/UK_BB/fold_{fold}/train_scaled_fold_{fold}.csv', index=False)\n",
    "    y_test_scaled_df.to_csv(f'/UK_BB/fold_{fold}/test_scaled_fold_{fold}.csv', index=False)\n",
    "\n",
    "\n",
    "    # Extract the 'eid' column for each train and test set and save as csv\n",
    "    y_train_id = y_train[:, 0]\n",
    "    y_test_id = y_test[:, 0]\n",
    "    # Convert to a data frame\n",
    "    y_train_id_df, y_test_id_df = pd.DataFrame(y_train_id, columns = ['eid']), pd.DataFrame(y_test_id, columns = ['eid'])\n",
    "    # Save\n",
    "    y_train_id_df.to_csv(f'/UK_BB/fold_{fold}/train_id_fold_{fold}.csv', index=False)\n",
    "    y_test_id_df.to_csv(f'/UK_BB/fold_{fold}/test_id_fold_{fold}.csv', index=False)\n",
    "    \n",
    "    \n",
    "    #1 Create the file name for each train and test set using the fold number\n",
    "    train_file = \"train_\" + str(fold) + \".csv\"\n",
    "    test_file = \"test_\" + str(fold) + \".csv\"\n",
    "    # Use the os.path.join function to create the full file path for each file\n",
    "    train_path = os.path.join(directory, train_file)\n",
    "    test_path = os.path.join(directory, test_file)\n",
    "    # Save the train and test sets as txt\n",
    "    np.savetxt(train_path, y_train, delimiter=\",\")\n",
    "    np.savetxt(test_path, y_test, delimiter=\",\")\n",
    "\n",
    "    #2 Create the file name for each train and test set using the fold number\n",
    "    train_file_scaled = \"train_scaled_\" + str(fold) + \".csv\"\n",
    "    test_file_scaled = \"test_scaled_\" + str(fold) + \".csv\"\n",
    "    # Use the os.path.join function to create the full file path for each file\n",
    "    train_path_scaled = os.path.join(directory, train_file_scaled)\n",
    "    test_path_scaled = os.path.join(directory, test_file_scaled)\n",
    "    # Save scaled files as txt\n",
    "    np.savetxt(train_path_scaled, y_train_scaled, delimiter=\",\")\n",
    "    np.savetxt(test_path_scaled, y_test_scaled, delimiter=\",\")\n",
    "\n",
    "    #3 Create the file name for each train and test set using the fold number\n",
    "    train_id = \"train_id_\" + str(fold) + \".csv\"\n",
    "    test_id = \"test_is_\" + str(fold) + \".csv\"\n",
    "    # Use the os.path.join function to create the full file path for each file\n",
    "    train_path_id = os.path.join(directory, train_id)\n",
    "    test_path_id = os.path.join(directory, test_id)\n",
    "    # Save ids as txt\n",
    "    np.savetxt(train_path_id, y_train_id)\n",
    "    np.savetxt(test_path_id, y_test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload demographics variables\n",
    "basic_confounds_min = pd.read_csv('/UK_BB/basic_confounds_min.csv').drop(columns='Date of attending assessment centre')\n",
    "participant_age = basic_confounds_min[['eid', 'Sex', 'Age when attended assessment centre']].merge(targets['eid'])\n",
    "print(basic_confounds_min.columns)\n",
    "print(participant_age.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 = Female;\n",
    "1 = Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Age when attended assessment centre, mean:', participant_age['Age when attended assessment centre'].mean().round(2), 'SD:', f\"{participant_age['Age when attended assessment centre'].std():.3f}\")\n",
    "print('Age max range:', participant_age['Age when attended assessment centre'].max())\n",
    "print('Age min range:', participant_age['Age when attended assessment centre'].min())\n",
    "print('Proportion of males:', (participant_age['Sex'].value_counts()[1] / len(participant_age['Sex']) * 100).round(2))\n",
    "print('Proportion of females:', (participant_age['Sex'].value_counts()[0] / len(participant_age['Sex']) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean demographic data for each fold\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "for fold in folds:\n",
    "    \n",
    "    y_train = pd.read_csv(f'/UK_BB/fold_{fold}/train_id_fold_{fold}.csv')\n",
    "    y_test = pd.read_csv(f'/UK_BB/fold_{fold}/test_id_fold_{fold}.csv')\n",
    "\n",
    "    conf_train, conf_test = pd.merge(participant_age, y_train['eid'], on='eid'), pd.merge(participant_age, y_test['eid'], on='eid')\n",
    "    print('TRAINING SET')\n",
    "    print(f'Number of participants in fold {fold}:', conf_train.shape)\n",
    "    print(f'Mean age in fold {fold}:', conf_train['Age when attended assessment centre'].mean().round(2), f'SD for age in fold {fold}:', '{0:.3f}'.format(conf_train['Age when attended assessment centre'].std()))\n",
    "    print(f'Proportion of females in fold {fold}:',  (conf_train['Sex'].value_counts()[0] / len(conf_train['Sex']) * 100).round(2))\n",
    "\n",
    "    print('TEST SET')\n",
    "    print(f'Number of participants in fold {fold}:', conf_test.shape)\n",
    "    print(f'Mean age in fold {fold}:', conf_test['Age when attended assessment centre'].mean().round(2), f'SD for age in fold {fold}:', '{0:.3f}'.format(conf_test['Age when attended assessment centre'].std()))\n",
    "    print(f'Proportion of females in fold {fold}:',  (conf_test['Sex'].value_counts()[0] / len(conf_test['Sex']) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a table with demographics data for each fold\n",
    "results_list = []\n",
    "\n",
    "folds = [\"0\", \"1\", \"2\", \"3\", \"4\"]\n",
    "for fold in folds:\n",
    "    \n",
    "    y_train = pd.read_csv(f'/UK_BB/fold_{fold}/train_id_fold_{fold}.csv')\n",
    "    y_test = pd.read_csv(f'/UK_BB/fold_{fold}/test_id_fold_{fold}.csv')\n",
    "\n",
    "    conf_train, conf_test = pd.merge(participant_age, y_train['eid'], on='eid'), pd.merge(participant_age, y_test['eid'], on='eid')\n",
    "    train_results = {\n",
    "        'Fold': fold,\n",
    "        'Set': 'Training',\n",
    "        'Number of Participants': conf_train.shape[0],\n",
    "        'Mean Age': conf_train['Age when attended assessment centre'].mean().round(2),\n",
    "        'Age SD': '{0:.3f}'.format(conf_train['Age when attended assessment centre'].std()),\n",
    "        'Proportion of Females (%)': (conf_train['Sex'].value_counts()[0] / len(conf_train['Sex']) * 100).round(2)\n",
    "    }\n",
    "    results_list.append(train_results)\n",
    "    \n",
    "    # Store test set results in a dictionary and append to the list\n",
    "    test_results = {\n",
    "        'Fold': fold,\n",
    "        'Set': 'Test',\n",
    "        'Number of Participants': conf_test.shape[0],\n",
    "        'Mean Age': conf_test['Age when attended assessment centre'].mean().round(2),\n",
    "        'Age SD': '{0:.3f}'.format(conf_test['Age when attended assessment centre'].std()),\n",
    "        'Proportion of Females (%)': (conf_test['Sex'].value_counts()[0] / len(conf_test['Sex']) * 100).round(2)\n",
    "    }\n",
    "    results_list.append(test_results)\n",
    "results_df = pd.DataFrame(results_list)\n",
    "results_df.to_csv('/UK_BB/folds_summary.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ukbiobank_py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
